{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Notebook for model visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from transformers import TFViTModel\n",
    "\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, BatchNormalization, Dropout, Subtract, Activation, Conv2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from utils import *\n",
    "from data_aug import *\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_rescale_hf = tf.keras.Sequential([\n",
    "    tf.keras.layers.Permute((3, 1, 2))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streetview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_array_Streetview, image2_array_Streetview, labels_Streetview = load_data(\"../data/question_1/Streetview_dataaug\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapillary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_array_Mapillary, image2_array_Mapillary, labels_Mapillary = load_data(\"../Mapillary/mapillary_training_dataaug_contrast/\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison model (VGG19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_model(input_shape):\n",
    "    \"\"\"Create a siamese model for image comparison using VGG19 as base model.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): Shape of the input images.\n",
    "    Returns:\n",
    "        keras.models.Model: The compiled siamese model.\n",
    "    \"\"\"\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    for layer in base_model.layers[:-4]:\n",
    "        layer.trainable=False\n",
    "\n",
    "    # Create inputs for pairs of images\n",
    "    input_1 = Input(shape=input_shape)\n",
    "    input_2 = Input(shape=input_shape)\n",
    "\n",
    "    # Get embeddings of the images using the shared VGG19 model\n",
    "    output_1 = base_model(input_1)\n",
    "    output_2 = base_model(input_2)\n",
    "\n",
    "    concat = concatenate([output_1, output_2])\n",
    "\n",
    "    # Classification layer to predict similarity\n",
    "    flatten = Flatten()(concat)\n",
    "    x = Conv2D(32, (3, 3), activation=\"tanh\", padding='same')(concat)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Conv2D(32, (3, 3), activation=\"tanh\", padding='same')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Flatten()(x)\n",
    "    output = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "    # Create the complete siamese model\n",
    "    siamese_model = Model(inputs=[input_1, input_2], outputs=output)\n",
    "\n",
    "    # Compile the model with the provided hyperparameters\n",
    "    siamese_model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=1e-05, decay=0.001), metrics=['accuracy'])\n",
    "\n",
    "    # Print model summary\n",
    "    siamese_model.summary()\n",
    "\n",
    "    return siamese_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking model (VGG19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ranking_network(img_size):\n",
    "    \"\"\"\n",
    "    Create ranking network which give a score to an image.\n",
    "\n",
    "    :param img_size: size of input images during training\n",
    "    :type img_size: tuple(int)\n",
    "    :return: ranking network model\n",
    "    :rtype: keras.Model\n",
    "    \"\"\"\n",
    "    # Create feature extractor from VGG19\n",
    "    feature_extractor = VGG19(weights=\"imagenet\", include_top=False, input_shape=(img_size, img_size, 3))\n",
    "    for layer in feature_extractor.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add dense layers on top of the feature extractor\n",
    "    inp = Input(shape=(img_size, img_size, 3), name='input_image')\n",
    "    base = feature_extractor(inp)\n",
    "    base = Flatten(name='Flatten')(base)\n",
    "\n",
    "    # Block 1\n",
    "    base = Dense(32, activation='sigmoid', name='Dense_1')(base)\n",
    "    base = BatchNormalization(name='BN1')(base)\n",
    "    base = Dropout(0.2, name='Drop_1')(base)\n",
    "\n",
    "    # Block 2\n",
    "    base = Dense(32, activation='sigmoid', name='Dense_2')(base)\n",
    "    base = BatchNormalization(name='BN2')(base)\n",
    "    base = Dropout(0.2, name='Drop_2')(base)\n",
    "\n",
    "    # Final dense\n",
    "    base = Dense(1, name=\"Dense_Output\")(base)\n",
    "    base_network = Model(inp, base, name='Scoring_model')\n",
    "    return base_network\n",
    "\n",
    "\n",
    "def create_meta_network(img_size, weights=None):\n",
    "    \"\"\"\n",
    "    Create meta network which is used to to teach the ranking network.\n",
    "\n",
    "    :param img_size: dimension of input images during training.\n",
    "    :type img_size: tuple(int)\n",
    "    :param weights: path to the weights use for initialization\n",
    "    :type weights: str\n",
    "    :return: meta network model\n",
    "    :rtype: keras.Model\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the two input branches\n",
    "    input_left = Input(shape=(img_size, img_size, 3), name='left_input')\n",
    "    input_right = Input(shape=(img_size, img_size, 3), name='right_input')\n",
    "    base_network = create_ranking_network(img_size)\n",
    "    left_score = base_network(input_left)\n",
    "    right_score = base_network(input_right)\n",
    "\n",
    "    # Subtract scores\n",
    "    diff = Subtract()([left_score, right_score])\n",
    "\n",
    "    # Pass difference through sigmoid function.\n",
    "    prob = Activation(\"sigmoid\", name=\"Activation_sigmoid\")(diff)\n",
    "    model = Model(inputs=[input_left, input_right], outputs= prob, name=\"Meta_Model\")\n",
    "\n",
    "    if weights:\n",
    "        print('Loading weights ...')\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    model.compile(optimizer=RMSprop(learning_rate=0.0001, decay=1e-05), loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison model (ViT from Google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_vit_model(input_shape):\n",
    "    input_1 = layers.Input(shape=input_shape)\n",
    "    resized_input_1 = resize_rescale_hf(input_1)  # Make sure resize_rescale_hf is defined or imported\n",
    "    input_2 = layers.Input(shape=input_shape)\n",
    "    resized_input_2 = resize_rescale_hf(input_2)  # Make sure resize_rescale_hf is defined or imported\n",
    "    \n",
    "    # Load the ViT model for image classification\n",
    "    base_model = TFViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable=True\n",
    "\n",
    "    # Extract the features from the ViT model\n",
    "    features_1 = base_model.vit(resized_input_1)[0][:, 0, :]\n",
    "    features_2 = base_model.vit(resized_input_2)[0][:, 0, :]\n",
    "\n",
    "    # Calculate the Euclidean distance between the representations of the two images\n",
    "    distance = layers.Lambda(lambda tensors: tf.math.abs(tensors[0] - tensors[1]))([features_1, features_2])\n",
    "    outputs = layers.Dense(2, activation='softmax')(distance)\n",
    "\n",
    "    # Create the Keras model\n",
    "    siamese_network = tf.keras.Model(inputs=[input_1, input_2], outputs=outputs)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    siamese_network.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return siamese_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking model (ViT from Google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ranking_network_vit(img_size):\n",
    "    \"\"\"\n",
    "    Create ranking network which give a score to an image.\n",
    "\n",
    "    :param img_size: size of input images during training\n",
    "    :type img_size: tuple(int)\n",
    "    :return: ranking network model\n",
    "    :rtype: keras.Model\n",
    "    \"\"\"\n",
    "    # Create feature extractor from VGG19\n",
    "    feature_extractor = TFViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "    for layer in feature_extractor.layers:\n",
    "        layer.trainable=True\n",
    "\n",
    "    # Add dense layers on top of the feature extractor\n",
    "    inp = Input(shape=(img_size, img_size, 3), name='input_image')\n",
    "    resized_inp = resize_rescale_hf(inp) \n",
    "    base = feature_extractor.vit(resized_inp)[0][:, 0, :]\n",
    "    base = Flatten(name='Flatten')(base)\n",
    "\n",
    "    # Block 1\n",
    "    base = Dense(32, activation='sigmoid', name='Dense_1')(base)\n",
    "    base = BatchNormalization(name='BN1')(base)\n",
    "    base = Dropout(0.2, name='Drop_1')(base)\n",
    "\n",
    "    # Block 2\n",
    "    base = Dense(32, activation='sigmoid', name='Dense_2')(base)\n",
    "    base = BatchNormalization(name='BN2')(base)\n",
    "    base = Dropout(0.2, name='Drop_2')(base)\n",
    "\n",
    "    # Final dense\n",
    "    base = Dense(1, name=\"Dense_Output\")(base)\n",
    "    base_network = Model(inp, base, name='Scoring_model')\n",
    "    return base_network\n",
    "\n",
    "\n",
    "def create_meta_network_vit(img_size, weights=None):\n",
    "    \"\"\"\n",
    "    Create meta network which is used to to teach the ranking network.\n",
    "\n",
    "    :param img_size: dimension of input images during training.\n",
    "    :type img_size: tuple(int)\n",
    "    :param weights: path to the weights use for initialization\n",
    "    :type weights: str\n",
    "    :return: meta network model\n",
    "    :rtype: keras.Model\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the two input branches\n",
    "    input_left = Input(shape=(img_size, img_size, 3), name='left_input')\n",
    "    input_right = Input(shape=(img_size, img_size, 3), name='right_input')\n",
    "    base_network = create_ranking_network(img_size)\n",
    "    left_score = base_network(input_left)\n",
    "    right_score = base_network(input_right)\n",
    "\n",
    "    # Subtract scores\n",
    "    diff = Subtract()([left_score, right_score])\n",
    "\n",
    "    # Pass difference through sigmoid function.\n",
    "    prob = Activation(\"sigmoid\", name=\"Activation_sigmoid\")(diff)\n",
    "    model = Model(inputs=[input_left, input_right], outputs= prob, name=\"Meta_Model\")\n",
    "\n",
    "    if weights:\n",
    "        print('Loading weights ...')\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    model.compile(optimizer=RMSprop(learning_rate=0.0001, decay=1e-05), loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at the training and validation loss/accuracy of the trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison model (VGG19) trained on Streetview data with data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"../Result/Streetview_Result/Comparison_Handpicked_DataAugmentation_With_contrast/accuracy_curve.png\" style=\"width: 40%; margin-right: 10px;\">\n",
    "    <img src=\"../Result/Streetview_Result/Comparison_Handpicked_DataAugmentation_With_contrast/loss_curve.png\" style=\"width: 40%; margin-right: 10px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking model (VGG19) trained on Streetview data with data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"../Result/Streetview_Result/Ranking_Handpicked_DatAug_With_Contrast/accuracy_curve.png\" style=\"width: 40%; margin-right: 10px;\">\n",
    "    <img src=\"../Result/Streetview_Result/Ranking_Handpicked_DatAug_With_Contrast/loss_curve.png\" style=\"width: 40%; margin-right: 10px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison model (VGG19) trained on Mapillary data with data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"../Result/Mapillary_Results/Best_ComparisonModel_From_Streetview_Trained_On_Mapillary_DataAug_Contrast/accuracy_curve.png\" style=\"width: 40%; margin-right: 10px;\">\n",
    "    <img src=\"../Result/Mapillary_Results/Best_ComparisonModel_From_Streetview_Trained_On_Mapillary_DataAug_Contrast/loss_curve.png\" style=\"width: 40%; margin-right: 10px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking model (VGG19) trained on Mapillary data with data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"../Result/Mapillary_Results/Best_RankingModel_From_Streetview_Trained_On_Mapillary_DataAug_Contrast/accuracy_curve.png\" style=\"width: 40%; margin-right: 10px;\">\n",
    "    <img src=\"../Result/Mapillary_Results/Best_RankingModel_From_Streetview_Trained_On_Mapillary_DataAug_Contrast/loss_curve.png\" style=\"width: 40%; margin-right: 10px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison model (ViT from Google) trained on Streetview data with data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"../Result/Transformer_Results/Streetview/Comparison_200E_dataaug_contrast/accuracy_curve.png\" style=\"width: 40%; margin-right: 10px;\">\n",
    "    <img src=\"../Result/Transformer_Results/Streetview/Comparison_200E_dataaug_contrast/loss_curve.png\" style=\"width: 40%; margin-right: 10px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking model (ViT from Google) trained on Streetview data with data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"../Result/Transformer_Results/Streetview/Ranking_10E_dataaug_contrast/accuracy_curve.png\" style=\"width: 40%; margin-right: 10px;\">\n",
    "    <img src=\"../Result/Transformer_Results/Streetview/Ranking_10E_dataaug_contrast/loss_curve.png\" style=\"width: 40%; margin-right: 10px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison model (ViT from Google) trained on Mapillary data with data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"../Result/Transformer_Results/Mapillary/Comparison_200E_dataaug_contrast/accuracy_curve.png\" style=\"width: 40%; margin-right: 10px;\">\n",
    "    <img src=\"../Result/Transformer_Results/Mapillary/Comparison_200E_dataaug_contrast/loss_curve.png\" style=\"width: 40%; margin-right: 10px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking model (ViT from Google) trained on Mapillary data with data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "    <img src=\"../Result/Transformer_Results/Mapillary/Ranking_30E_dataaug_contrast/accuracy_curve.png\" style=\"width: 40%; margin-right: 10px;\">\n",
    "    <img src=\"../Result/Transformer_Results/Mapillary/Ranking_30E_dataaug_contrast/loss_curve.png\" style=\"width: 40%; margin-right: 10px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data for the comparison models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapillary data for regular VGG19 comparison models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_generator, valid_generator, test_generator, train_size, valid_size = prepare_dataset_generators(image1_array_Mapillary, image2_array_Mapillary, labels_Mapillary, batch_size, \"comparison\")\n",
    "\n",
    "train_steps_per_epoch = train_size // batch_size\n",
    "valid_steps_per_epoch = valid_size // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streetview data for regular VGG19 comparison models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_generator, valid_generator, test_generator, train_size, valid_size = prepare_dataset_generators(image1_array_Streetview, image2_array_Streetview, labels_Streetview, batch_size, \"comparison\")\n",
    "\n",
    "train_steps_per_epoch = train_size // batch_size\n",
    "valid_steps_per_epoch = valid_size // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapillary data for the Google ViT comparison model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_generator, valid_generator, test_generator, train_size, valid_size = prepare_dataset_generators(image1_array_Mapillary, image2_array_Mapillary, labels_Mapillary, batch_size, \"comparison\")\n",
    "\n",
    "train_steps_per_epoch = train_size // batch_size\n",
    "valid_steps_per_epoch = valid_size // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streetview data for the Google ViT comparison model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_generator, valid_generator, test_generator, train_size, valid_size = prepare_dataset_generators(image1_array_Streetview, image2_array_Streetview, labels_Streetview, batch_size, \"comparison\")\n",
    "\n",
    "train_steps_per_epoch = train_size // batch_size\n",
    "valid_steps_per_epoch = valid_size // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data for the Ranking models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapillary data for the regular VGG19 ranking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_generator, valid_generator, test_generator, train_size, valid_size = prepare_dataset_generators(image1_array_Mapillary, image2_array_Mapillary, labels_Mapillary, batch_size, \"ranking\")\n",
    "\n",
    "train_steps_per_epoch = train_size // batch_size\n",
    "valid_steps_per_epoch = valid_size // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streetview data for the regular VGG19 ranking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_generator, valid_generator, test_generator, train_size, valid_size = prepare_dataset_generators(image1_array_Streetview, image2_array_Streetview, labels_Streetview, batch_size, \"ranking\")\n",
    "\n",
    "train_steps_per_epoch = train_size // batch_size\n",
    "valid_steps_per_epoch = valid_size // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapillary data for the Google ViT ranking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_generator, valid_generator, test_generator, train_size, valid_size = prepare_dataset_generators(image1_array_Mapillary, image2_array_Mapillary, labels_Mapillary, batch_size, \"ranking\")\n",
    "\n",
    "train_steps_per_epoch = train_size // batch_size\n",
    "valid_steps_per_epoch = valid_size // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streetview data for the Google ViT ranking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_generator, valid_generator, test_generator, train_size, valid_size = prepare_dataset_generators(image1_array_Streetview, image2_array_Streetview, labels_Streetview, batch_size, \"ranking\")\n",
    "\n",
    "train_steps_per_epoch = train_size // batch_size\n",
    "valid_steps_per_epoch = valid_size // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_ranking = 224\n",
    "input_shape_comparison = (224, 224, 3)\n",
    "num_epochs = 100\n",
    "\n",
    "model = \"Initialize the desired model here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "          steps_per_epoch=train_steps_per_epoch,\n",
    "          epochs=num_epochs,\n",
    "          validation_data=valid_generator,\n",
    "          validation_steps=valid_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save and look at the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(history)\n",
    "plot_loss(history)\n",
    "model.save(\"Test_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator, steps=valid_steps_per_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
