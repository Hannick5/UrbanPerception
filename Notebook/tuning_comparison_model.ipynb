{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from dataset import *\n",
    "from data_aug import *\n",
    "import tensorflow as tf\n",
    "from comparison_model import *\n",
    "from utils import *\n",
    "from ranking_model import *\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, BatchNormalization, Dropout, Subtract, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_array, image2_array, labels = load_data(\"../data/question_1/Npy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_generator, valid_generator, test_generator, train_size, valid_size = prepare_dataset_generators(image1_array, image2_array, labels, batch_size, \"comparison\")\n",
    "\n",
    "train_steps_per_epoch = train_size // batch_size\n",
    "valid_steps_per_epoch = valid_size // batch_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redefining the model for the tuning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter search space with wider ranges\n",
    "hyperparameters = {\n",
    "    'dense_units': [32, 64, 128, 256, 512],\n",
    "    'dropout_rate': [0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "    'learning_rate': [0.0001, 0.00001, 0.000001],\n",
    "    'optimizer': ['adam', 'sgd', 'rmsprop'],\n",
    "    'activation': ['relu', 'sigmoid', 'tanh'],\n",
    "    'learning_rate_decay': [0.001, 0.0001, 0.00001]\n",
    "}\n",
    "\n",
    "def comparison_siamese_model(input_shape, dense_units, dropout_rate, learning_rate, optimizer, learning_rate_decay, activation):\n",
    "    \"\"\"Create a siamese model for image comparison using VGG19 as base model.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): Shape of the input images.\n",
    "        dense_units (int): Number of units in the dense layers.\n",
    "        dropout_rate (float): Dropout rate.\n",
    "        learning_rate (float): Learning rate for the optimizer.\n",
    "        optimizer (str): Optimizer algorithm.\n",
    "        activation (str): Activation function for the dense layers.\n",
    "\n",
    "    Returns:\n",
    "        keras.models.Model: The compiled siamese model.\n",
    "    \"\"\"\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    for layer in base_model.layers[:-4]:\n",
    "        layer.trainable=False\n",
    "\n",
    "    # Create inputs for pairs of images\n",
    "    input_1 = Input(shape=input_shape)\n",
    "    input_2 = Input(shape=input_shape)\n",
    "\n",
    "    # Get embeddings of the images using the shared VGG19 model\n",
    "    output_1 = base_model(input_1)\n",
    "    output_2 = base_model(input_2)\n",
    "\n",
    "    concat = concatenate([output_1, output_2])\n",
    "\n",
    "    # Classification layer to predict similarity\n",
    "    flatten = Flatten()(concat)\n",
    "    x = Conv2D(dense_units, (3, 3), activation=activation, padding='same')(concat)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Conv2D(dense_units, (3, 3), activation=activation, padding='same')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Flatten()(x)\n",
    "    output = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "    # Create the complete siamese model\n",
    "    siamese_model = Model(inputs=[input_1, input_2], outputs=output)\n",
    "\n",
    "    if optimizer == \"adam\":\n",
    "        optimizer = Adam(learning_rate=learning_rate, decay=learning_rate_decay)\n",
    "    elif optimizer == \"sgd\":\n",
    "        optimizer = SGD(learning_rate=learning_rate, decay=learning_rate_decay)\n",
    "    elif optimizer == \"rmsprop\":\n",
    "        optimizer = RMSprop(learning_rate=learning_rate, decay=learning_rate_decay)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optimizer: \" + optimizer)\n",
    "\n",
    "    # Compile the model with the provided hyperparameters\n",
    "    siamese_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # Print model summary\n",
    "    siamese_model.summary()\n",
    "\n",
    "    return siamese_model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dense_units': 512, 'dropout_rate': 0.5, 'learning_rate': 1e-05, 'optimizer': 'adam', 'activation': 'sigmoid', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 7, 7, 512)    4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 7, 7, 512)    0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 512)    2359808     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 25088)        0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            50178       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,153,474\n",
      "Trainable params: 14,208,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 59s 486ms/step - loss: 0.7243 - accuracy: 0.5504 - val_loss: 0.5789 - val_accuracy: 0.7712\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 48s 491ms/step - loss: 0.5001 - accuracy: 0.7762 - val_loss: 0.4232 - val_accuracy: 0.8092\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.4239 - accuracy: 0.8141 - val_loss: 0.3960 - val_accuracy: 0.8214\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3997 - accuracy: 0.8329 - val_loss: 0.3743 - val_accuracy: 0.8320\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3730 - accuracy: 0.8431 - val_loss: 0.3611 - val_accuracy: 0.8404\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3581 - accuracy: 0.8501 - val_loss: 0.3528 - val_accuracy: 0.8482\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 42s 490ms/step - loss: 0.3405 - accuracy: 0.8625 - val_loss: 0.3333 - val_accuracy: 0.8544\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3218 - accuracy: 0.8706 - val_loss: 0.3196 - val_accuracy: 0.8588\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3042 - accuracy: 0.8806 - val_loss: 0.3173 - val_accuracy: 0.8655\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.2806 - accuracy: 0.8887 - val_loss: 0.3174 - val_accuracy: 0.8599\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.2643 - accuracy: 0.8950 - val_loss: 0.2963 - val_accuracy: 0.8672\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.2349 - accuracy: 0.9181 - val_loss: 0.2871 - val_accuracy: 0.8756\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 42s 490ms/step - loss: 0.2152 - accuracy: 0.9248 - val_loss: 0.2839 - val_accuracy: 0.8717\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.1975 - accuracy: 0.9359 - val_loss: 0.2879 - val_accuracy: 0.8778\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.1689 - accuracy: 0.9483 - val_loss: 0.2747 - val_accuracy: 0.8873\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.1515 - accuracy: 0.9507 - val_loss: 0.2955 - val_accuracy: 0.8800\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 490ms/step - loss: 0.1224 - accuracy: 0.9654 - val_loss: 0.2822 - val_accuracy: 0.8934\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.1027 - accuracy: 0.9728 - val_loss: 0.2810 - val_accuracy: 0.8834\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.0940 - accuracy: 0.9763 - val_loss: 0.2893 - val_accuracy: 0.8862\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.0827 - accuracy: 0.9799 - val_loss: 0.2877 - val_accuracy: 0.8901\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.0689 - accuracy: 0.9843 - val_loss: 0.2845 - val_accuracy: 0.8934\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.0546 - accuracy: 0.9884 - val_loss: 0.2973 - val_accuracy: 0.8934\n",
      "28/28 [==============================] - 9s 329ms/step - loss: 0.3846 - accuracy: 0.8845\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'dense_units': 512, 'dropout_rate': 0.5, 'learning_rate': 1e-05, 'optimizer': 'adam', 'activation': 'sigmoid', 'learning_rate_decay': 1e-05}\n",
      "Best Test Loss: 0.3845643401145935\n",
      "{'dense_units': 128, 'dropout_rate': 0.5, 'learning_rate': 1e-05, 'optimizer': 'rmsprop', 'activation': 'relu', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 128)    1179776     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 128)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 7, 7, 128)    147584      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 128)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 6272)         0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            12546       flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 21,364,290\n",
      "Trainable params: 8,419,330\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 42s 484ms/step - loss: 0.6766 - accuracy: 0.6065 - val_loss: 0.5893 - val_accuracy: 0.7489\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5384 - accuracy: 0.7596 - val_loss: 0.4650 - val_accuracy: 0.7930\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4570 - accuracy: 0.8024 - val_loss: 0.4204 - val_accuracy: 0.8075\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4192 - accuracy: 0.8202 - val_loss: 0.3927 - val_accuracy: 0.8209\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.3907 - accuracy: 0.8276 - val_loss: 0.3798 - val_accuracy: 0.8287\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.3726 - accuracy: 0.8424 - val_loss: 0.3701 - val_accuracy: 0.8281\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3659 - accuracy: 0.8496 - val_loss: 0.3617 - val_accuracy: 0.8365\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.3414 - accuracy: 0.8592 - val_loss: 0.3557 - val_accuracy: 0.8393\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.3305 - accuracy: 0.8627 - val_loss: 0.3472 - val_accuracy: 0.8426\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.3271 - accuracy: 0.8651 - val_loss: 0.3383 - val_accuracy: 0.8482\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.3034 - accuracy: 0.8791 - val_loss: 0.3275 - val_accuracy: 0.8549\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.2883 - accuracy: 0.8814 - val_loss: 0.3245 - val_accuracy: 0.8521\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.2926 - accuracy: 0.8849 - val_loss: 0.3267 - val_accuracy: 0.8516\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.2656 - accuracy: 0.8960 - val_loss: 0.3210 - val_accuracy: 0.8566\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.2530 - accuracy: 0.9045 - val_loss: 0.3044 - val_accuracy: 0.8583\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.2486 - accuracy: 0.9032 - val_loss: 0.2976 - val_accuracy: 0.8655\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.2315 - accuracy: 0.9144 - val_loss: 0.2927 - val_accuracy: 0.8705\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.2041 - accuracy: 0.9272 - val_loss: 0.2831 - val_accuracy: 0.8705\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.2065 - accuracy: 0.9274 - val_loss: 0.2788 - val_accuracy: 0.8728\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.1902 - accuracy: 0.9359 - val_loss: 0.2798 - val_accuracy: 0.8750\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.1693 - accuracy: 0.9414 - val_loss: 0.2868 - val_accuracy: 0.8772\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.1570 - accuracy: 0.9484 - val_loss: 0.2735 - val_accuracy: 0.8845\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.1511 - accuracy: 0.9512 - val_loss: 0.2660 - val_accuracy: 0.8940\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.1301 - accuracy: 0.9610 - val_loss: 0.2742 - val_accuracy: 0.8800\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.1209 - accuracy: 0.9619 - val_loss: 0.2669 - val_accuracy: 0.8917\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.1096 - accuracy: 0.9691 - val_loss: 0.2764 - val_accuracy: 0.8856\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.0936 - accuracy: 0.9736 - val_loss: 0.2704 - val_accuracy: 0.8973\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.0916 - accuracy: 0.9745 - val_loss: 0.2740 - val_accuracy: 0.8934\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.0773 - accuracy: 0.9784 - val_loss: 0.2686 - val_accuracy: 0.8984\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.0732 - accuracy: 0.9810 - val_loss: 0.2854 - val_accuracy: 0.8956\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.0628 - accuracy: 0.9839 - val_loss: 0.2952 - val_accuracy: 0.8962\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.0520 - accuracy: 0.9885 - val_loss: 0.2819 - val_accuracy: 0.8951\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.0501 - accuracy: 0.9895 - val_loss: 0.2896 - val_accuracy: 0.8984\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.0413 - accuracy: 0.9908 - val_loss: 0.3034 - val_accuracy: 0.8968\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.4096 - accuracy: 0.8845\n",
      "{'dense_units': 128, 'dropout_rate': 0.2, 'learning_rate': 0.0001, 'optimizer': 'adam', 'activation': 'tanh', 'learning_rate_decay': 0.001}\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 128)    1179776     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 128)    0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 7, 7, 128)    147584      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 6272)         0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            12546       flatten_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 21,364,290\n",
      "Trainable params: 8,419,330\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4594 - accuracy: 0.7792 - val_loss: 0.3711 - val_accuracy: 0.8365\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.3230 - accuracy: 0.8675 - val_loss: 0.3309 - val_accuracy: 0.8527\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.2677 - accuracy: 0.8913 - val_loss: 0.2924 - val_accuracy: 0.8661\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1840 - accuracy: 0.9333 - val_loss: 0.2780 - val_accuracy: 0.8834\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1272 - accuracy: 0.9599 - val_loss: 0.2328 - val_accuracy: 0.9057\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0806 - accuracy: 0.9771 - val_loss: 0.2421 - val_accuracy: 0.9062\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0477 - accuracy: 0.9871 - val_loss: 0.2684 - val_accuracy: 0.8990\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0309 - accuracy: 0.9926 - val_loss: 0.2641 - val_accuracy: 0.9169\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0238 - accuracy: 0.9937 - val_loss: 0.2729 - val_accuracy: 0.9007\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0107 - accuracy: 0.9987 - val_loss: 0.2694 - val_accuracy: 0.9118\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.2609 - val_accuracy: 0.9152\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.2553 - val_accuracy: 0.9219\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.2616 - val_accuracy: 0.9202\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.2666 - val_accuracy: 0.9208\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.2688 - val_accuracy: 0.9224\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.2682 - val_accuracy: 0.9241\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.2613 - val_accuracy: 0.9241\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.2741 - val_accuracy: 0.9241\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.2759 - val_accuracy: 0.9224\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.2821 - val_accuracy: 0.9235\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 4.0959e-04 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9263\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 7.3733e-04 - accuracy: 0.9996 - val_loss: 0.2725 - val_accuracy: 0.9247\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.2784 - val_accuracy: 0.9247\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.2860 - val_accuracy: 0.9252\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.3063 - val_accuracy: 0.9174\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 9.8111e-04 - accuracy: 0.9996 - val_loss: 0.2944 - val_accuracy: 0.9258\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.4375 - accuracy: 0.9029\n",
      "{'dense_units': 256, 'dropout_rate': 0.6, 'learning_rate': 1e-06, 'optimizer': 'rmsprop', 'activation': 'relu', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 7, 7, 256)    2359552     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 7, 7, 256)    590080      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 7, 7, 256)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 12544)        0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            25090       flatten_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,999,106\n",
      "Trainable params: 10,054,146\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 42s 488ms/step - loss: 0.7746 - accuracy: 0.5058 - val_loss: 0.6850 - val_accuracy: 0.5312\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.7566 - accuracy: 0.5167 - val_loss: 0.6777 - val_accuracy: 0.5301\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.7432 - accuracy: 0.5225 - val_loss: 0.6699 - val_accuracy: 0.5458\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.7256 - accuracy: 0.5603 - val_loss: 0.6614 - val_accuracy: 0.5731\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.7087 - accuracy: 0.5672 - val_loss: 0.6533 - val_accuracy: 0.5977\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.7032 - accuracy: 0.5729 - val_loss: 0.6441 - val_accuracy: 0.6378\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.6914 - accuracy: 0.5962 - val_loss: 0.6329 - val_accuracy: 0.6735\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 484ms/step - loss: 0.6758 - accuracy: 0.6132 - val_loss: 0.6218 - val_accuracy: 0.6998\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 484ms/step - loss: 0.6574 - accuracy: 0.6503 - val_loss: 0.6080 - val_accuracy: 0.7215\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.6409 - accuracy: 0.6651 - val_loss: 0.5941 - val_accuracy: 0.7405\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.6227 - accuracy: 0.6949 - val_loss: 0.5782 - val_accuracy: 0.7539\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.6090 - accuracy: 0.7113 - val_loss: 0.5643 - val_accuracy: 0.7578\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.5836 - accuracy: 0.7359 - val_loss: 0.5478 - val_accuracy: 0.7723\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.5791 - accuracy: 0.7296 - val_loss: 0.5314 - val_accuracy: 0.7746\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.5570 - accuracy: 0.7494 - val_loss: 0.5186 - val_accuracy: 0.7773\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.5412 - accuracy: 0.7646 - val_loss: 0.5043 - val_accuracy: 0.7818\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.5225 - accuracy: 0.7719 - val_loss: 0.4909 - val_accuracy: 0.7896\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.5183 - accuracy: 0.7695 - val_loss: 0.4801 - val_accuracy: 0.7941\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4934 - accuracy: 0.7875 - val_loss: 0.4671 - val_accuracy: 0.7991\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4960 - accuracy: 0.7797 - val_loss: 0.4606 - val_accuracy: 0.7980\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4854 - accuracy: 0.7801 - val_loss: 0.4537 - val_accuracy: 0.8002\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4743 - accuracy: 0.7899 - val_loss: 0.4494 - val_accuracy: 0.7969\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4755 - accuracy: 0.7914 - val_loss: 0.4412 - val_accuracy: 0.8047\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4642 - accuracy: 0.7923 - val_loss: 0.4404 - val_accuracy: 0.8036\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4594 - accuracy: 0.7989 - val_loss: 0.4346 - val_accuracy: 0.8064\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4535 - accuracy: 0.7963 - val_loss: 0.4285 - val_accuracy: 0.8097\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.4458 - accuracy: 0.8087 - val_loss: 0.4300 - val_accuracy: 0.8058\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4451 - accuracy: 0.8061 - val_loss: 0.4245 - val_accuracy: 0.8075\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4429 - accuracy: 0.8006 - val_loss: 0.4223 - val_accuracy: 0.8080\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4310 - accuracy: 0.8189 - val_loss: 0.4208 - val_accuracy: 0.8092\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4315 - accuracy: 0.8152 - val_loss: 0.4099 - val_accuracy: 0.8147\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4265 - accuracy: 0.8161 - val_loss: 0.4114 - val_accuracy: 0.8103\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4345 - accuracy: 0.8111 - val_loss: 0.4146 - val_accuracy: 0.8097\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4263 - accuracy: 0.8117 - val_loss: 0.4112 - val_accuracy: 0.8097\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4091 - accuracy: 0.8241 - val_loss: 0.4077 - val_accuracy: 0.8125\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4225 - accuracy: 0.8139 - val_loss: 0.4041 - val_accuracy: 0.8131\n",
      "28/28 [==============================] - 9s 329ms/step - loss: 0.4136 - accuracy: 0.8092\n",
      "{'dense_units': 256, 'dropout_rate': 0.6, 'learning_rate': 1e-06, 'optimizer': 'adam', 'activation': 'tanh', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_14[0][0]                   \n",
      "                                                                 input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 7, 7, 256)    2359552     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 7, 7, 256)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 7, 7, 256)    590080      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 7, 7, 256)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 12544)        0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            25090       flatten_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,999,106\n",
      "Trainable params: 10,054,146\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 42s 484ms/step - loss: 0.8095 - accuracy: 0.5116 - val_loss: 0.6825 - val_accuracy: 0.5910\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.7931 - accuracy: 0.5302 - val_loss: 0.6655 - val_accuracy: 0.6306\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7693 - accuracy: 0.5457 - val_loss: 0.6485 - val_accuracy: 0.6892\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7505 - accuracy: 0.5781 - val_loss: 0.6308 - val_accuracy: 0.7087\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7321 - accuracy: 0.5945 - val_loss: 0.6115 - val_accuracy: 0.7288\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7052 - accuracy: 0.6324 - val_loss: 0.5906 - val_accuracy: 0.7349\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.6903 - accuracy: 0.6405 - val_loss: 0.5664 - val_accuracy: 0.7517\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.6408 - accuracy: 0.6884 - val_loss: 0.5429 - val_accuracy: 0.7556\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.6212 - accuracy: 0.7054 - val_loss: 0.5219 - val_accuracy: 0.7550\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.5908 - accuracy: 0.7208 - val_loss: 0.5030 - val_accuracy: 0.7684\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.5714 - accuracy: 0.7381 - val_loss: 0.4859 - val_accuracy: 0.7751\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.5472 - accuracy: 0.7511 - val_loss: 0.4738 - val_accuracy: 0.7812\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.5177 - accuracy: 0.7688 - val_loss: 0.4635 - val_accuracy: 0.7874\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.5186 - accuracy: 0.7699 - val_loss: 0.4546 - val_accuracy: 0.7930\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4981 - accuracy: 0.7786 - val_loss: 0.4458 - val_accuracy: 0.8047\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4929 - accuracy: 0.7840 - val_loss: 0.4414 - val_accuracy: 0.8047\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4805 - accuracy: 0.7889 - val_loss: 0.4373 - val_accuracy: 0.8058\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4749 - accuracy: 0.7980 - val_loss: 0.4299 - val_accuracy: 0.8064\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4586 - accuracy: 0.8076 - val_loss: 0.4269 - val_accuracy: 0.8075\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4595 - accuracy: 0.8045 - val_loss: 0.4229 - val_accuracy: 0.8108\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4594 - accuracy: 0.8032 - val_loss: 0.4209 - val_accuracy: 0.8108\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4381 - accuracy: 0.8165 - val_loss: 0.4209 - val_accuracy: 0.8097\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4457 - accuracy: 0.8148 - val_loss: 0.4109 - val_accuracy: 0.8209\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4445 - accuracy: 0.8078 - val_loss: 0.4114 - val_accuracy: 0.8203\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4269 - accuracy: 0.8183 - val_loss: 0.4107 - val_accuracy: 0.8209\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4305 - accuracy: 0.8185 - val_loss: 0.4073 - val_accuracy: 0.8186\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4301 - accuracy: 0.8202 - val_loss: 0.4054 - val_accuracy: 0.8209\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4248 - accuracy: 0.8202 - val_loss: 0.4024 - val_accuracy: 0.8209\n",
      "28/28 [==============================] - 9s 329ms/step - loss: 0.4037 - accuracy: 0.8220\n",
      "{'dense_units': 256, 'dropout_rate': 0.2, 'learning_rate': 1e-06, 'optimizer': 'sgd', 'activation': 'tanh', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_17[0][0]                   \n",
      "                                                                 input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 7, 7, 256)    2359552     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 7, 7, 256)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 7, 7, 256)    590080      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 7, 7, 256)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 12544)        0           dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            25090       flatten_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,999,106\n",
      "Trainable params: 10,054,146\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.7312 - accuracy: 0.5095 - val_loss: 0.7085 - val_accuracy: 0.5285\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7251 - accuracy: 0.5236 - val_loss: 0.7073 - val_accuracy: 0.5290\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7254 - accuracy: 0.5156 - val_loss: 0.7076 - val_accuracy: 0.5246\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7222 - accuracy: 0.5334 - val_loss: 0.7066 - val_accuracy: 0.5257\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7233 - accuracy: 0.5213 - val_loss: 0.7036 - val_accuracy: 0.5318\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7190 - accuracy: 0.5298 - val_loss: 0.7032 - val_accuracy: 0.5307\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7205 - accuracy: 0.5173 - val_loss: 0.7016 - val_accuracy: 0.5312\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7188 - accuracy: 0.5212 - val_loss: 0.7015 - val_accuracy: 0.5307\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7174 - accuracy: 0.5230 - val_loss: 0.7008 - val_accuracy: 0.5285\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7167 - accuracy: 0.5274 - val_loss: 0.6997 - val_accuracy: 0.5285\n",
      "28/28 [==============================] - 9s 330ms/step - loss: 0.7027 - accuracy: 0.5061\n",
      "{'dense_units': 128, 'dropout_rate': 0.3, 'learning_rate': 1e-06, 'optimizer': 'rmsprop', 'activation': 'relu', 'learning_rate_decay': 0.001}\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_20[0][0]                   \n",
      "                                                                 input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 7, 7, 128)    1179776     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 7, 7, 128)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 7, 7, 128)    147584      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 7, 7, 128)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 6272)         0           dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            12546       flatten_13[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,364,290\n",
      "Trainable params: 8,419,330\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.7073 - accuracy: 0.5287 - val_loss: 0.6780 - val_accuracy: 0.5725\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.6882 - accuracy: 0.5738 - val_loss: 0.6641 - val_accuracy: 0.6429\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.6757 - accuracy: 0.6038 - val_loss: 0.6506 - val_accuracy: 0.6836\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.6584 - accuracy: 0.6370 - val_loss: 0.6369 - val_accuracy: 0.7176\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.6444 - accuracy: 0.6653 - val_loss: 0.6220 - val_accuracy: 0.7433\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.6222 - accuracy: 0.7004 - val_loss: 0.6060 - val_accuracy: 0.7528\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.6052 - accuracy: 0.7145 - val_loss: 0.5903 - val_accuracy: 0.7567\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5937 - accuracy: 0.7219 - val_loss: 0.5748 - val_accuracy: 0.7662\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5724 - accuracy: 0.7496 - val_loss: 0.5579 - val_accuracy: 0.7723\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5580 - accuracy: 0.7498 - val_loss: 0.5442 - val_accuracy: 0.7785\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5443 - accuracy: 0.7594 - val_loss: 0.5320 - val_accuracy: 0.7801\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5360 - accuracy: 0.7609 - val_loss: 0.5215 - val_accuracy: 0.7779\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5194 - accuracy: 0.7729 - val_loss: 0.5103 - val_accuracy: 0.7852\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5083 - accuracy: 0.7738 - val_loss: 0.5015 - val_accuracy: 0.7896\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4976 - accuracy: 0.7862 - val_loss: 0.4916 - val_accuracy: 0.7896\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4889 - accuracy: 0.7847 - val_loss: 0.4863 - val_accuracy: 0.7919\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4829 - accuracy: 0.7878 - val_loss: 0.4792 - val_accuracy: 0.7919\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4743 - accuracy: 0.7939 - val_loss: 0.4703 - val_accuracy: 0.7969\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4676 - accuracy: 0.7987 - val_loss: 0.4660 - val_accuracy: 0.7985\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4636 - accuracy: 0.7974 - val_loss: 0.4608 - val_accuracy: 0.8002\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4648 - accuracy: 0.7978 - val_loss: 0.4591 - val_accuracy: 0.7997\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4587 - accuracy: 0.7949 - val_loss: 0.4568 - val_accuracy: 0.8008\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4529 - accuracy: 0.8007 - val_loss: 0.4524 - val_accuracy: 0.8019\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4474 - accuracy: 0.8080 - val_loss: 0.4497 - val_accuracy: 0.8030\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4456 - accuracy: 0.8063 - val_loss: 0.4471 - val_accuracy: 0.8030\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4414 - accuracy: 0.8126 - val_loss: 0.4444 - val_accuracy: 0.8041\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4401 - accuracy: 0.8106 - val_loss: 0.4404 - val_accuracy: 0.8058\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4365 - accuracy: 0.8126 - val_loss: 0.4360 - val_accuracy: 0.8092\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4383 - accuracy: 0.8109 - val_loss: 0.4346 - val_accuracy: 0.8064\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4330 - accuracy: 0.8135 - val_loss: 0.4346 - val_accuracy: 0.8058\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4255 - accuracy: 0.8157 - val_loss: 0.4319 - val_accuracy: 0.8080\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4356 - accuracy: 0.8115 - val_loss: 0.4324 - val_accuracy: 0.8064\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4325 - accuracy: 0.8120 - val_loss: 0.4299 - val_accuracy: 0.8086\n",
      "28/28 [==============================] - 9s 329ms/step - loss: 0.4233 - accuracy: 0.8058\n",
      "{'dense_units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'optimizer': 'rmsprop', 'activation': 'relu', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_23[0][0]                   \n",
      "                                                                 input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 7, 7, 64)     589888      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 7, 7, 64)     0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 7, 7, 64)     36928       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 7, 7, 64)     0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 3136)         0           dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2)            6274        flatten_15[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,657,474\n",
      "Trainable params: 7,712,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.4647 - accuracy: 0.7884 - val_loss: 0.3737 - val_accuracy: 0.8315\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.3670 - accuracy: 0.8479 - val_loss: 0.3464 - val_accuracy: 0.8432\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.3253 - accuracy: 0.8668 - val_loss: 0.3193 - val_accuracy: 0.8566\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.2611 - accuracy: 0.8987 - val_loss: 0.3144 - val_accuracy: 0.8683\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.2266 - accuracy: 0.9104 - val_loss: 0.2886 - val_accuracy: 0.8728\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.1720 - accuracy: 0.9337 - val_loss: 0.3420 - val_accuracy: 0.8817\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.1349 - accuracy: 0.9542 - val_loss: 0.4163 - val_accuracy: 0.8828\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.1110 - accuracy: 0.9625 - val_loss: 0.4035 - val_accuracy: 0.8873\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0972 - accuracy: 0.9690 - val_loss: 0.3924 - val_accuracy: 0.8917\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0770 - accuracy: 0.9723 - val_loss: 0.4714 - val_accuracy: 0.8867\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0655 - accuracy: 0.9776 - val_loss: 0.3693 - val_accuracy: 0.8906\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0546 - accuracy: 0.9819 - val_loss: 0.4919 - val_accuracy: 0.9007\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0566 - accuracy: 0.9823 - val_loss: 0.5886 - val_accuracy: 0.8767\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0509 - accuracy: 0.9832 - val_loss: 0.3455 - val_accuracy: 0.9079\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0406 - accuracy: 0.9867 - val_loss: 0.4851 - val_accuracy: 0.9012\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0380 - accuracy: 0.9872 - val_loss: 0.6589 - val_accuracy: 0.8917\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0383 - accuracy: 0.9867 - val_loss: 0.4737 - val_accuracy: 0.8962\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0367 - accuracy: 0.9871 - val_loss: 0.4343 - val_accuracy: 0.8856\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0325 - accuracy: 0.9902 - val_loss: 0.5359 - val_accuracy: 0.9007\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.5855 - accuracy: 0.8850\n",
      "{'dense_units': 512, 'dropout_rate': 0.2, 'learning_rate': 1e-06, 'optimizer': 'adam', 'activation': 'sigmoid', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_26 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_27 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_26[0][0]                   \n",
      "                                                                 input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 7, 7, 512)    4719104     concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 7, 7, 512)    0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 7, 7, 512)    2359808     dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 7, 7, 512)    0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 25088)        0           dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 2)            50178       flatten_17[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 27,153,474\n",
      "Trainable params: 14,208,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 42s 490ms/step - loss: 0.7138 - accuracy: 0.5145 - val_loss: 0.6888 - val_accuracy: 0.5257\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.7047 - accuracy: 0.5178 - val_loss: 0.6850 - val_accuracy: 0.5352\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.6958 - accuracy: 0.5457 - val_loss: 0.6773 - val_accuracy: 0.5893\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.6849 - accuracy: 0.5799 - val_loss: 0.6622 - val_accuracy: 0.7126\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.6588 - accuracy: 0.6420 - val_loss: 0.6334 - val_accuracy: 0.7757\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.6186 - accuracy: 0.7065 - val_loss: 0.5870 - val_accuracy: 0.7885\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.5582 - accuracy: 0.7618 - val_loss: 0.5363 - val_accuracy: 0.7868\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.5075 - accuracy: 0.7873 - val_loss: 0.4973 - val_accuracy: 0.7907\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.4750 - accuracy: 0.7936 - val_loss: 0.4727 - val_accuracy: 0.7935\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4499 - accuracy: 0.8047 - val_loss: 0.4528 - val_accuracy: 0.8025\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4361 - accuracy: 0.8111 - val_loss: 0.4436 - val_accuracy: 0.8052\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4288 - accuracy: 0.8126 - val_loss: 0.4309 - val_accuracy: 0.8119\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.4215 - accuracy: 0.8115 - val_loss: 0.4271 - val_accuracy: 0.8080\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4123 - accuracy: 0.8174 - val_loss: 0.4224 - val_accuracy: 0.8058\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4052 - accuracy: 0.8172 - val_loss: 0.4142 - val_accuracy: 0.8192\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.4024 - accuracy: 0.8246 - val_loss: 0.4121 - val_accuracy: 0.8181\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.4087 - accuracy: 0.8133 - val_loss: 0.4058 - val_accuracy: 0.8164\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.3831 - accuracy: 0.8311 - val_loss: 0.4039 - val_accuracy: 0.8203\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3962 - accuracy: 0.8224 - val_loss: 0.4011 - val_accuracy: 0.8186\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3855 - accuracy: 0.8268 - val_loss: 0.3954 - val_accuracy: 0.8203\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3863 - accuracy: 0.8318 - val_loss: 0.3957 - val_accuracy: 0.8203\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3810 - accuracy: 0.8318 - val_loss: 0.3925 - val_accuracy: 0.8209\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.3817 - accuracy: 0.8291 - val_loss: 0.3877 - val_accuracy: 0.8237\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3717 - accuracy: 0.8385 - val_loss: 0.3844 - val_accuracy: 0.8265\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3816 - accuracy: 0.8276 - val_loss: 0.3856 - val_accuracy: 0.8259\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.3661 - accuracy: 0.8422 - val_loss: 0.3857 - val_accuracy: 0.8237\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.3765 - accuracy: 0.8340 - val_loss: 0.3832 - val_accuracy: 0.8248\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3686 - accuracy: 0.8427 - val_loss: 0.3785 - val_accuracy: 0.8287\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3602 - accuracy: 0.8425 - val_loss: 0.3809 - val_accuracy: 0.8276\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3677 - accuracy: 0.8424 - val_loss: 0.3742 - val_accuracy: 0.8326\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3551 - accuracy: 0.8448 - val_loss: 0.3748 - val_accuracy: 0.8298\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.3620 - accuracy: 0.8424 - val_loss: 0.3742 - val_accuracy: 0.8309\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.3536 - accuracy: 0.8498 - val_loss: 0.3729 - val_accuracy: 0.8276\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.3548 - accuracy: 0.8472 - val_loss: 0.3728 - val_accuracy: 0.8298\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3545 - accuracy: 0.8473 - val_loss: 0.3708 - val_accuracy: 0.8281\n",
      "28/28 [==============================] - 9s 331ms/step - loss: 0.3902 - accuracy: 0.8209\n",
      "{'dense_units': 32, 'dropout_rate': 0.6, 'learning_rate': 1e-06, 'optimizer': 'rmsprop', 'activation': 'relu', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_29[0][0]                   \n",
      "                                                                 input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 7, 7, 32)     294944      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 7, 7, 32)     0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 7, 7, 32)     9248        dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 7, 7, 32)     0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 1568)         0           dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 2)            3138        flatten_19[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,331,714\n",
      "Trainable params: 7,386,754\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.7990 - accuracy: 0.5141 - val_loss: 0.7045 - val_accuracy: 0.5246\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.7600 - accuracy: 0.5273 - val_loss: 0.6936 - val_accuracy: 0.5279\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.7396 - accuracy: 0.5140 - val_loss: 0.6882 - val_accuracy: 0.5285\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.7201 - accuracy: 0.5254 - val_loss: 0.6839 - val_accuracy: 0.5430\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7063 - accuracy: 0.5376 - val_loss: 0.6799 - val_accuracy: 0.5770\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6970 - accuracy: 0.5583 - val_loss: 0.6781 - val_accuracy: 0.6055\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6916 - accuracy: 0.5446 - val_loss: 0.6756 - val_accuracy: 0.6289\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6875 - accuracy: 0.5611 - val_loss: 0.6725 - val_accuracy: 0.6512\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6799 - accuracy: 0.5831 - val_loss: 0.6694 - val_accuracy: 0.6719\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6730 - accuracy: 0.6071 - val_loss: 0.6658 - val_accuracy: 0.6808\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6681 - accuracy: 0.6235 - val_loss: 0.6621 - val_accuracy: 0.6931\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6663 - accuracy: 0.6274 - val_loss: 0.6576 - val_accuracy: 0.7065\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6633 - accuracy: 0.6304 - val_loss: 0.6535 - val_accuracy: 0.7070\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6589 - accuracy: 0.6374 - val_loss: 0.6485 - val_accuracy: 0.7098\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6544 - accuracy: 0.6417 - val_loss: 0.6439 - val_accuracy: 0.7238\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6501 - accuracy: 0.6452 - val_loss: 0.6393 - val_accuracy: 0.7249\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6462 - accuracy: 0.6642 - val_loss: 0.6349 - val_accuracy: 0.7277\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6413 - accuracy: 0.6644 - val_loss: 0.6308 - val_accuracy: 0.7299\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6345 - accuracy: 0.6710 - val_loss: 0.6244 - val_accuracy: 0.7372\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6297 - accuracy: 0.6792 - val_loss: 0.6191 - val_accuracy: 0.7377\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6304 - accuracy: 0.6801 - val_loss: 0.6156 - val_accuracy: 0.7338\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6240 - accuracy: 0.6892 - val_loss: 0.6107 - val_accuracy: 0.7377\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6166 - accuracy: 0.6971 - val_loss: 0.6053 - val_accuracy: 0.7383\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6164 - accuracy: 0.6967 - val_loss: 0.6012 - val_accuracy: 0.7383\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.6110 - accuracy: 0.7022 - val_loss: 0.5967 - val_accuracy: 0.7427\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.6013 - accuracy: 0.7169 - val_loss: 0.5906 - val_accuracy: 0.7450\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6049 - accuracy: 0.7089 - val_loss: 0.5873 - val_accuracy: 0.7478\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5961 - accuracy: 0.7150 - val_loss: 0.5816 - val_accuracy: 0.7528\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5951 - accuracy: 0.7202 - val_loss: 0.5773 - val_accuracy: 0.7500\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5906 - accuracy: 0.7233 - val_loss: 0.5732 - val_accuracy: 0.7561\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5853 - accuracy: 0.7296 - val_loss: 0.5693 - val_accuracy: 0.7567\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5810 - accuracy: 0.7355 - val_loss: 0.5648 - val_accuracy: 0.7600\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5740 - accuracy: 0.7398 - val_loss: 0.5596 - val_accuracy: 0.7612\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5762 - accuracy: 0.7328 - val_loss: 0.5570 - val_accuracy: 0.7634\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5733 - accuracy: 0.7337 - val_loss: 0.5533 - val_accuracy: 0.7617\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5690 - accuracy: 0.7394 - val_loss: 0.5491 - val_accuracy: 0.7679\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5587 - accuracy: 0.7566 - val_loss: 0.5433 - val_accuracy: 0.7740\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5598 - accuracy: 0.7501 - val_loss: 0.5414 - val_accuracy: 0.7785\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5576 - accuracy: 0.7470 - val_loss: 0.5368 - val_accuracy: 0.7785\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5527 - accuracy: 0.7524 - val_loss: 0.5335 - val_accuracy: 0.7812\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5545 - accuracy: 0.7520 - val_loss: 0.5309 - val_accuracy: 0.7807\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5513 - accuracy: 0.7477 - val_loss: 0.5274 - val_accuracy: 0.7857\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5482 - accuracy: 0.7477 - val_loss: 0.5238 - val_accuracy: 0.7896\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5413 - accuracy: 0.7597 - val_loss: 0.5207 - val_accuracy: 0.7924\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5391 - accuracy: 0.7666 - val_loss: 0.5177 - val_accuracy: 0.7924\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5356 - accuracy: 0.7703 - val_loss: 0.5135 - val_accuracy: 0.7946\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5321 - accuracy: 0.7714 - val_loss: 0.5103 - val_accuracy: 0.7952\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5277 - accuracy: 0.7708 - val_loss: 0.5057 - val_accuracy: 0.7991\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5278 - accuracy: 0.7695 - val_loss: 0.5032 - val_accuracy: 0.7985\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5207 - accuracy: 0.7705 - val_loss: 0.5007 - val_accuracy: 0.8002\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.4931 - accuracy: 0.7974\n",
      "{'dense_units': 512, 'dropout_rate': 0.3, 'learning_rate': 1e-06, 'optimizer': 'sgd', 'activation': 'tanh', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_32 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_33 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_32[0][0]                   \n",
      "                                                                 input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 7, 7, 512)    4719104     concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 7, 7, 512)    0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 7, 7, 512)    2359808     dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 7, 7, 512)    0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 25088)        0           dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 2)            50178       flatten_21[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 27,153,474\n",
      "Trainable params: 14,208,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 42s 490ms/step - loss: 0.7341 - accuracy: 0.4818 - val_loss: 0.7019 - val_accuracy: 0.4777\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7350 - accuracy: 0.4894 - val_loss: 0.7012 - val_accuracy: 0.4816\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7380 - accuracy: 0.4829 - val_loss: 0.7015 - val_accuracy: 0.4777\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7312 - accuracy: 0.4879 - val_loss: 0.7009 - val_accuracy: 0.4855\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7324 - accuracy: 0.4968 - val_loss: 0.7006 - val_accuracy: 0.4922\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7361 - accuracy: 0.4842 - val_loss: 0.7007 - val_accuracy: 0.4900\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7294 - accuracy: 0.4933 - val_loss: 0.7003 - val_accuracy: 0.4933\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 487ms/step - loss: 0.7336 - accuracy: 0.4909 - val_loss: 0.6998 - val_accuracy: 0.4911\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7339 - accuracy: 0.4838 - val_loss: 0.6998 - val_accuracy: 0.4927\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7314 - accuracy: 0.4970 - val_loss: 0.6992 - val_accuracy: 0.4922\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 487ms/step - loss: 0.7324 - accuracy: 0.4907 - val_loss: 0.6994 - val_accuracy: 0.4911\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7302 - accuracy: 0.5016 - val_loss: 0.6993 - val_accuracy: 0.4922\n",
      "28/28 [==============================] - 9s 331ms/step - loss: 0.7014 - accuracy: 0.4788\n",
      "{'dense_units': 64, 'dropout_rate': 0.3, 'learning_rate': 1e-05, 'optimizer': 'adam', 'activation': 'sigmoid', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_35 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_35[0][0]                   \n",
      "                                                                 input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 7, 7, 64)     589888      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 7, 7, 64)     0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 7, 7, 64)     36928       dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 7, 7, 64)     0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 3136)         0           dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2)            6274        flatten_23[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,657,474\n",
      "Trainable params: 7,712,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7068 - accuracy: 0.5478 - val_loss: 0.6397 - val_accuracy: 0.7321\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5907 - accuracy: 0.7287 - val_loss: 0.5316 - val_accuracy: 0.7969\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.5140 - accuracy: 0.7938 - val_loss: 0.4783 - val_accuracy: 0.8136\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4695 - accuracy: 0.8115 - val_loss: 0.4408 - val_accuracy: 0.8253\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4313 - accuracy: 0.8274 - val_loss: 0.4145 - val_accuracy: 0.8331\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4167 - accuracy: 0.8296 - val_loss: 0.3997 - val_accuracy: 0.8348\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.3815 - accuracy: 0.8512 - val_loss: 0.3829 - val_accuracy: 0.8382\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.3750 - accuracy: 0.8507 - val_loss: 0.3680 - val_accuracy: 0.8471\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3501 - accuracy: 0.8618 - val_loss: 0.3587 - val_accuracy: 0.8477\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.3389 - accuracy: 0.8677 - val_loss: 0.3494 - val_accuracy: 0.8583\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3229 - accuracy: 0.8734 - val_loss: 0.3330 - val_accuracy: 0.8633\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3028 - accuracy: 0.8875 - val_loss: 0.3313 - val_accuracy: 0.8627\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.2800 - accuracy: 0.8956 - val_loss: 0.3254 - val_accuracy: 0.8655\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2778 - accuracy: 0.9011 - val_loss: 0.3004 - val_accuracy: 0.8789\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.2565 - accuracy: 0.9115 - val_loss: 0.3062 - val_accuracy: 0.8767\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.2257 - accuracy: 0.9240 - val_loss: 0.2923 - val_accuracy: 0.8811\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.2203 - accuracy: 0.9296 - val_loss: 0.2841 - val_accuracy: 0.8845\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.1965 - accuracy: 0.9383 - val_loss: 0.2828 - val_accuracy: 0.8789\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1818 - accuracy: 0.9475 - val_loss: 0.2828 - val_accuracy: 0.8795\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1592 - accuracy: 0.9547 - val_loss: 0.2584 - val_accuracy: 0.8912\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1434 - accuracy: 0.9621 - val_loss: 0.2564 - val_accuracy: 0.8929\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1292 - accuracy: 0.9684 - val_loss: 0.2630 - val_accuracy: 0.8917\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1170 - accuracy: 0.9730 - val_loss: 0.2585 - val_accuracy: 0.8923\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.1034 - accuracy: 0.9756 - val_loss: 0.2503 - val_accuracy: 0.8929\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0929 - accuracy: 0.9799 - val_loss: 0.2574 - val_accuracy: 0.8917\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0796 - accuracy: 0.9837 - val_loss: 0.2572 - val_accuracy: 0.8917\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.3031 - accuracy: 0.8823\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'dense_units': 64, 'dropout_rate': 0.3, 'learning_rate': 1e-05, 'optimizer': 'adam', 'activation': 'sigmoid', 'learning_rate_decay': 1e-05}\n",
      "Best Test Loss: 0.3030979037284851\n",
      "{'dense_units': 512, 'dropout_rate': 0.2, 'learning_rate': 1e-05, 'optimizer': 'rmsprop', 'activation': 'relu', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_38 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_39 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_38[0][0]                   \n",
      "                                                                 input_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 7, 7, 512)    4719104     concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 7, 7, 512)    0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 7, 7, 512)    2359808     dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 7, 7, 512)    0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 25088)        0           dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2)            50178       flatten_25[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 27,153,474\n",
      "Trainable params: 14,208,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 43s 495ms/step - loss: 0.5236 - accuracy: 0.7453 - val_loss: 0.4325 - val_accuracy: 0.8092\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3884 - accuracy: 0.8272 - val_loss: 0.4006 - val_accuracy: 0.8147\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3641 - accuracy: 0.8437 - val_loss: 0.3970 - val_accuracy: 0.8198\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3360 - accuracy: 0.8533 - val_loss: 0.3554 - val_accuracy: 0.8371\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3141 - accuracy: 0.8644 - val_loss: 0.3418 - val_accuracy: 0.8438\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.2755 - accuracy: 0.8913 - val_loss: 0.3328 - val_accuracy: 0.8555\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.2644 - accuracy: 0.8954 - val_loss: 0.3256 - val_accuracy: 0.8527\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.2483 - accuracy: 0.9033 - val_loss: 0.3090 - val_accuracy: 0.8571\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.2268 - accuracy: 0.9154 - val_loss: 0.2973 - val_accuracy: 0.8650\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.2033 - accuracy: 0.9276 - val_loss: 0.2992 - val_accuracy: 0.8689\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.1762 - accuracy: 0.9418 - val_loss: 0.2930 - val_accuracy: 0.8655\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.1684 - accuracy: 0.9446 - val_loss: 0.2651 - val_accuracy: 0.8839\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.1454 - accuracy: 0.9534 - val_loss: 0.2662 - val_accuracy: 0.8800\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.1289 - accuracy: 0.9614 - val_loss: 0.2695 - val_accuracy: 0.8761\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.1166 - accuracy: 0.9645 - val_loss: 0.2480 - val_accuracy: 0.8917\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0990 - accuracy: 0.9719 - val_loss: 0.2499 - val_accuracy: 0.8890\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0876 - accuracy: 0.9775 - val_loss: 0.2574 - val_accuracy: 0.8934\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0759 - accuracy: 0.9824 - val_loss: 0.2612 - val_accuracy: 0.8929\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0608 - accuracy: 0.9865 - val_loss: 0.2673 - val_accuracy: 0.8878\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.0548 - accuracy: 0.9874 - val_loss: 0.2522 - val_accuracy: 0.8940\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.0484 - accuracy: 0.9889 - val_loss: 0.2391 - val_accuracy: 0.9085\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0370 - accuracy: 0.9908 - val_loss: 0.2579 - val_accuracy: 0.9040\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0309 - accuracy: 0.9941 - val_loss: 0.2718 - val_accuracy: 0.9023\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0255 - accuracy: 0.9945 - val_loss: 0.2639 - val_accuracy: 0.9035\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0225 - accuracy: 0.9952 - val_loss: 0.2832 - val_accuracy: 0.9085\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 42s 493ms/step - loss: 0.0194 - accuracy: 0.9961 - val_loss: 0.2874 - val_accuracy: 0.9046\n",
      "28/28 [==============================] - 9s 331ms/step - loss: 0.4231 - accuracy: 0.8856\n",
      "{'dense_units': 64, 'dropout_rate': 0.6, 'learning_rate': 0.0001, 'optimizer': 'adam', 'activation': 'relu', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_41 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_42 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_41[0][0]                   \n",
      "                                                                 input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 64)     589888      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 7, 7, 64)     0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 7, 7, 64)     36928       dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 7, 7, 64)     0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)            (None, 3136)         0           dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 2)            6274        flatten_27[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,657,474\n",
      "Trainable params: 7,712,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5841 - accuracy: 0.6983 - val_loss: 0.4022 - val_accuracy: 0.8181\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 40s 479ms/step - loss: 0.4060 - accuracy: 0.8268 - val_loss: 0.3588 - val_accuracy: 0.8298\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3573 - accuracy: 0.8534 - val_loss: 0.3315 - val_accuracy: 0.8521\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3068 - accuracy: 0.8740 - val_loss: 0.3215 - val_accuracy: 0.8627\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2525 - accuracy: 0.9052 - val_loss: 0.3102 - val_accuracy: 0.8677\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2116 - accuracy: 0.9215 - val_loss: 0.2759 - val_accuracy: 0.8873\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1687 - accuracy: 0.9396 - val_loss: 0.2693 - val_accuracy: 0.8901\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1342 - accuracy: 0.9527 - val_loss: 0.2608 - val_accuracy: 0.9040\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.1069 - accuracy: 0.9627 - val_loss: 0.3011 - val_accuracy: 0.8940\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0798 - accuracy: 0.9730 - val_loss: 0.3142 - val_accuracy: 0.9001\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0608 - accuracy: 0.9806 - val_loss: 0.3244 - val_accuracy: 0.9040\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0613 - accuracy: 0.9789 - val_loss: 0.3216 - val_accuracy: 0.9046\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0402 - accuracy: 0.9858 - val_loss: 0.3720 - val_accuracy: 0.9023\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0485 - accuracy: 0.9830 - val_loss: 0.3908 - val_accuracy: 0.8940\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0386 - accuracy: 0.9871 - val_loss: 0.5205 - val_accuracy: 0.8783\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0466 - accuracy: 0.9860 - val_loss: 0.3583 - val_accuracy: 0.8973\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 0.4626 - val_accuracy: 0.9096\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0287 - accuracy: 0.9922 - val_loss: 0.4902 - val_accuracy: 0.9046\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0253 - accuracy: 0.9911 - val_loss: 0.3902 - val_accuracy: 0.9096\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0249 - accuracy: 0.9919 - val_loss: 0.4359 - val_accuracy: 0.9135\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0166 - accuracy: 0.9965 - val_loss: 0.4200 - val_accuracy: 0.9102\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0152 - accuracy: 0.9961 - val_loss: 0.4699 - val_accuracy: 0.9129\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.4288 - val_accuracy: 0.9040\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.5270 - val_accuracy: 0.9051\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0206 - accuracy: 0.9946 - val_loss: 0.4858 - val_accuracy: 0.9035\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.5871 - accuracy: 0.8867\n",
      "{'dense_units': 32, 'dropout_rate': 0.6, 'learning_rate': 1e-06, 'optimizer': 'adam', 'activation': 'tanh', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_44 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_45 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_44[0][0]                   \n",
      "                                                                 input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 7, 7, 32)     294944      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 7, 7, 32)     0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 32)     9248        dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 7, 7, 32)     0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 1568)         0           dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 2)            3138        flatten_29[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,331,714\n",
      "Trainable params: 7,386,754\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.8345 - accuracy: 0.5008 - val_loss: 0.6868 - val_accuracy: 0.5508\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.8155 - accuracy: 0.5117 - val_loss: 0.6751 - val_accuracy: 0.6138\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7944 - accuracy: 0.5322 - val_loss: 0.6630 - val_accuracy: 0.6641\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7760 - accuracy: 0.5522 - val_loss: 0.6494 - val_accuracy: 0.7026\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7746 - accuracy: 0.5529 - val_loss: 0.6384 - val_accuracy: 0.7215\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7300 - accuracy: 0.5993 - val_loss: 0.6236 - val_accuracy: 0.7349\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7185 - accuracy: 0.6093 - val_loss: 0.6083 - val_accuracy: 0.7511\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.6891 - accuracy: 0.6400 - val_loss: 0.5922 - val_accuracy: 0.7533\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.6640 - accuracy: 0.6603 - val_loss: 0.5779 - val_accuracy: 0.7617\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.6396 - accuracy: 0.6892 - val_loss: 0.5654 - val_accuracy: 0.7628\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.6193 - accuracy: 0.7032 - val_loss: 0.5521 - val_accuracy: 0.7662\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.6062 - accuracy: 0.7097 - val_loss: 0.5404 - val_accuracy: 0.7673\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5949 - accuracy: 0.7154 - val_loss: 0.5309 - val_accuracy: 0.7695\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.5732 - accuracy: 0.7470 - val_loss: 0.5217 - val_accuracy: 0.7746\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.5695 - accuracy: 0.7461 - val_loss: 0.5132 - val_accuracy: 0.7757\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5597 - accuracy: 0.7494 - val_loss: 0.5052 - val_accuracy: 0.7807\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5535 - accuracy: 0.7525 - val_loss: 0.5004 - val_accuracy: 0.7818\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5476 - accuracy: 0.7551 - val_loss: 0.4930 - val_accuracy: 0.7852\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5367 - accuracy: 0.7651 - val_loss: 0.4884 - val_accuracy: 0.7902\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5356 - accuracy: 0.7634 - val_loss: 0.4835 - val_accuracy: 0.7919\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5207 - accuracy: 0.7731 - val_loss: 0.4770 - val_accuracy: 0.7935\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.5261 - accuracy: 0.7740 - val_loss: 0.4733 - val_accuracy: 0.7958\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5113 - accuracy: 0.7729 - val_loss: 0.4691 - val_accuracy: 0.7980\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5110 - accuracy: 0.7797 - val_loss: 0.4650 - val_accuracy: 0.8002\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5038 - accuracy: 0.7821 - val_loss: 0.4607 - val_accuracy: 0.7985\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5078 - accuracy: 0.7792 - val_loss: 0.4582 - val_accuracy: 0.7980\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5031 - accuracy: 0.7838 - val_loss: 0.4555 - val_accuracy: 0.8052\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4824 - accuracy: 0.8013 - val_loss: 0.4522 - val_accuracy: 0.8002\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4932 - accuracy: 0.7912 - val_loss: 0.4462 - val_accuracy: 0.8047\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4850 - accuracy: 0.7954 - val_loss: 0.4458 - val_accuracy: 0.8036\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4825 - accuracy: 0.7932 - val_loss: 0.4416 - val_accuracy: 0.8047\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4788 - accuracy: 0.7917 - val_loss: 0.4406 - val_accuracy: 0.8052\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.4360 - accuracy: 0.8064\n",
      "{'dense_units': 32, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'optimizer': 'rmsprop', 'activation': 'tanh', 'learning_rate_decay': 0.001}\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_47 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_48 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_47[0][0]                   \n",
      "                                                                 input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 32)     294944      concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 7, 7, 32)     0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 32)     9248        dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 7, 7, 32)     0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 1568)         0           dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 2)            3138        flatten_31[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,331,714\n",
      "Trainable params: 7,386,754\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4577 - accuracy: 0.7921 - val_loss: 0.3820 - val_accuracy: 0.8315\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.3539 - accuracy: 0.8498 - val_loss: 0.3485 - val_accuracy: 0.8465\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.3201 - accuracy: 0.8688 - val_loss: 0.3130 - val_accuracy: 0.8767\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.2516 - accuracy: 0.9052 - val_loss: 0.2965 - val_accuracy: 0.8683\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.1976 - accuracy: 0.9338 - val_loss: 0.2688 - val_accuracy: 0.8901\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1576 - accuracy: 0.9436 - val_loss: 0.2631 - val_accuracy: 0.8984\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1197 - accuracy: 0.9614 - val_loss: 0.2731 - val_accuracy: 0.8917\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0826 - accuracy: 0.9795 - val_loss: 0.2424 - val_accuracy: 0.9096\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0591 - accuracy: 0.9823 - val_loss: 0.2523 - val_accuracy: 0.9062\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0436 - accuracy: 0.9871 - val_loss: 0.2333 - val_accuracy: 0.9208\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0358 - accuracy: 0.9898 - val_loss: 0.2848 - val_accuracy: 0.8940\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0274 - accuracy: 0.9926 - val_loss: 0.2529 - val_accuracy: 0.9090\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0158 - accuracy: 0.9965 - val_loss: 0.2811 - val_accuracy: 0.9102\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0167 - accuracy: 0.9961 - val_loss: 0.2832 - val_accuracy: 0.9102\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0102 - accuracy: 0.9980 - val_loss: 0.3254 - val_accuracy: 0.9096\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.4474 - accuracy: 0.8951\n",
      "{'dense_units': 32, 'dropout_rate': 0.2, 'learning_rate': 0.0001, 'optimizer': 'sgd', 'activation': 'sigmoid', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_50 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_51 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_50[0][0]                   \n",
      "                                                                 input_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 32)     294944      concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 7, 7, 32)     0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 32)     9248        dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 7, 7, 32)     0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 1568)         0           dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 2)            3138        flatten_33[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,331,714\n",
      "Trainable params: 7,386,754\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7525 - accuracy: 0.4840 - val_loss: 0.7190 - val_accuracy: 0.4766\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7242 - accuracy: 0.4938 - val_loss: 0.7036 - val_accuracy: 0.4715\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7162 - accuracy: 0.4979 - val_loss: 0.6975 - val_accuracy: 0.4754\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7133 - accuracy: 0.5029 - val_loss: 0.6943 - val_accuracy: 0.4732\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7105 - accuracy: 0.5084 - val_loss: 0.6928 - val_accuracy: 0.5240\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7105 - accuracy: 0.5014 - val_loss: 0.6920 - val_accuracy: 0.5324\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7107 - accuracy: 0.4920 - val_loss: 0.6917 - val_accuracy: 0.5251\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7076 - accuracy: 0.5099 - val_loss: 0.6916 - val_accuracy: 0.5234\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7068 - accuracy: 0.5108 - val_loss: 0.6912 - val_accuracy: 0.5257\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7090 - accuracy: 0.5097 - val_loss: 0.6912 - val_accuracy: 0.5273\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7106 - accuracy: 0.5058 - val_loss: 0.6913 - val_accuracy: 0.5251\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.6928 - accuracy: 0.5017\n",
      "{'dense_units': 64, 'dropout_rate': 0.5, 'learning_rate': 1e-05, 'optimizer': 'sgd', 'activation': 'relu', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_53 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_54 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_53[0][0]                   \n",
      "                                                                 input_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 64)     589888      concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 7, 7, 64)     0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 64)     36928       dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 7, 7, 64)     0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 3136)         0           dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 2)            6274        flatten_35[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,657,474\n",
      "Trainable params: 7,712,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.7597 - accuracy: 0.5055 - val_loss: 0.6977 - val_accuracy: 0.5257\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7566 - accuracy: 0.5088 - val_loss: 0.6966 - val_accuracy: 0.5257\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7568 - accuracy: 0.5019 - val_loss: 0.6949 - val_accuracy: 0.5273\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7483 - accuracy: 0.5055 - val_loss: 0.6940 - val_accuracy: 0.5290\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7464 - accuracy: 0.5025 - val_loss: 0.6939 - val_accuracy: 0.5257\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7440 - accuracy: 0.5147 - val_loss: 0.6932 - val_accuracy: 0.5268\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7435 - accuracy: 0.5169 - val_loss: 0.6916 - val_accuracy: 0.5296\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7445 - accuracy: 0.5063 - val_loss: 0.6921 - val_accuracy: 0.5279\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7458 - accuracy: 0.5040 - val_loss: 0.6913 - val_accuracy: 0.5290\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7438 - accuracy: 0.4953 - val_loss: 0.6905 - val_accuracy: 0.5290\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7435 - accuracy: 0.5030 - val_loss: 0.6901 - val_accuracy: 0.5318\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7435 - accuracy: 0.5023 - val_loss: 0.6902 - val_accuracy: 0.5285\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7411 - accuracy: 0.5067 - val_loss: 0.6894 - val_accuracy: 0.5312\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7379 - accuracy: 0.5071 - val_loss: 0.6893 - val_accuracy: 0.5340\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7393 - accuracy: 0.5027 - val_loss: 0.6890 - val_accuracy: 0.5335\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7389 - accuracy: 0.5025 - val_loss: 0.6885 - val_accuracy: 0.5368\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7388 - accuracy: 0.4992 - val_loss: 0.6885 - val_accuracy: 0.5324\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7295 - accuracy: 0.5147 - val_loss: 0.6880 - val_accuracy: 0.5363\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7320 - accuracy: 0.5103 - val_loss: 0.6881 - val_accuracy: 0.5363\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7313 - accuracy: 0.5134 - val_loss: 0.6879 - val_accuracy: 0.5374\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7318 - accuracy: 0.4999 - val_loss: 0.6873 - val_accuracy: 0.5396\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7317 - accuracy: 0.5090 - val_loss: 0.6877 - val_accuracy: 0.5407\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7266 - accuracy: 0.5106 - val_loss: 0.6872 - val_accuracy: 0.5430\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7307 - accuracy: 0.5095 - val_loss: 0.6873 - val_accuracy: 0.5407\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7308 - accuracy: 0.5016 - val_loss: 0.6870 - val_accuracy: 0.5480\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7254 - accuracy: 0.5104 - val_loss: 0.6868 - val_accuracy: 0.5502\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7304 - accuracy: 0.4970 - val_loss: 0.6863 - val_accuracy: 0.5519\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7224 - accuracy: 0.5184 - val_loss: 0.6862 - val_accuracy: 0.5525\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7235 - accuracy: 0.5191 - val_loss: 0.6863 - val_accuracy: 0.5536\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7221 - accuracy: 0.5147 - val_loss: 0.6859 - val_accuracy: 0.5569\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7285 - accuracy: 0.4964 - val_loss: 0.6864 - val_accuracy: 0.5558\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7228 - accuracy: 0.5125 - val_loss: 0.6859 - val_accuracy: 0.5580\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7217 - accuracy: 0.5154 - val_loss: 0.6859 - val_accuracy: 0.5552\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7248 - accuracy: 0.5112 - val_loss: 0.6856 - val_accuracy: 0.5625\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7210 - accuracy: 0.5184 - val_loss: 0.6855 - val_accuracy: 0.5625\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7138 - accuracy: 0.5282 - val_loss: 0.6854 - val_accuracy: 0.5642\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7218 - accuracy: 0.5171 - val_loss: 0.6849 - val_accuracy: 0.5686\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7213 - accuracy: 0.5099 - val_loss: 0.6851 - val_accuracy: 0.5681\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7187 - accuracy: 0.5236 - val_loss: 0.6849 - val_accuracy: 0.5686\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7203 - accuracy: 0.5117 - val_loss: 0.6847 - val_accuracy: 0.5698\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7169 - accuracy: 0.5217 - val_loss: 0.6848 - val_accuracy: 0.5686\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7178 - accuracy: 0.5106 - val_loss: 0.6845 - val_accuracy: 0.5720\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7133 - accuracy: 0.5228 - val_loss: 0.6844 - val_accuracy: 0.5720\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7158 - accuracy: 0.5208 - val_loss: 0.6845 - val_accuracy: 0.5714\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7121 - accuracy: 0.5212 - val_loss: 0.6849 - val_accuracy: 0.5703\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7136 - accuracy: 0.5169 - val_loss: 0.6845 - val_accuracy: 0.5714\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7125 - accuracy: 0.5241 - val_loss: 0.6842 - val_accuracy: 0.5720\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.6887 - accuracy: 0.5469\n",
      "{'dense_units': 128, 'dropout_rate': 0.3, 'learning_rate': 0.0001, 'optimizer': 'rmsprop', 'activation': 'sigmoid', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_56 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_57 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_56[0][0]                   \n",
      "                                                                 input_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    1179776     concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 7, 7, 128)    0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    147584      dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 7, 7, 128)    0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)            (None, 6272)         0           dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 2)            12546       flatten_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,364,290\n",
      "Trainable params: 8,419,330\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4601 - accuracy: 0.7880 - val_loss: 0.3888 - val_accuracy: 0.8270\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.3614 - accuracy: 0.8416 - val_loss: 0.3514 - val_accuracy: 0.8454\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.3272 - accuracy: 0.8669 - val_loss: 0.3202 - val_accuracy: 0.8583\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.2760 - accuracy: 0.8910 - val_loss: 0.3153 - val_accuracy: 0.8650\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.2445 - accuracy: 0.9046 - val_loss: 0.3383 - val_accuracy: 0.8650\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.1926 - accuracy: 0.9270 - val_loss: 0.3193 - val_accuracy: 0.8750\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.1600 - accuracy: 0.9451 - val_loss: 0.3303 - val_accuracy: 0.8744\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.1263 - accuracy: 0.9606 - val_loss: 0.2923 - val_accuracy: 0.8878\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.1151 - accuracy: 0.9673 - val_loss: 0.3507 - val_accuracy: 0.8806\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.1010 - accuracy: 0.9701 - val_loss: 0.3229 - val_accuracy: 0.8873\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.0766 - accuracy: 0.9743 - val_loss: 0.4103 - val_accuracy: 0.8443\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.0782 - accuracy: 0.9782 - val_loss: 0.3618 - val_accuracy: 0.8828\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.0628 - accuracy: 0.9830 - val_loss: 0.3366 - val_accuracy: 0.9057\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.0525 - accuracy: 0.9819 - val_loss: 0.3497 - val_accuracy: 0.8923\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.0535 - accuracy: 0.9821 - val_loss: 0.4001 - val_accuracy: 0.8811\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.0515 - accuracy: 0.9850 - val_loss: 0.3468 - val_accuracy: 0.9012\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.0454 - accuracy: 0.9861 - val_loss: 0.3847 - val_accuracy: 0.8856\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.0310 - accuracy: 0.9898 - val_loss: 0.3860 - val_accuracy: 0.8956\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.4660 - accuracy: 0.8895\n",
      "{'dense_units': 32, 'dropout_rate': 0.3, 'learning_rate': 1e-06, 'optimizer': 'rmsprop', 'activation': 'relu', 'learning_rate_decay': 0.001}\n",
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_59 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_60 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_59[0][0]                   \n",
      "                                                                 input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 32)     294944      concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 7, 7, 32)     0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 32)     9248        dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 7, 7, 32)     0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)            (None, 1568)         0           dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 2)            3138        flatten_39[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,331,714\n",
      "Trainable params: 7,386,754\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7293 - accuracy: 0.5090 - val_loss: 0.6925 - val_accuracy: 0.4939\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.7095 - accuracy: 0.5271 - val_loss: 0.6806 - val_accuracy: 0.5831\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6950 - accuracy: 0.5618 - val_loss: 0.6698 - val_accuracy: 0.6775\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6853 - accuracy: 0.5762 - val_loss: 0.6619 - val_accuracy: 0.6936\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6741 - accuracy: 0.6086 - val_loss: 0.6536 - val_accuracy: 0.7104\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6657 - accuracy: 0.6280 - val_loss: 0.6466 - val_accuracy: 0.7204\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6560 - accuracy: 0.6439 - val_loss: 0.6382 - val_accuracy: 0.7288\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6465 - accuracy: 0.6686 - val_loss: 0.6312 - val_accuracy: 0.7321\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6358 - accuracy: 0.6842 - val_loss: 0.6224 - val_accuracy: 0.7360\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6276 - accuracy: 0.6943 - val_loss: 0.6146 - val_accuracy: 0.7416\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6195 - accuracy: 0.7071 - val_loss: 0.6073 - val_accuracy: 0.7439\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6122 - accuracy: 0.7182 - val_loss: 0.6002 - val_accuracy: 0.7461\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6061 - accuracy: 0.7100 - val_loss: 0.5924 - val_accuracy: 0.7506\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5961 - accuracy: 0.7302 - val_loss: 0.5854 - val_accuracy: 0.7545\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5915 - accuracy: 0.7304 - val_loss: 0.5792 - val_accuracy: 0.7595\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5821 - accuracy: 0.7398 - val_loss: 0.5729 - val_accuracy: 0.7617\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5768 - accuracy: 0.7500 - val_loss: 0.5662 - val_accuracy: 0.7612\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5704 - accuracy: 0.7514 - val_loss: 0.5600 - val_accuracy: 0.7645\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5637 - accuracy: 0.7609 - val_loss: 0.5552 - val_accuracy: 0.7640\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5608 - accuracy: 0.7505 - val_loss: 0.5496 - val_accuracy: 0.7651\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5494 - accuracy: 0.7675 - val_loss: 0.5455 - val_accuracy: 0.7673\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5512 - accuracy: 0.7599 - val_loss: 0.5412 - val_accuracy: 0.7673\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5445 - accuracy: 0.7686 - val_loss: 0.5363 - val_accuracy: 0.7695\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5453 - accuracy: 0.7638 - val_loss: 0.5326 - val_accuracy: 0.7695\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5336 - accuracy: 0.7699 - val_loss: 0.5274 - val_accuracy: 0.7712\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5365 - accuracy: 0.7638 - val_loss: 0.5255 - val_accuracy: 0.7690\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5319 - accuracy: 0.7607 - val_loss: 0.5221 - val_accuracy: 0.7712\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5291 - accuracy: 0.7682 - val_loss: 0.5198 - val_accuracy: 0.7723\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5228 - accuracy: 0.7793 - val_loss: 0.5138 - val_accuracy: 0.7757\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5186 - accuracy: 0.7738 - val_loss: 0.5133 - val_accuracy: 0.7751\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5203 - accuracy: 0.7711 - val_loss: 0.5095 - val_accuracy: 0.7779\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5117 - accuracy: 0.7821 - val_loss: 0.5076 - val_accuracy: 0.7790\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5117 - accuracy: 0.7782 - val_loss: 0.5053 - val_accuracy: 0.7785\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5079 - accuracy: 0.7803 - val_loss: 0.5008 - val_accuracy: 0.7818\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5021 - accuracy: 0.7858 - val_loss: 0.4998 - val_accuracy: 0.7818\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5072 - accuracy: 0.7736 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5011 - accuracy: 0.7841 - val_loss: 0.4963 - val_accuracy: 0.7812\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4982 - accuracy: 0.7849 - val_loss: 0.4951 - val_accuracy: 0.7812\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4990 - accuracy: 0.7834 - val_loss: 0.4925 - val_accuracy: 0.7818\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.4724 - accuracy: 0.8041\n",
      "{'dense_units': 128, 'dropout_rate': 0.2, 'learning_rate': 0.0001, 'optimizer': 'sgd', 'activation': 'tanh', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_62 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_63 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_62[0][0]                   \n",
      "                                                                 input_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 128)    1179776     concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 7, 7, 128)    0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 128)    147584      dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 7, 7, 128)    0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)            (None, 6272)         0           dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 2)            12546       flatten_41[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,364,290\n",
      "Trainable params: 8,419,330\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7123 - accuracy: 0.5387 - val_loss: 0.6837 - val_accuracy: 0.5586\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6942 - accuracy: 0.5644 - val_loss: 0.6770 - val_accuracy: 0.5982\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6879 - accuracy: 0.5773 - val_loss: 0.6705 - val_accuracy: 0.6200\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6778 - accuracy: 0.5975 - val_loss: 0.6646 - val_accuracy: 0.6395\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6701 - accuracy: 0.6160 - val_loss: 0.6578 - val_accuracy: 0.6462\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6597 - accuracy: 0.6391 - val_loss: 0.6514 - val_accuracy: 0.6735\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6585 - accuracy: 0.6361 - val_loss: 0.6447 - val_accuracy: 0.6775\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6510 - accuracy: 0.6503 - val_loss: 0.6384 - val_accuracy: 0.6869\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6401 - accuracy: 0.6720 - val_loss: 0.6319 - val_accuracy: 0.7031\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6336 - accuracy: 0.6864 - val_loss: 0.6238 - val_accuracy: 0.7104\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6262 - accuracy: 0.6930 - val_loss: 0.6165 - val_accuracy: 0.7199\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.6157 - accuracy: 0.7069 - val_loss: 0.6109 - val_accuracy: 0.7310\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6084 - accuracy: 0.7191 - val_loss: 0.6023 - val_accuracy: 0.7277\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5944 - accuracy: 0.7317 - val_loss: 0.5931 - val_accuracy: 0.7355\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5918 - accuracy: 0.7315 - val_loss: 0.5864 - val_accuracy: 0.7450\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5797 - accuracy: 0.7418 - val_loss: 0.5795 - val_accuracy: 0.7483\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5724 - accuracy: 0.7418 - val_loss: 0.5705 - val_accuracy: 0.7545\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.5668 - accuracy: 0.7466 - val_loss: 0.5637 - val_accuracy: 0.7573\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5546 - accuracy: 0.7557 - val_loss: 0.5568 - val_accuracy: 0.7606\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5424 - accuracy: 0.7610 - val_loss: 0.5493 - val_accuracy: 0.7662\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5394 - accuracy: 0.7590 - val_loss: 0.5417 - val_accuracy: 0.7690\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5232 - accuracy: 0.7710 - val_loss: 0.5364 - val_accuracy: 0.7667\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5231 - accuracy: 0.7655 - val_loss: 0.5290 - val_accuracy: 0.7701\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5138 - accuracy: 0.7731 - val_loss: 0.5219 - val_accuracy: 0.7740\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5107 - accuracy: 0.7729 - val_loss: 0.5157 - val_accuracy: 0.7762\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5005 - accuracy: 0.7797 - val_loss: 0.5112 - val_accuracy: 0.7762\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4920 - accuracy: 0.7897 - val_loss: 0.5042 - val_accuracy: 0.7824\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4869 - accuracy: 0.7838 - val_loss: 0.5011 - val_accuracy: 0.7773\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4836 - accuracy: 0.7779 - val_loss: 0.4972 - val_accuracy: 0.7790\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4791 - accuracy: 0.7910 - val_loss: 0.4911 - val_accuracy: 0.7868\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4706 - accuracy: 0.7884 - val_loss: 0.4861 - val_accuracy: 0.7863\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4718 - accuracy: 0.7908 - val_loss: 0.4860 - val_accuracy: 0.7829\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4688 - accuracy: 0.7919 - val_loss: 0.4812 - val_accuracy: 0.7868\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4659 - accuracy: 0.7841 - val_loss: 0.4778 - val_accuracy: 0.7868\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4568 - accuracy: 0.7949 - val_loss: 0.4750 - val_accuracy: 0.7857\n",
      "28/28 [==============================] - 9s 329ms/step - loss: 0.4584 - accuracy: 0.7896\n",
      "{'dense_units': 256, 'dropout_rate': 0.5, 'learning_rate': 1e-06, 'optimizer': 'adam', 'activation': 'relu', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_65 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_66 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_65[0][0]                   \n",
      "                                                                 input_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 256)    2359552     concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 7, 7, 256)    0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 256)    590080      dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 7, 7, 256)    0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_43 (Flatten)            (None, 12544)        0           dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 2)            25090       flatten_43[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,999,106\n",
      "Trainable params: 10,054,146\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 484ms/step - loss: 0.7535 - accuracy: 0.4999 - val_loss: 0.6858 - val_accuracy: 0.5776\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7242 - accuracy: 0.5363 - val_loss: 0.6750 - val_accuracy: 0.6417\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7129 - accuracy: 0.5470 - val_loss: 0.6650 - val_accuracy: 0.7042\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.6977 - accuracy: 0.5716 - val_loss: 0.6528 - val_accuracy: 0.7360\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.6865 - accuracy: 0.6017 - val_loss: 0.6380 - val_accuracy: 0.7528\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.6643 - accuracy: 0.6361 - val_loss: 0.6202 - val_accuracy: 0.7567\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.6388 - accuracy: 0.6742 - val_loss: 0.5976 - val_accuracy: 0.7511\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.6233 - accuracy: 0.6831 - val_loss: 0.5720 - val_accuracy: 0.7734\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.5817 - accuracy: 0.7361 - val_loss: 0.5463 - val_accuracy: 0.7746\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.5574 - accuracy: 0.7474 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.5275 - accuracy: 0.7686 - val_loss: 0.4978 - val_accuracy: 0.7868\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.5136 - accuracy: 0.7646 - val_loss: 0.4794 - val_accuracy: 0.7924\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.4885 - accuracy: 0.7878 - val_loss: 0.4646 - val_accuracy: 0.7963\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.4683 - accuracy: 0.7971 - val_loss: 0.4544 - val_accuracy: 0.8013\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4621 - accuracy: 0.7943 - val_loss: 0.4480 - val_accuracy: 0.8008\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.4573 - accuracy: 0.7991 - val_loss: 0.4392 - val_accuracy: 0.8041\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4553 - accuracy: 0.8030 - val_loss: 0.4329 - val_accuracy: 0.8058\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4274 - accuracy: 0.8185 - val_loss: 0.4298 - val_accuracy: 0.8036\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4411 - accuracy: 0.8011 - val_loss: 0.4253 - val_accuracy: 0.8092\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4288 - accuracy: 0.8146 - val_loss: 0.4233 - val_accuracy: 0.8125\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.4206 - accuracy: 0.8228 - val_loss: 0.4188 - val_accuracy: 0.8119\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.4283 - accuracy: 0.8076 - val_loss: 0.4163 - val_accuracy: 0.8119\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4129 - accuracy: 0.8224 - val_loss: 0.4146 - val_accuracy: 0.8086\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4186 - accuracy: 0.8148 - val_loss: 0.4127 - val_accuracy: 0.8103\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4104 - accuracy: 0.8228 - val_loss: 0.4086 - val_accuracy: 0.8153\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4027 - accuracy: 0.8255 - val_loss: 0.4058 - val_accuracy: 0.8136\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.4089 - accuracy: 0.8231 - val_loss: 0.4018 - val_accuracy: 0.8147\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3983 - accuracy: 0.8305 - val_loss: 0.4014 - val_accuracy: 0.8147\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4002 - accuracy: 0.8259 - val_loss: 0.3972 - val_accuracy: 0.8186\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3900 - accuracy: 0.8313 - val_loss: 0.3967 - val_accuracy: 0.8175\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3901 - accuracy: 0.8322 - val_loss: 0.3969 - val_accuracy: 0.8164\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3923 - accuracy: 0.8307 - val_loss: 0.3934 - val_accuracy: 0.8186\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3869 - accuracy: 0.8311 - val_loss: 0.3955 - val_accuracy: 0.8170\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3824 - accuracy: 0.8381 - val_loss: 0.3883 - val_accuracy: 0.8225\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3828 - accuracy: 0.8337 - val_loss: 0.3909 - val_accuracy: 0.8186\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3805 - accuracy: 0.8342 - val_loss: 0.3869 - val_accuracy: 0.8231\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3818 - accuracy: 0.8379 - val_loss: 0.3856 - val_accuracy: 0.8231\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3738 - accuracy: 0.8409 - val_loss: 0.3846 - val_accuracy: 0.8237\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.3739 - accuracy: 0.8392 - val_loss: 0.3852 - val_accuracy: 0.8237\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.3769 - accuracy: 0.8390 - val_loss: 0.3800 - val_accuracy: 0.8265\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.3691 - accuracy: 0.8440 - val_loss: 0.3772 - val_accuracy: 0.8281\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3701 - accuracy: 0.8461 - val_loss: 0.3809 - val_accuracy: 0.8276\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3706 - accuracy: 0.8435 - val_loss: 0.3746 - val_accuracy: 0.8292\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3657 - accuracy: 0.8444 - val_loss: 0.3785 - val_accuracy: 0.8270\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3629 - accuracy: 0.8441 - val_loss: 0.3764 - val_accuracy: 0.8270\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3631 - accuracy: 0.8449 - val_loss: 0.3764 - val_accuracy: 0.8292\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3664 - accuracy: 0.8472 - val_loss: 0.3731 - val_accuracy: 0.8304\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3543 - accuracy: 0.8505 - val_loss: 0.3694 - val_accuracy: 0.8331\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3579 - accuracy: 0.8483 - val_loss: 0.3689 - val_accuracy: 0.8331\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3594 - accuracy: 0.8490 - val_loss: 0.3697 - val_accuracy: 0.8337\n",
      "28/28 [==============================] - 9s 329ms/step - loss: 0.3875 - accuracy: 0.8259\n",
      "{'dense_units': 256, 'dropout_rate': 0.3, 'learning_rate': 1e-06, 'optimizer': 'sgd', 'activation': 'relu', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_68 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_69 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_68[0][0]                   \n",
      "                                                                 input_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 256)    2359552     concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 7, 7, 256)    0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 256)    590080      dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 7, 7, 256)    0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_45 (Flatten)            (None, 12544)        0           dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 2)            25090       flatten_45[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,999,106\n",
      "Trainable params: 10,054,146\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.7153 - accuracy: 0.5134 - val_loss: 0.6975 - val_accuracy: 0.4827\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7129 - accuracy: 0.5095 - val_loss: 0.6970 - val_accuracy: 0.4872\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7154 - accuracy: 0.5125 - val_loss: 0.6969 - val_accuracy: 0.4905\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7151 - accuracy: 0.5021 - val_loss: 0.6966 - val_accuracy: 0.4888\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7113 - accuracy: 0.5202 - val_loss: 0.6963 - val_accuracy: 0.4883\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7171 - accuracy: 0.5029 - val_loss: 0.6957 - val_accuracy: 0.4916\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7123 - accuracy: 0.5138 - val_loss: 0.6957 - val_accuracy: 0.4894\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7147 - accuracy: 0.5134 - val_loss: 0.6960 - val_accuracy: 0.4888\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7108 - accuracy: 0.5289 - val_loss: 0.6958 - val_accuracy: 0.4916\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7133 - accuracy: 0.5162 - val_loss: 0.6955 - val_accuracy: 0.4961\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7148 - accuracy: 0.5049 - val_loss: 0.6955 - val_accuracy: 0.4950\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7145 - accuracy: 0.5097 - val_loss: 0.6953 - val_accuracy: 0.4939\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7132 - accuracy: 0.5108 - val_loss: 0.6951 - val_accuracy: 0.4939\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7176 - accuracy: 0.5001 - val_loss: 0.6949 - val_accuracy: 0.4972\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7138 - accuracy: 0.5127 - val_loss: 0.6949 - val_accuracy: 0.4978\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7118 - accuracy: 0.5158 - val_loss: 0.6949 - val_accuracy: 0.4983\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7140 - accuracy: 0.5141 - val_loss: 0.6946 - val_accuracy: 0.4978\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7132 - accuracy: 0.5149 - val_loss: 0.6944 - val_accuracy: 0.4989\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7109 - accuracy: 0.5189 - val_loss: 0.6946 - val_accuracy: 0.4967\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7135 - accuracy: 0.5136 - val_loss: 0.6943 - val_accuracy: 0.4989\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7165 - accuracy: 0.5053 - val_loss: 0.6943 - val_accuracy: 0.5000\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7132 - accuracy: 0.5241 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7127 - accuracy: 0.5158 - val_loss: 0.6939 - val_accuracy: 0.5006\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7135 - accuracy: 0.5152 - val_loss: 0.6937 - val_accuracy: 0.5045\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7150 - accuracy: 0.5088 - val_loss: 0.6935 - val_accuracy: 0.5006\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7133 - accuracy: 0.5130 - val_loss: 0.6935 - val_accuracy: 0.5033\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7100 - accuracy: 0.5173 - val_loss: 0.6938 - val_accuracy: 0.5039\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7105 - accuracy: 0.5195 - val_loss: 0.6933 - val_accuracy: 0.5089\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7099 - accuracy: 0.5186 - val_loss: 0.6933 - val_accuracy: 0.5067\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7118 - accuracy: 0.5119 - val_loss: 0.6933 - val_accuracy: 0.5095\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7124 - accuracy: 0.5099 - val_loss: 0.6932 - val_accuracy: 0.5095\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7111 - accuracy: 0.5154 - val_loss: 0.6930 - val_accuracy: 0.5123\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7086 - accuracy: 0.5337 - val_loss: 0.6933 - val_accuracy: 0.5084\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7117 - accuracy: 0.5071 - val_loss: 0.6930 - val_accuracy: 0.5145\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7128 - accuracy: 0.5184 - val_loss: 0.6930 - val_accuracy: 0.5167\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7150 - accuracy: 0.5047 - val_loss: 0.6928 - val_accuracy: 0.5206\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7152 - accuracy: 0.5093 - val_loss: 0.6931 - val_accuracy: 0.5162\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7094 - accuracy: 0.5352 - val_loss: 0.6926 - val_accuracy: 0.5234\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7149 - accuracy: 0.5069 - val_loss: 0.6926 - val_accuracy: 0.5246\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7094 - accuracy: 0.5213 - val_loss: 0.6924 - val_accuracy: 0.5257\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7092 - accuracy: 0.5267 - val_loss: 0.6927 - val_accuracy: 0.5246\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7118 - accuracy: 0.5132 - val_loss: 0.6924 - val_accuracy: 0.5285\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7074 - accuracy: 0.5284 - val_loss: 0.6924 - val_accuracy: 0.5296\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7112 - accuracy: 0.5188 - val_loss: 0.6922 - val_accuracy: 0.5279\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7084 - accuracy: 0.5243 - val_loss: 0.6923 - val_accuracy: 0.5285\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7071 - accuracy: 0.5276 - val_loss: 0.6919 - val_accuracy: 0.5318\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7103 - accuracy: 0.5188 - val_loss: 0.6922 - val_accuracy: 0.5307\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7151 - accuracy: 0.5134 - val_loss: 0.6920 - val_accuracy: 0.5335\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7101 - accuracy: 0.5049 - val_loss: 0.6919 - val_accuracy: 0.5312\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7073 - accuracy: 0.5226 - val_loss: 0.6923 - val_accuracy: 0.5307\n",
      "28/28 [==============================] - 9s 329ms/step - loss: 0.6905 - accuracy: 0.5536\n",
      "{'dense_units': 512, 'dropout_rate': 0.2, 'learning_rate': 1e-05, 'optimizer': 'adam', 'activation': 'relu', 'learning_rate_decay': 0.001}\n",
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_71 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_72 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_71[0][0]                   \n",
      "                                                                 input_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 512)    4719104     concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 7, 7, 512)    0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 512)    2359808     dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 7, 7, 512)    0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_47 (Flatten)            (None, 25088)        0           dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 2)            50178       flatten_47[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 27,153,474\n",
      "Trainable params: 14,208,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.5610 - accuracy: 0.7154 - val_loss: 0.4382 - val_accuracy: 0.8030\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.3937 - accuracy: 0.8226 - val_loss: 0.3909 - val_accuracy: 0.8209\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.3714 - accuracy: 0.8388 - val_loss: 0.3747 - val_accuracy: 0.8309\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.3223 - accuracy: 0.8616 - val_loss: 0.3574 - val_accuracy: 0.8359\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.3120 - accuracy: 0.8669 - val_loss: 0.3567 - val_accuracy: 0.8471\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.2936 - accuracy: 0.8817 - val_loss: 0.3286 - val_accuracy: 0.8588\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.2629 - accuracy: 0.8932 - val_loss: 0.3265 - val_accuracy: 0.8571\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.2460 - accuracy: 0.9065 - val_loss: 0.3038 - val_accuracy: 0.8677\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.2249 - accuracy: 0.9165 - val_loss: 0.3033 - val_accuracy: 0.8638\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.2067 - accuracy: 0.9248 - val_loss: 0.2967 - val_accuracy: 0.8655\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.1869 - accuracy: 0.9370 - val_loss: 0.2837 - val_accuracy: 0.8717\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.1755 - accuracy: 0.9425 - val_loss: 0.2779 - val_accuracy: 0.8717\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.1554 - accuracy: 0.9497 - val_loss: 0.2799 - val_accuracy: 0.8722\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.1460 - accuracy: 0.9586 - val_loss: 0.2715 - val_accuracy: 0.8783\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.1186 - accuracy: 0.9671 - val_loss: 0.2614 - val_accuracy: 0.8834\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.1166 - accuracy: 0.9660 - val_loss: 0.2576 - val_accuracy: 0.8867\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.1091 - accuracy: 0.9710 - val_loss: 0.2576 - val_accuracy: 0.8873\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.0954 - accuracy: 0.9784 - val_loss: 0.2652 - val_accuracy: 0.8845\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.0814 - accuracy: 0.9828 - val_loss: 0.2494 - val_accuracy: 0.8923\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.0752 - accuracy: 0.9837 - val_loss: 0.2473 - val_accuracy: 0.8984\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.0730 - accuracy: 0.9848 - val_loss: 0.2474 - val_accuracy: 0.8962\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.0576 - accuracy: 0.9900 - val_loss: 0.2444 - val_accuracy: 0.8979\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.0559 - accuracy: 0.9889 - val_loss: 0.2435 - val_accuracy: 0.8990\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.0456 - accuracy: 0.9935 - val_loss: 0.2464 - val_accuracy: 0.8979\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.0447 - accuracy: 0.9930 - val_loss: 0.2525 - val_accuracy: 0.9012\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.0402 - accuracy: 0.9946 - val_loss: 0.2947 - val_accuracy: 0.8862\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.0361 - accuracy: 0.9948 - val_loss: 0.2543 - val_accuracy: 0.9057\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.0338 - accuracy: 0.9946 - val_loss: 0.2655 - val_accuracy: 0.8962\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.0282 - accuracy: 0.9965 - val_loss: 0.2652 - val_accuracy: 0.9007\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.0264 - accuracy: 0.9956 - val_loss: 0.2759 - val_accuracy: 0.9007\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.0232 - accuracy: 0.9980 - val_loss: 0.2602 - val_accuracy: 0.9068\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.0209 - accuracy: 0.9982 - val_loss: 0.2755 - val_accuracy: 0.9007\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.0206 - accuracy: 0.9983 - val_loss: 0.2679 - val_accuracy: 0.9085\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 41s 490ms/step - loss: 0.0173 - accuracy: 0.9983 - val_loss: 0.2729 - val_accuracy: 0.9051\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.0151 - accuracy: 0.9987 - val_loss: 0.2729 - val_accuracy: 0.9107\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.0145 - accuracy: 0.9991 - val_loss: 0.2901 - val_accuracy: 0.9029\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.0135 - accuracy: 0.9994 - val_loss: 0.2964 - val_accuracy: 0.9007\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.0124 - accuracy: 0.9996 - val_loss: 0.2988 - val_accuracy: 0.8996\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.0118 - accuracy: 0.9993 - val_loss: 0.2994 - val_accuracy: 0.9012\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.0113 - accuracy: 0.9985 - val_loss: 0.3060 - val_accuracy: 0.9001\n",
      "28/28 [==============================] - 9s 330ms/step - loss: 0.4550 - accuracy: 0.8767\n",
      "{'dense_units': 256, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'optimizer': 'adam', 'activation': 'relu', 'learning_rate_decay': 0.001}\n",
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_74 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_75 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_74[0][0]                   \n",
      "                                                                 input_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 256)    2359552     concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 7, 7, 256)    0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 256)    590080      dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 7, 7, 256)    0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_49 (Flatten)            (None, 12544)        0           dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 2)            25090       flatten_49[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,999,106\n",
      "Trainable params: 10,054,146\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4610 - accuracy: 0.7786 - val_loss: 0.3839 - val_accuracy: 0.8292\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3500 - accuracy: 0.8523 - val_loss: 0.3446 - val_accuracy: 0.8482\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3057 - accuracy: 0.8760 - val_loss: 0.3142 - val_accuracy: 0.8683\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.2479 - accuracy: 0.8998 - val_loss: 0.2999 - val_accuracy: 0.8733\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.1918 - accuracy: 0.9259 - val_loss: 0.2708 - val_accuracy: 0.8890\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.1373 - accuracy: 0.9508 - val_loss: 0.2730 - val_accuracy: 0.8867\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.0962 - accuracy: 0.9712 - val_loss: 0.2605 - val_accuracy: 0.9068\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.0626 - accuracy: 0.9810 - val_loss: 0.3054 - val_accuracy: 0.9040\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.0512 - accuracy: 0.9808 - val_loss: 0.3170 - val_accuracy: 0.8951\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.0348 - accuracy: 0.9897 - val_loss: 0.3653 - val_accuracy: 0.9096\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.4534 - val_accuracy: 0.8945\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.0188 - accuracy: 0.9930 - val_loss: 0.4470 - val_accuracy: 0.9057\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.4681 - val_accuracy: 0.9062\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.5136 - val_accuracy: 0.9046\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.5231 - val_accuracy: 0.9074\n",
      "28/28 [==============================] - 9s 329ms/step - loss: 0.6223 - accuracy: 0.8901\n",
      "{'dense_units': 256, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'optimizer': 'sgd', 'activation': 'sigmoid', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_77 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_78 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_77[0][0]                   \n",
      "                                                                 input_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 256)    2359552     concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 7, 7, 256)    0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 256)    590080      dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 7, 7, 256)    0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_51 (Flatten)            (None, 12544)        0           dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 2)            25090       flatten_51[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,999,106\n",
      "Trainable params: 10,054,146\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.7543 - accuracy: 0.4929 - val_loss: 0.6926 - val_accuracy: 0.5273\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7411 - accuracy: 0.5012 - val_loss: 0.6930 - val_accuracy: 0.5262\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7401 - accuracy: 0.5003 - val_loss: 0.6929 - val_accuracy: 0.5246\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7485 - accuracy: 0.4827 - val_loss: 0.6923 - val_accuracy: 0.5296\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7443 - accuracy: 0.4909 - val_loss: 0.6926 - val_accuracy: 0.5251\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7425 - accuracy: 0.4958 - val_loss: 0.6927 - val_accuracy: 0.5257\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7443 - accuracy: 0.4881 - val_loss: 0.6922 - val_accuracy: 0.5285\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7418 - accuracy: 0.4934 - val_loss: 0.6926 - val_accuracy: 0.5257\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7405 - accuracy: 0.5101 - val_loss: 0.6924 - val_accuracy: 0.5262\n",
      "28/28 [==============================] - 9s 329ms/step - loss: 0.6954 - accuracy: 0.5017\n",
      "{'dense_units': 128, 'dropout_rate': 0.5, 'learning_rate': 1e-06, 'optimizer': 'rmsprop', 'activation': 'tanh', 'learning_rate_decay': 0.001}\n",
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_80 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_81 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_80[0][0]                   \n",
      "                                                                 input_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 128)    1179776     concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 7, 7, 128)    0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 128)    147584      dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 7, 7, 128)    0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_53 (Flatten)            (None, 6272)         0           dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 2)            12546       flatten_53[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,364,290\n",
      "Trainable params: 8,419,330\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7637 - accuracy: 0.5358 - val_loss: 0.6687 - val_accuracy: 0.6507\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.7450 - accuracy: 0.5502 - val_loss: 0.6525 - val_accuracy: 0.6869\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7314 - accuracy: 0.5709 - val_loss: 0.6366 - val_accuracy: 0.7193\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.7035 - accuracy: 0.6121 - val_loss: 0.6211 - val_accuracy: 0.7349\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6883 - accuracy: 0.6248 - val_loss: 0.6063 - val_accuracy: 0.7444\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.6735 - accuracy: 0.6365 - val_loss: 0.5916 - val_accuracy: 0.7561\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.6491 - accuracy: 0.6683 - val_loss: 0.5763 - val_accuracy: 0.7634\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.6340 - accuracy: 0.6869 - val_loss: 0.5611 - val_accuracy: 0.7667\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.6192 - accuracy: 0.6936 - val_loss: 0.5488 - val_accuracy: 0.7734\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.6049 - accuracy: 0.7161 - val_loss: 0.5370 - val_accuracy: 0.7740\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5971 - accuracy: 0.7089 - val_loss: 0.5259 - val_accuracy: 0.7768\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5700 - accuracy: 0.7370 - val_loss: 0.5161 - val_accuracy: 0.7751\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5655 - accuracy: 0.7281 - val_loss: 0.5075 - val_accuracy: 0.7807\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5537 - accuracy: 0.7516 - val_loss: 0.5013 - val_accuracy: 0.7835\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5340 - accuracy: 0.7616 - val_loss: 0.4957 - val_accuracy: 0.7818\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5324 - accuracy: 0.7540 - val_loss: 0.4877 - val_accuracy: 0.7846\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5371 - accuracy: 0.7555 - val_loss: 0.4854 - val_accuracy: 0.7824\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5254 - accuracy: 0.7609 - val_loss: 0.4800 - val_accuracy: 0.7835\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5069 - accuracy: 0.7768 - val_loss: 0.4753 - val_accuracy: 0.7874\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5039 - accuracy: 0.7788 - val_loss: 0.4701 - val_accuracy: 0.7879\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5015 - accuracy: 0.7758 - val_loss: 0.4691 - val_accuracy: 0.7896\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4869 - accuracy: 0.7884 - val_loss: 0.4663 - val_accuracy: 0.7924\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4876 - accuracy: 0.7828 - val_loss: 0.4612 - val_accuracy: 0.7930\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5016 - accuracy: 0.7719 - val_loss: 0.4594 - val_accuracy: 0.7930\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4861 - accuracy: 0.7827 - val_loss: 0.4580 - val_accuracy: 0.7930\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4772 - accuracy: 0.7965 - val_loss: 0.4541 - val_accuracy: 0.7958\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4751 - accuracy: 0.7930 - val_loss: 0.4536 - val_accuracy: 0.7974\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4778 - accuracy: 0.7934 - val_loss: 0.4525 - val_accuracy: 0.7985\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4799 - accuracy: 0.7901 - val_loss: 0.4511 - val_accuracy: 0.7969\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4745 - accuracy: 0.7923 - val_loss: 0.4495 - val_accuracy: 0.7997\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4721 - accuracy: 0.7965 - val_loss: 0.4438 - val_accuracy: 0.8013\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4643 - accuracy: 0.7962 - val_loss: 0.4447 - val_accuracy: 0.8019\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4660 - accuracy: 0.7958 - val_loss: 0.4428 - val_accuracy: 0.8030\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4654 - accuracy: 0.7978 - val_loss: 0.4443 - val_accuracy: 0.8030\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4597 - accuracy: 0.7999 - val_loss: 0.4404 - val_accuracy: 0.8041\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4553 - accuracy: 0.8011 - val_loss: 0.4375 - val_accuracy: 0.8030\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4638 - accuracy: 0.7967 - val_loss: 0.4380 - val_accuracy: 0.8052\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4539 - accuracy: 0.8019 - val_loss: 0.4417 - val_accuracy: 0.8036\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4606 - accuracy: 0.7997 - val_loss: 0.4369 - val_accuracy: 0.8041\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4513 - accuracy: 0.8063 - val_loss: 0.4357 - val_accuracy: 0.8069\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4587 - accuracy: 0.8011 - val_loss: 0.4359 - val_accuracy: 0.8036\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4553 - accuracy: 0.8030 - val_loss: 0.4363 - val_accuracy: 0.8047\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4529 - accuracy: 0.8002 - val_loss: 0.4350 - val_accuracy: 0.8058\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4405 - accuracy: 0.8139 - val_loss: 0.4338 - val_accuracy: 0.8058\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4571 - accuracy: 0.7947 - val_loss: 0.4312 - val_accuracy: 0.8064\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.4256 - accuracy: 0.8086\n",
      "{'dense_units': 32, 'dropout_rate': 0.4, 'learning_rate': 1e-06, 'optimizer': 'adam', 'activation': 'sigmoid', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_83 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_84 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_83[0][0]                   \n",
      "                                                                 input_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 32)     294944      concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 7, 7, 32)     0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 32)     9248        dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 7, 7, 32)     0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_55 (Flatten)            (None, 1568)         0           dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 2)            3138        flatten_55[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,331,714\n",
      "Trainable params: 7,386,754\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.8002 - accuracy: 0.5088 - val_loss: 0.7450 - val_accuracy: 0.5273\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7892 - accuracy: 0.5108 - val_loss: 0.7319 - val_accuracy: 0.5273\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7667 - accuracy: 0.5189 - val_loss: 0.7194 - val_accuracy: 0.5273\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7564 - accuracy: 0.5195 - val_loss: 0.7083 - val_accuracy: 0.5240\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7483 - accuracy: 0.5114 - val_loss: 0.6966 - val_accuracy: 0.5251\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7318 - accuracy: 0.5254 - val_loss: 0.6875 - val_accuracy: 0.5257\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.6928 - accuracy: 0.5033\n",
      "{'dense_units': 64, 'dropout_rate': 0.5, 'learning_rate': 1e-06, 'optimizer': 'sgd', 'activation': 'sigmoid', 'learning_rate_decay': 0.001}\n",
      "Model: \"model_28\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_86 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_87 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_86[0][0]                   \n",
      "                                                                 input_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 64)     589888      concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 7, 7, 64)     0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 64)     36928       dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 7, 7, 64)     0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_57 (Flatten)            (None, 3136)         0           dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 2)            6274        flatten_57[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,657,474\n",
      "Trainable params: 7,712,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.8354 - accuracy: 0.5147 - val_loss: 0.7718 - val_accuracy: 0.5251\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.8310 - accuracy: 0.5136 - val_loss: 0.7709 - val_accuracy: 0.5251\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.8382 - accuracy: 0.5005 - val_loss: 0.7704 - val_accuracy: 0.5240\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.8341 - accuracy: 0.5023 - val_loss: 0.7681 - val_accuracy: 0.5268\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.8325 - accuracy: 0.5132 - val_loss: 0.7698 - val_accuracy: 0.5218\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.8212 - accuracy: 0.5171 - val_loss: 0.7672 - val_accuracy: 0.5257\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.8263 - accuracy: 0.5091 - val_loss: 0.7662 - val_accuracy: 0.5262\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.8352 - accuracy: 0.5040 - val_loss: 0.7662 - val_accuracy: 0.5251\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.8274 - accuracy: 0.5103 - val_loss: 0.7650 - val_accuracy: 0.5262\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.7780 - accuracy: 0.5000\n",
      "{'dense_units': 64, 'dropout_rate': 0.5, 'learning_rate': 0.0001, 'optimizer': 'adam', 'activation': 'tanh', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_29\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_89 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_90 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_89[0][0]                   \n",
      "                                                                 input_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 64)     589888      concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 7, 7, 64)     0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 64)     36928       dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 7, 7, 64)     0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_59 (Flatten)            (None, 3136)         0           dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 2)            6274        flatten_59[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,657,474\n",
      "Trainable params: 7,712,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.4890 - accuracy: 0.7733 - val_loss: 0.4113 - val_accuracy: 0.8265\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.3821 - accuracy: 0.8387 - val_loss: 0.3685 - val_accuracy: 0.8426\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.3175 - accuracy: 0.8701 - val_loss: 0.3116 - val_accuracy: 0.8655\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.2713 - accuracy: 0.8982 - val_loss: 0.3392 - val_accuracy: 0.8694\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.2150 - accuracy: 0.9246 - val_loss: 0.2997 - val_accuracy: 0.8772\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.1682 - accuracy: 0.9409 - val_loss: 0.3195 - val_accuracy: 0.8705\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.1354 - accuracy: 0.9560 - val_loss: 0.3155 - val_accuracy: 0.8839\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0984 - accuracy: 0.9673 - val_loss: 0.3300 - val_accuracy: 0.8783\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0867 - accuracy: 0.9732 - val_loss: 0.3264 - val_accuracy: 0.8934\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0504 - accuracy: 0.9863 - val_loss: 0.3152 - val_accuracy: 0.9051\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0403 - accuracy: 0.9889 - val_loss: 0.3303 - val_accuracy: 0.9029\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0440 - accuracy: 0.9878 - val_loss: 0.3690 - val_accuracy: 0.8968\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 0.3479 - val_accuracy: 0.8951\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 0.3637 - val_accuracy: 0.8984\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.0341 - accuracy: 0.9889 - val_loss: 0.3367 - val_accuracy: 0.9057\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0251 - accuracy: 0.9917 - val_loss: 0.3075 - val_accuracy: 0.9135\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0216 - accuracy: 0.9937 - val_loss: 0.3542 - val_accuracy: 0.9035\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.4190 - val_accuracy: 0.9090\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.3722 - val_accuracy: 0.9090\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.3881 - val_accuracy: 0.9102\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.3612 - val_accuracy: 0.9174\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.3399 - val_accuracy: 0.9235\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.3262 - val_accuracy: 0.9219\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.3516 - val_accuracy: 0.9196\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 3.1165e-04 - accuracy: 1.0000 - val_loss: 0.3560 - val_accuracy: 0.9202\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.3470 - val_accuracy: 0.9230\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 2.5516e-04 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9230\n",
      "28/28 [==============================] - 9s 329ms/step - loss: 0.5072 - accuracy: 0.9018\n",
      "{'dense_units': 512, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'optimizer': 'rmsprop', 'activation': 'sigmoid', 'learning_rate_decay': 0.001}\n",
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_92 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_93 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_92[0][0]                   \n",
      "                                                                 input_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 512)    4719104     concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 7, 7, 512)    0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 512)    2359808     dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 7, 7, 512)    0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_61 (Flatten)            (None, 25088)        0           dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 2)            50178       flatten_61[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 27,153,474\n",
      "Trainable params: 14,208,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 42s 493ms/step - loss: 0.5213 - accuracy: 0.7662 - val_loss: 0.4004 - val_accuracy: 0.8181\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3843 - accuracy: 0.8390 - val_loss: 0.3418 - val_accuracy: 0.8516\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.3222 - accuracy: 0.8636 - val_loss: 0.3170 - val_accuracy: 0.8638\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.2906 - accuracy: 0.8786 - val_loss: 0.3008 - val_accuracy: 0.8744\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.2385 - accuracy: 0.9063 - val_loss: 0.3105 - val_accuracy: 0.8717\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.1855 - accuracy: 0.9324 - val_loss: 0.2809 - val_accuracy: 0.8811\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.1590 - accuracy: 0.9479 - val_loss: 0.3152 - val_accuracy: 0.8756\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.1159 - accuracy: 0.9629 - val_loss: 0.3376 - val_accuracy: 0.8834\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.1052 - accuracy: 0.9680 - val_loss: 0.3379 - val_accuracy: 0.8733\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0733 - accuracy: 0.9754 - val_loss: 0.3581 - val_accuracy: 0.8923\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.0615 - accuracy: 0.9811 - val_loss: 0.3664 - val_accuracy: 0.8890\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.0513 - accuracy: 0.9858 - val_loss: 0.3909 - val_accuracy: 0.8929\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0383 - accuracy: 0.9880 - val_loss: 0.3958 - val_accuracy: 0.8962\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0336 - accuracy: 0.9900 - val_loss: 0.3801 - val_accuracy: 0.9051\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0251 - accuracy: 0.9935 - val_loss: 0.4257 - val_accuracy: 0.8984\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 0.3754 - val_accuracy: 0.9046\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.4321 - val_accuracy: 0.8917\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.4773 - val_accuracy: 0.9018\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.4866 - val_accuracy: 0.8934\n",
      "28/28 [==============================] - 9s 330ms/step - loss: 0.5749 - accuracy: 0.8878\n",
      "{'dense_units': 256, 'dropout_rate': 0.2, 'learning_rate': 1e-05, 'optimizer': 'rmsprop', 'activation': 'sigmoid', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_31\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_95 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_96 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_95[0][0]                   \n",
      "                                                                 input_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 256)    2359552     concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 7, 7, 256)    0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 256)    590080      dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 7, 7, 256)    0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_63 (Flatten)            (None, 12544)        0           dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 2)            25090       flatten_63[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,999,106\n",
      "Trainable params: 10,054,146\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 42s 485ms/step - loss: 0.6435 - accuracy: 0.6374 - val_loss: 0.5290 - val_accuracy: 0.7796\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 484ms/step - loss: 0.4704 - accuracy: 0.7904 - val_loss: 0.4401 - val_accuracy: 0.8025\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4100 - accuracy: 0.8132 - val_loss: 0.3976 - val_accuracy: 0.8203\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3874 - accuracy: 0.8311 - val_loss: 0.3821 - val_accuracy: 0.8315\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3615 - accuracy: 0.8381 - val_loss: 0.4052 - val_accuracy: 0.8153\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3561 - accuracy: 0.8440 - val_loss: 0.3614 - val_accuracy: 0.8359\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3410 - accuracy: 0.8549 - val_loss: 0.3537 - val_accuracy: 0.8443\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 484ms/step - loss: 0.3258 - accuracy: 0.8594 - val_loss: 0.3515 - val_accuracy: 0.8449\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3177 - accuracy: 0.8692 - val_loss: 0.3479 - val_accuracy: 0.8438\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3101 - accuracy: 0.8767 - val_loss: 0.3445 - val_accuracy: 0.8510\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.2952 - accuracy: 0.8782 - val_loss: 0.3223 - val_accuracy: 0.8566\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.2784 - accuracy: 0.8886 - val_loss: 0.3228 - val_accuracy: 0.8594\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 484ms/step - loss: 0.2712 - accuracy: 0.8923 - val_loss: 0.3088 - val_accuracy: 0.8644\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.2547 - accuracy: 0.8993 - val_loss: 0.3136 - val_accuracy: 0.8633\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 484ms/step - loss: 0.2487 - accuracy: 0.9067 - val_loss: 0.3079 - val_accuracy: 0.8610\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.2226 - accuracy: 0.9185 - val_loss: 0.2884 - val_accuracy: 0.8761\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.2140 - accuracy: 0.9207 - val_loss: 0.2948 - val_accuracy: 0.8750\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.2044 - accuracy: 0.9316 - val_loss: 0.2879 - val_accuracy: 0.8733\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 484ms/step - loss: 0.1829 - accuracy: 0.9386 - val_loss: 0.2815 - val_accuracy: 0.8828\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.1679 - accuracy: 0.9464 - val_loss: 0.2816 - val_accuracy: 0.8795\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.1606 - accuracy: 0.9473 - val_loss: 0.2808 - val_accuracy: 0.8828\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.1403 - accuracy: 0.9579 - val_loss: 0.2868 - val_accuracy: 0.8839\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.1355 - accuracy: 0.9571 - val_loss: 0.2816 - val_accuracy: 0.8834\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.1208 - accuracy: 0.9629 - val_loss: 0.2675 - val_accuracy: 0.8890\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 484ms/step - loss: 0.1082 - accuracy: 0.9719 - val_loss: 0.2760 - val_accuracy: 0.8912\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0974 - accuracy: 0.9767 - val_loss: 0.2943 - val_accuracy: 0.8789\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0887 - accuracy: 0.9771 - val_loss: 0.2752 - val_accuracy: 0.8901\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 484ms/step - loss: 0.0836 - accuracy: 0.9791 - val_loss: 0.2847 - val_accuracy: 0.8862\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0713 - accuracy: 0.9836 - val_loss: 0.2840 - val_accuracy: 0.8890\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0656 - accuracy: 0.9848 - val_loss: 0.2849 - val_accuracy: 0.8878\n",
      "28/28 [==============================] - 9s 329ms/step - loss: 0.3671 - accuracy: 0.8744\n",
      "{'dense_units': 64, 'dropout_rate': 0.4, 'learning_rate': 1e-05, 'optimizer': 'adam', 'activation': 'tanh', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_32\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_98 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_99 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_98[0][0]                   \n",
      "                                                                 input_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 64)     589888      concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 7, 7, 64)     0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 64)     36928       dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 7, 7, 64)     0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_65 (Flatten)            (None, 3136)         0           dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 2)            6274        flatten_65[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,657,474\n",
      "Trainable params: 7,712,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.6874 - accuracy: 0.6062 - val_loss: 0.5430 - val_accuracy: 0.7617\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.4989 - accuracy: 0.7723 - val_loss: 0.4427 - val_accuracy: 0.8041\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.4347 - accuracy: 0.8095 - val_loss: 0.4080 - val_accuracy: 0.8158\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.3922 - accuracy: 0.8348 - val_loss: 0.3887 - val_accuracy: 0.8231\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.3708 - accuracy: 0.8449 - val_loss: 0.3835 - val_accuracy: 0.8259\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.3459 - accuracy: 0.8577 - val_loss: 0.3622 - val_accuracy: 0.8415\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.3344 - accuracy: 0.8632 - val_loss: 0.3505 - val_accuracy: 0.8499\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.3089 - accuracy: 0.8806 - val_loss: 0.3391 - val_accuracy: 0.8555\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2931 - accuracy: 0.8854 - val_loss: 0.3322 - val_accuracy: 0.8560\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.2679 - accuracy: 0.9022 - val_loss: 0.3257 - val_accuracy: 0.8521\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2540 - accuracy: 0.9052 - val_loss: 0.3101 - val_accuracy: 0.8599\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.2343 - accuracy: 0.9211 - val_loss: 0.3037 - val_accuracy: 0.8672\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.2164 - accuracy: 0.9279 - val_loss: 0.2902 - val_accuracy: 0.8700\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.2023 - accuracy: 0.9318 - val_loss: 0.2819 - val_accuracy: 0.8811\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 40s 479ms/step - loss: 0.1789 - accuracy: 0.9488 - val_loss: 0.2697 - val_accuracy: 0.8862\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.1607 - accuracy: 0.9527 - val_loss: 0.2666 - val_accuracy: 0.8901\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.1441 - accuracy: 0.9651 - val_loss: 0.2620 - val_accuracy: 0.8929\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1250 - accuracy: 0.9688 - val_loss: 0.2475 - val_accuracy: 0.8895\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1080 - accuracy: 0.9784 - val_loss: 0.2490 - val_accuracy: 0.8940\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0959 - accuracy: 0.9795 - val_loss: 0.2425 - val_accuracy: 0.8962\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0811 - accuracy: 0.9845 - val_loss: 0.2503 - val_accuracy: 0.8990\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.0700 - accuracy: 0.9874 - val_loss: 0.2404 - val_accuracy: 0.9018\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.0575 - accuracy: 0.9911 - val_loss: 0.2270 - val_accuracy: 0.9023\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0508 - accuracy: 0.9909 - val_loss: 0.2268 - val_accuracy: 0.9085\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0411 - accuracy: 0.9950 - val_loss: 0.2303 - val_accuracy: 0.9085\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0365 - accuracy: 0.9950 - val_loss: 0.2300 - val_accuracy: 0.9090\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.0288 - accuracy: 0.9970 - val_loss: 0.2392 - val_accuracy: 0.9040\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.0223 - accuracy: 0.9983 - val_loss: 0.2321 - val_accuracy: 0.9118\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.0207 - accuracy: 0.9980 - val_loss: 0.2413 - val_accuracy: 0.9079\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.0173 - accuracy: 0.9982 - val_loss: 0.2487 - val_accuracy: 0.9118\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0163 - accuracy: 0.9982 - val_loss: 0.2518 - val_accuracy: 0.9062\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.0124 - accuracy: 0.9985 - val_loss: 0.2689 - val_accuracy: 0.9068\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0135 - accuracy: 0.9982 - val_loss: 0.2756 - val_accuracy: 0.9018\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.3934 - accuracy: 0.8945\n",
      "{'dense_units': 64, 'dropout_rate': 0.6, 'learning_rate': 0.0001, 'optimizer': 'rmsprop', 'activation': 'sigmoid', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_33\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_101 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_102 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_101[0][0]                  \n",
      "                                                                 input_102[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 64)     589888      concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 7, 7, 64)     0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 64)     36928       dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 7, 7, 64)     0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_67 (Flatten)            (None, 3136)         0           dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 2)            6274        flatten_67[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,657,474\n",
      "Trainable params: 7,712,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.5631 - accuracy: 0.7411 - val_loss: 0.4070 - val_accuracy: 0.8287\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4159 - accuracy: 0.8318 - val_loss: 0.3656 - val_accuracy: 0.8421\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.3576 - accuracy: 0.8592 - val_loss: 0.3271 - val_accuracy: 0.8538\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.3235 - accuracy: 0.8717 - val_loss: 0.3433 - val_accuracy: 0.8521\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.2731 - accuracy: 0.8958 - val_loss: 0.3298 - val_accuracy: 0.8594\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.2356 - accuracy: 0.9141 - val_loss: 0.3141 - val_accuracy: 0.8689\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.1930 - accuracy: 0.9311 - val_loss: 0.3325 - val_accuracy: 0.8689\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.1597 - accuracy: 0.9449 - val_loss: 0.2862 - val_accuracy: 0.8878\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.1347 - accuracy: 0.9569 - val_loss: 0.3159 - val_accuracy: 0.8800\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.1042 - accuracy: 0.9677 - val_loss: 0.2877 - val_accuracy: 0.9018\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.1004 - accuracy: 0.9706 - val_loss: 0.3045 - val_accuracy: 0.9007\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0819 - accuracy: 0.9765 - val_loss: 0.3254 - val_accuracy: 0.8956\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0607 - accuracy: 0.9813 - val_loss: 0.3127 - val_accuracy: 0.9007\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0646 - accuracy: 0.9823 - val_loss: 0.4221 - val_accuracy: 0.8694\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0652 - accuracy: 0.9826 - val_loss: 0.3422 - val_accuracy: 0.8901\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.4070 - accuracy: 0.8862\n",
      "{'dense_units': 512, 'dropout_rate': 0.3, 'learning_rate': 0.0001, 'optimizer': 'rmsprop', 'activation': 'relu', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_34\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_104 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_105 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_104[0][0]                  \n",
      "                                                                 input_105[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 512)    4719104     concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 7, 7, 512)    0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 512)    2359808     dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 7, 7, 512)    0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_69 (Flatten)            (None, 25088)        0           dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 2)            50178       flatten_69[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 27,153,474\n",
      "Trainable params: 14,208,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 42s 493ms/step - loss: 0.4580 - accuracy: 0.7819 - val_loss: 0.3679 - val_accuracy: 0.8320\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3539 - accuracy: 0.8540 - val_loss: 0.3507 - val_accuracy: 0.8471\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3021 - accuracy: 0.8734 - val_loss: 0.3158 - val_accuracy: 0.8622\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.2609 - accuracy: 0.8939 - val_loss: 0.3234 - val_accuracy: 0.8722\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.2097 - accuracy: 0.9141 - val_loss: 0.2984 - val_accuracy: 0.8761\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.1605 - accuracy: 0.9436 - val_loss: 0.3171 - val_accuracy: 0.8778\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.1192 - accuracy: 0.9569 - val_loss: 0.3657 - val_accuracy: 0.8828\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0939 - accuracy: 0.9662 - val_loss: 0.4728 - val_accuracy: 0.8683\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0810 - accuracy: 0.9719 - val_loss: 0.3389 - val_accuracy: 0.8962\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 42s 490ms/step - loss: 0.0728 - accuracy: 0.9762 - val_loss: 0.3732 - val_accuracy: 0.8839\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0583 - accuracy: 0.9802 - val_loss: 0.3585 - val_accuracy: 0.9113\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0541 - accuracy: 0.9815 - val_loss: 0.3764 - val_accuracy: 0.9018\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 42s 490ms/step - loss: 0.0509 - accuracy: 0.9830 - val_loss: 0.3458 - val_accuracy: 0.8990\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0409 - accuracy: 0.9863 - val_loss: 0.4631 - val_accuracy: 0.8856\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0401 - accuracy: 0.9860 - val_loss: 0.6895 - val_accuracy: 0.8850\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.0375 - accuracy: 0.9891 - val_loss: 0.4270 - val_accuracy: 0.8823\n",
      "28/28 [==============================] - 9s 332ms/step - loss: 0.4852 - accuracy: 0.8783\n",
      "{'dense_units': 256, 'dropout_rate': 0.3, 'learning_rate': 1e-05, 'optimizer': 'adam', 'activation': 'sigmoid', 'learning_rate_decay': 0.001}\n",
      "Model: \"model_35\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_107 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_108 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_107[0][0]                  \n",
      "                                                                 input_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 7, 7, 256)    2359552     concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 7, 7, 256)    0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 7, 7, 256)    590080      dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 7, 7, 256)    0           conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_71 (Flatten)            (None, 12544)        0           dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 2)            25090       flatten_71[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,999,106\n",
      "Trainable params: 10,054,146\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 42s 483ms/step - loss: 0.6813 - accuracy: 0.5833 - val_loss: 0.5743 - val_accuracy: 0.7785\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4878 - accuracy: 0.7884 - val_loss: 0.4319 - val_accuracy: 0.8075\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4265 - accuracy: 0.8124 - val_loss: 0.4023 - val_accuracy: 0.8198\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3881 - accuracy: 0.8337 - val_loss: 0.3764 - val_accuracy: 0.8326\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3726 - accuracy: 0.8446 - val_loss: 0.3758 - val_accuracy: 0.8337\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.3624 - accuracy: 0.8485 - val_loss: 0.3591 - val_accuracy: 0.8410\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3467 - accuracy: 0.8558 - val_loss: 0.3510 - val_accuracy: 0.8449\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.3373 - accuracy: 0.8586 - val_loss: 0.3473 - val_accuracy: 0.8493\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.3202 - accuracy: 0.8660 - val_loss: 0.3368 - val_accuracy: 0.8521\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.3168 - accuracy: 0.8706 - val_loss: 0.3310 - val_accuracy: 0.8571\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.3051 - accuracy: 0.8780 - val_loss: 0.3274 - val_accuracy: 0.8594\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.2885 - accuracy: 0.8863 - val_loss: 0.3209 - val_accuracy: 0.8616\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.2856 - accuracy: 0.8887 - val_loss: 0.3200 - val_accuracy: 0.8633\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.2686 - accuracy: 0.8932 - val_loss: 0.3056 - val_accuracy: 0.8683\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.2647 - accuracy: 0.9008 - val_loss: 0.3045 - val_accuracy: 0.8700\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.2527 - accuracy: 0.9041 - val_loss: 0.2992 - val_accuracy: 0.8750\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.2371 - accuracy: 0.9163 - val_loss: 0.2970 - val_accuracy: 0.8705\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.2298 - accuracy: 0.9167 - val_loss: 0.2881 - val_accuracy: 0.8789\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.2217 - accuracy: 0.9209 - val_loss: 0.2839 - val_accuracy: 0.8817\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.2110 - accuracy: 0.9233 - val_loss: 0.2838 - val_accuracy: 0.8756\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.1947 - accuracy: 0.9377 - val_loss: 0.2838 - val_accuracy: 0.8789\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.1978 - accuracy: 0.9348 - val_loss: 0.2727 - val_accuracy: 0.8783\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.1782 - accuracy: 0.9409 - val_loss: 0.2735 - val_accuracy: 0.8839\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.1722 - accuracy: 0.9446 - val_loss: 0.2741 - val_accuracy: 0.8873\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.1628 - accuracy: 0.9525 - val_loss: 0.2736 - val_accuracy: 0.8845\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.1526 - accuracy: 0.9519 - val_loss: 0.2805 - val_accuracy: 0.8823\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.1461 - accuracy: 0.9580 - val_loss: 0.2674 - val_accuracy: 0.8912\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.1423 - accuracy: 0.9580 - val_loss: 0.2648 - val_accuracy: 0.8906\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.1306 - accuracy: 0.9667 - val_loss: 0.2657 - val_accuracy: 0.8912\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.1274 - accuracy: 0.9641 - val_loss: 0.2714 - val_accuracy: 0.8867\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.1211 - accuracy: 0.9690 - val_loss: 0.2720 - val_accuracy: 0.8912\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.1121 - accuracy: 0.9739 - val_loss: 0.2776 - val_accuracy: 0.8839\n",
      "28/28 [==============================] - 9s 329ms/step - loss: 0.3362 - accuracy: 0.8717\n",
      "{'dense_units': 32, 'dropout_rate': 0.4, 'learning_rate': 1e-05, 'optimizer': 'sgd', 'activation': 'sigmoid', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_36\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_110 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_111 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_110[0][0]                  \n",
      "                                                                 input_111[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 7, 7, 32)     294944      concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 7, 7, 32)     0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 7, 7, 32)     9248        dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 7, 7, 32)     0           conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_73 (Flatten)            (None, 1568)         0           dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 2)            3138        flatten_73[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,331,714\n",
      "Trainable params: 7,386,754\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.8511 - accuracy: 0.4783 - val_loss: 0.8113 - val_accuracy: 0.4749\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.8348 - accuracy: 0.4866 - val_loss: 0.8024 - val_accuracy: 0.4766\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.8288 - accuracy: 0.4860 - val_loss: 0.7964 - val_accuracy: 0.4749\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.8204 - accuracy: 0.4818 - val_loss: 0.7924 - val_accuracy: 0.4704\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.8130 - accuracy: 0.4903 - val_loss: 0.7828 - val_accuracy: 0.4754\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.8163 - accuracy: 0.4848 - val_loss: 0.7787 - val_accuracy: 0.4721\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.8026 - accuracy: 0.4890 - val_loss: 0.7717 - val_accuracy: 0.4743\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.7571 - accuracy: 0.4994\n",
      "{'dense_units': 256, 'dropout_rate': 0.6, 'learning_rate': 1e-05, 'optimizer': 'rmsprop', 'activation': 'relu', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_37\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_113 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_114 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_113[0][0]                  \n",
      "                                                                 input_114[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 7, 7, 256)    2359552     concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 7, 7, 256)    0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 7, 7, 256)    590080      dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 7, 7, 256)    0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_75 (Flatten)            (None, 12544)        0           dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 2)            25090       flatten_75[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,999,106\n",
      "Trainable params: 10,054,146\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 42s 485ms/step - loss: 0.7078 - accuracy: 0.5834 - val_loss: 0.5997 - val_accuracy: 0.7439\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 484ms/step - loss: 0.5599 - accuracy: 0.7399 - val_loss: 0.4838 - val_accuracy: 0.7829\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 484ms/step - loss: 0.4738 - accuracy: 0.7965 - val_loss: 0.4390 - val_accuracy: 0.8002\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4368 - accuracy: 0.8128 - val_loss: 0.4125 - val_accuracy: 0.8131\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4092 - accuracy: 0.8231 - val_loss: 0.3925 - val_accuracy: 0.8265\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3815 - accuracy: 0.8411 - val_loss: 0.3780 - val_accuracy: 0.8259\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3674 - accuracy: 0.8420 - val_loss: 0.3664 - val_accuracy: 0.8376\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3528 - accuracy: 0.8510 - val_loss: 0.3561 - val_accuracy: 0.8410\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3403 - accuracy: 0.8583 - val_loss: 0.3463 - val_accuracy: 0.8454\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3287 - accuracy: 0.8651 - val_loss: 0.3356 - val_accuracy: 0.8527\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3150 - accuracy: 0.8686 - val_loss: 0.3287 - val_accuracy: 0.8610\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.2999 - accuracy: 0.8782 - val_loss: 0.3195 - val_accuracy: 0.8610\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.2847 - accuracy: 0.8819 - val_loss: 0.3126 - val_accuracy: 0.8694\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.2678 - accuracy: 0.8958 - val_loss: 0.3025 - val_accuracy: 0.8661\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.2470 - accuracy: 0.9065 - val_loss: 0.3075 - val_accuracy: 0.8638\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.2337 - accuracy: 0.9146 - val_loss: 0.2946 - val_accuracy: 0.8744\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.2180 - accuracy: 0.9154 - val_loss: 0.2828 - val_accuracy: 0.8739\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.2045 - accuracy: 0.9264 - val_loss: 0.2818 - val_accuracy: 0.8778\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.1848 - accuracy: 0.9340 - val_loss: 0.2691 - val_accuracy: 0.8850\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.1744 - accuracy: 0.9423 - val_loss: 0.2715 - val_accuracy: 0.8884\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.1467 - accuracy: 0.9542 - val_loss: 0.2605 - val_accuracy: 0.8901\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.1387 - accuracy: 0.9556 - val_loss: 0.2677 - val_accuracy: 0.8884\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.1212 - accuracy: 0.9638 - val_loss: 0.2742 - val_accuracy: 0.8890\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.1063 - accuracy: 0.9697 - val_loss: 0.2930 - val_accuracy: 0.8828\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0984 - accuracy: 0.9736 - val_loss: 0.2759 - val_accuracy: 0.8968\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0849 - accuracy: 0.9769 - val_loss: 0.2803 - val_accuracy: 0.8923\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0672 - accuracy: 0.9823 - val_loss: 0.2897 - val_accuracy: 0.8973\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0629 - accuracy: 0.9837 - val_loss: 0.3287 - val_accuracy: 0.8828\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0514 - accuracy: 0.9861 - val_loss: 0.3349 - val_accuracy: 0.8945\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0470 - accuracy: 0.9882 - val_loss: 0.3313 - val_accuracy: 0.9012\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0390 - accuracy: 0.9898 - val_loss: 0.3254 - val_accuracy: 0.9001\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0302 - accuracy: 0.9926 - val_loss: 0.3620 - val_accuracy: 0.8968\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0380 - accuracy: 0.9902 - val_loss: 0.3473 - val_accuracy: 0.9001\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0257 - accuracy: 0.9943 - val_loss: 0.3338 - val_accuracy: 0.9051\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0208 - accuracy: 0.9946 - val_loss: 0.3973 - val_accuracy: 0.8990\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0207 - accuracy: 0.9941 - val_loss: 0.3969 - val_accuracy: 0.9012\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0195 - accuracy: 0.9946 - val_loss: 0.4127 - val_accuracy: 0.9057\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0155 - accuracy: 0.9967 - val_loss: 0.4381 - val_accuracy: 0.9001\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0132 - accuracy: 0.9965 - val_loss: 0.4709 - val_accuracy: 0.8973\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.4567 - val_accuracy: 0.9029\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 41s 484ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.4881 - val_accuracy: 0.8968\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.5239 - val_accuracy: 0.8923\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.6478 - accuracy: 0.8772\n",
      "{'dense_units': 256, 'dropout_rate': 0.4, 'learning_rate': 1e-06, 'optimizer': 'rmsprop', 'activation': 'relu', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_38\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_116 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_117 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_116[0][0]                  \n",
      "                                                                 input_117[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 7, 7, 256)    2359552     concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 7, 7, 256)    0           conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 7, 7, 256)    590080      dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 7, 7, 256)    0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_77 (Flatten)            (None, 12544)        0           dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 2)            25090       flatten_77[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,999,106\n",
      "Trainable params: 10,054,146\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 42s 484ms/step - loss: 0.7287 - accuracy: 0.5125 - val_loss: 0.6867 - val_accuracy: 0.5608\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.7168 - accuracy: 0.5284 - val_loss: 0.6744 - val_accuracy: 0.6311\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.6960 - accuracy: 0.5639 - val_loss: 0.6621 - val_accuracy: 0.6451\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.6808 - accuracy: 0.6058 - val_loss: 0.6468 - val_accuracy: 0.6987\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.6589 - accuracy: 0.6370 - val_loss: 0.6290 - val_accuracy: 0.7260\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.6454 - accuracy: 0.6596 - val_loss: 0.6109 - val_accuracy: 0.7327\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.6136 - accuracy: 0.7047 - val_loss: 0.5881 - val_accuracy: 0.7411\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.5878 - accuracy: 0.7285 - val_loss: 0.5642 - val_accuracy: 0.7478\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.5705 - accuracy: 0.7307 - val_loss: 0.5427 - val_accuracy: 0.7522\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.5391 - accuracy: 0.7609 - val_loss: 0.5219 - val_accuracy: 0.7600\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.5271 - accuracy: 0.7614 - val_loss: 0.5053 - val_accuracy: 0.7645\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.5029 - accuracy: 0.7749 - val_loss: 0.4908 - val_accuracy: 0.7740\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4919 - accuracy: 0.7792 - val_loss: 0.4800 - val_accuracy: 0.7790\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4736 - accuracy: 0.7906 - val_loss: 0.4716 - val_accuracy: 0.7768\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4625 - accuracy: 0.7941 - val_loss: 0.4630 - val_accuracy: 0.7885\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4645 - accuracy: 0.7914 - val_loss: 0.4557 - val_accuracy: 0.7863\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4473 - accuracy: 0.8032 - val_loss: 0.4476 - val_accuracy: 0.7935\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4400 - accuracy: 0.8111 - val_loss: 0.4442 - val_accuracy: 0.7958\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4402 - accuracy: 0.8032 - val_loss: 0.4395 - val_accuracy: 0.8002\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4313 - accuracy: 0.8132 - val_loss: 0.4319 - val_accuracy: 0.8058\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4236 - accuracy: 0.8157 - val_loss: 0.4318 - val_accuracy: 0.8036\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4241 - accuracy: 0.8193 - val_loss: 0.4281 - val_accuracy: 0.8036\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4177 - accuracy: 0.8213 - val_loss: 0.4202 - val_accuracy: 0.8103\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4107 - accuracy: 0.8198 - val_loss: 0.4169 - val_accuracy: 0.8075\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4014 - accuracy: 0.8272 - val_loss: 0.4180 - val_accuracy: 0.8069\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.4079 - accuracy: 0.8242 - val_loss: 0.4138 - val_accuracy: 0.8025\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3898 - accuracy: 0.8300 - val_loss: 0.4100 - val_accuracy: 0.8069\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3998 - accuracy: 0.8261 - val_loss: 0.4066 - val_accuracy: 0.8092\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.4098 - accuracy: 0.8164\n",
      "{'dense_units': 64, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'optimizer': 'sgd', 'activation': 'tanh', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_39\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_119 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_120 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_119[0][0]                  \n",
      "                                                                 input_120[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 7, 7, 64)     589888      concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 7, 7, 64)     0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 7, 7, 64)     36928       dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 7, 7, 64)     0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_79 (Flatten)            (None, 3136)         0           dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 2)            6274        flatten_79[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,657,474\n",
      "Trainable params: 7,712,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7518 - accuracy: 0.5138 - val_loss: 0.6892 - val_accuracy: 0.5441\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7520 - accuracy: 0.5082 - val_loss: 0.6832 - val_accuracy: 0.5759\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7339 - accuracy: 0.5217 - val_loss: 0.6775 - val_accuracy: 0.5999\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7249 - accuracy: 0.5422 - val_loss: 0.6719 - val_accuracy: 0.6250\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7195 - accuracy: 0.5520 - val_loss: 0.6658 - val_accuracy: 0.6507\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7191 - accuracy: 0.5585 - val_loss: 0.6594 - val_accuracy: 0.6713\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7080 - accuracy: 0.5714 - val_loss: 0.6539 - val_accuracy: 0.6635\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7083 - accuracy: 0.5642 - val_loss: 0.6477 - val_accuracy: 0.6908\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.6897 - accuracy: 0.5980 - val_loss: 0.6423 - val_accuracy: 0.6953\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.6866 - accuracy: 0.6113 - val_loss: 0.6354 - val_accuracy: 0.7065\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.6727 - accuracy: 0.6346 - val_loss: 0.6298 - val_accuracy: 0.7154\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.6678 - accuracy: 0.6285 - val_loss: 0.6228 - val_accuracy: 0.7243\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.6558 - accuracy: 0.6439 - val_loss: 0.6166 - val_accuracy: 0.7288\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.6560 - accuracy: 0.6450 - val_loss: 0.6086 - val_accuracy: 0.7355\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.6453 - accuracy: 0.6600 - val_loss: 0.6026 - val_accuracy: 0.7405\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.6334 - accuracy: 0.6801 - val_loss: 0.5965 - val_accuracy: 0.7394\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.6288 - accuracy: 0.6862 - val_loss: 0.5883 - val_accuracy: 0.7439\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.6278 - accuracy: 0.6932 - val_loss: 0.5829 - val_accuracy: 0.7461\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.6083 - accuracy: 0.7052 - val_loss: 0.5750 - val_accuracy: 0.7494\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6014 - accuracy: 0.7145 - val_loss: 0.5692 - val_accuracy: 0.7528\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 40s 479ms/step - loss: 0.5918 - accuracy: 0.7126 - val_loss: 0.5640 - val_accuracy: 0.7511\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5839 - accuracy: 0.7198 - val_loss: 0.5557 - val_accuracy: 0.7584\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5750 - accuracy: 0.7309 - val_loss: 0.5496 - val_accuracy: 0.7545\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5737 - accuracy: 0.7280 - val_loss: 0.5445 - val_accuracy: 0.7578\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5586 - accuracy: 0.7387 - val_loss: 0.5384 - val_accuracy: 0.7589\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5571 - accuracy: 0.7331 - val_loss: 0.5324 - val_accuracy: 0.7606\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5483 - accuracy: 0.7479 - val_loss: 0.5268 - val_accuracy: 0.7617\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5383 - accuracy: 0.7597 - val_loss: 0.5212 - val_accuracy: 0.7656\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5321 - accuracy: 0.7616 - val_loss: 0.5178 - val_accuracy: 0.7628\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5235 - accuracy: 0.7660 - val_loss: 0.5122 - val_accuracy: 0.7651\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5207 - accuracy: 0.7653 - val_loss: 0.5052 - val_accuracy: 0.7701\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5132 - accuracy: 0.7649 - val_loss: 0.5019 - val_accuracy: 0.7690\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5116 - accuracy: 0.7673 - val_loss: 0.4967 - val_accuracy: 0.7723\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5078 - accuracy: 0.7732 - val_loss: 0.4942 - val_accuracy: 0.7740\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.5048 - accuracy: 0.7736 - val_loss: 0.4914 - val_accuracy: 0.7768\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4880 - accuracy: 0.7880 - val_loss: 0.4888 - val_accuracy: 0.7779\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4948 - accuracy: 0.7801 - val_loss: 0.4844 - val_accuracy: 0.7773\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4909 - accuracy: 0.7825 - val_loss: 0.4822 - val_accuracy: 0.7818\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4843 - accuracy: 0.7768 - val_loss: 0.4784 - val_accuracy: 0.7829\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4822 - accuracy: 0.7858 - val_loss: 0.4763 - val_accuracy: 0.7857\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4840 - accuracy: 0.7814 - val_loss: 0.4717 - val_accuracy: 0.7868\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4743 - accuracy: 0.7860 - val_loss: 0.4730 - val_accuracy: 0.7879\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4729 - accuracy: 0.7884 - val_loss: 0.4684 - val_accuracy: 0.7902\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4715 - accuracy: 0.7862 - val_loss: 0.4677 - val_accuracy: 0.7891\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4598 - accuracy: 0.8013 - val_loss: 0.4637 - val_accuracy: 0.7924\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.4666 - accuracy: 0.7926 - val_loss: 0.4634 - val_accuracy: 0.7907\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4623 - accuracy: 0.7960 - val_loss: 0.4654 - val_accuracy: 0.7896\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4642 - accuracy: 0.7871 - val_loss: 0.4602 - val_accuracy: 0.7930\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4565 - accuracy: 0.7987 - val_loss: 0.4576 - val_accuracy: 0.7919\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4624 - accuracy: 0.7943 - val_loss: 0.4535 - val_accuracy: 0.7963\n",
      "28/28 [==============================] - 9s 327ms/step - loss: 0.4479 - accuracy: 0.7974\n",
      "{'dense_units': 32, 'dropout_rate': 0.2, 'learning_rate': 1e-06, 'optimizer': 'sgd', 'activation': 'tanh', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_40\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_122 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_123 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_122[0][0]                  \n",
      "                                                                 input_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 7, 7, 32)     294944      concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 7, 7, 32)     0           conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 7, 7, 32)     9248        dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 7, 7, 32)     0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_81 (Flatten)            (None, 1568)         0           dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 2)            3138        flatten_81[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,331,714\n",
      "Trainable params: 7,386,754\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7452 - accuracy: 0.4753 - val_loss: 0.7184 - val_accuracy: 0.5073\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7422 - accuracy: 0.4827 - val_loss: 0.7174 - val_accuracy: 0.5100\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7398 - accuracy: 0.4809 - val_loss: 0.7173 - val_accuracy: 0.5078\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7442 - accuracy: 0.4727 - val_loss: 0.7180 - val_accuracy: 0.5045\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7458 - accuracy: 0.4746 - val_loss: 0.7187 - val_accuracy: 0.5006\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7440 - accuracy: 0.4735 - val_loss: 0.7169 - val_accuracy: 0.5056\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7449 - accuracy: 0.4666 - val_loss: 0.7175 - val_accuracy: 0.5017\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.7272 - accuracy: 0.4743\n",
      "{'dense_units': 512, 'dropout_rate': 0.3, 'learning_rate': 1e-06, 'optimizer': 'rmsprop', 'activation': 'tanh', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_41\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_125 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_126 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_125[0][0]                  \n",
      "                                                                 input_126[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 7, 7, 512)    4719104     concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 7, 7, 512)    0           conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 7, 7, 512)    2359808     dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 7, 7, 512)    0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_83 (Flatten)            (None, 25088)        0           dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 2)            50178       flatten_83[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 27,153,474\n",
      "Trainable params: 14,208,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 42s 493ms/step - loss: 0.7047 - accuracy: 0.5548 - val_loss: 0.6557 - val_accuracy: 0.6574\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.6585 - accuracy: 0.6457 - val_loss: 0.6155 - val_accuracy: 0.7132\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.6127 - accuracy: 0.7019 - val_loss: 0.5722 - val_accuracy: 0.7584\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.5569 - accuracy: 0.7466 - val_loss: 0.5288 - val_accuracy: 0.7701\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.5169 - accuracy: 0.7719 - val_loss: 0.4956 - val_accuracy: 0.7785\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.4803 - accuracy: 0.7878 - val_loss: 0.4747 - val_accuracy: 0.7924\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.4626 - accuracy: 0.7925 - val_loss: 0.4568 - val_accuracy: 0.7997\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.4474 - accuracy: 0.7989 - val_loss: 0.4393 - val_accuracy: 0.7924\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.4262 - accuracy: 0.8117 - val_loss: 0.4339 - val_accuracy: 0.8114\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.4164 - accuracy: 0.8161 - val_loss: 0.4278 - val_accuracy: 0.8075\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.4119 - accuracy: 0.8193 - val_loss: 0.4215 - val_accuracy: 0.8058\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.4035 - accuracy: 0.8228 - val_loss: 0.4164 - val_accuracy: 0.8103\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.4000 - accuracy: 0.8254 - val_loss: 0.4097 - val_accuracy: 0.8158\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3842 - accuracy: 0.8316 - val_loss: 0.4033 - val_accuracy: 0.8198\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3940 - accuracy: 0.8242 - val_loss: 0.4044 - val_accuracy: 0.8064\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3713 - accuracy: 0.8400 - val_loss: 0.3993 - val_accuracy: 0.8175\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3850 - accuracy: 0.8318 - val_loss: 0.3955 - val_accuracy: 0.8231\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3735 - accuracy: 0.8425 - val_loss: 0.3900 - val_accuracy: 0.8253\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.3677 - accuracy: 0.8394 - val_loss: 0.3880 - val_accuracy: 0.8237\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3627 - accuracy: 0.8429 - val_loss: 0.3933 - val_accuracy: 0.8186\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3623 - accuracy: 0.8440 - val_loss: 0.3838 - val_accuracy: 0.8276\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3571 - accuracy: 0.8461 - val_loss: 0.3816 - val_accuracy: 0.8265\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3608 - accuracy: 0.8420 - val_loss: 0.3789 - val_accuracy: 0.8292\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3541 - accuracy: 0.8488 - val_loss: 0.3795 - val_accuracy: 0.8276\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3456 - accuracy: 0.8562 - val_loss: 0.3776 - val_accuracy: 0.8292\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3448 - accuracy: 0.8586 - val_loss: 0.3755 - val_accuracy: 0.8281\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.3432 - accuracy: 0.8527 - val_loss: 0.3706 - val_accuracy: 0.8292\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3433 - accuracy: 0.8512 - val_loss: 0.3743 - val_accuracy: 0.8287\n",
      "28/28 [==============================] - 9s 330ms/step - loss: 0.3925 - accuracy: 0.8214\n",
      "{'dense_units': 32, 'dropout_rate': 0.3, 'learning_rate': 1e-05, 'optimizer': 'adam', 'activation': 'tanh', 'learning_rate_decay': 0.001}\n",
      "Model: \"model_42\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_128 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_129 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_128[0][0]                  \n",
      "                                                                 input_129[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 7, 7, 32)     294944      concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 7, 7, 32)     0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 7, 7, 32)     9248        dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 7, 7, 32)     0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_85 (Flatten)            (None, 1568)         0           dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 2)            3138        flatten_85[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,331,714\n",
      "Trainable params: 7,386,754\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6345 - accuracy: 0.6649 - val_loss: 0.5271 - val_accuracy: 0.7612\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4773 - accuracy: 0.7895 - val_loss: 0.4422 - val_accuracy: 0.8041\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4174 - accuracy: 0.8217 - val_loss: 0.4100 - val_accuracy: 0.8192\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3914 - accuracy: 0.8359 - val_loss: 0.3931 - val_accuracy: 0.8265\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3643 - accuracy: 0.8523 - val_loss: 0.3770 - val_accuracy: 0.8410\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3531 - accuracy: 0.8566 - val_loss: 0.3679 - val_accuracy: 0.8438\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3319 - accuracy: 0.8664 - val_loss: 0.3598 - val_accuracy: 0.8471\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3065 - accuracy: 0.8845 - val_loss: 0.3522 - val_accuracy: 0.8510\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3043 - accuracy: 0.8852 - val_loss: 0.3493 - val_accuracy: 0.8510\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3027 - accuracy: 0.8841 - val_loss: 0.3411 - val_accuracy: 0.8477\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2718 - accuracy: 0.9008 - val_loss: 0.3326 - val_accuracy: 0.8599\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2773 - accuracy: 0.8996 - val_loss: 0.3261 - val_accuracy: 0.8577\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2602 - accuracy: 0.9074 - val_loss: 0.3214 - val_accuracy: 0.8644\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2561 - accuracy: 0.9094 - val_loss: 0.3198 - val_accuracy: 0.8666\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2441 - accuracy: 0.9194 - val_loss: 0.3131 - val_accuracy: 0.8622\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2301 - accuracy: 0.9239 - val_loss: 0.3084 - val_accuracy: 0.8717\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2278 - accuracy: 0.9229 - val_loss: 0.3036 - val_accuracy: 0.8717\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2198 - accuracy: 0.9313 - val_loss: 0.3018 - val_accuracy: 0.8750\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2111 - accuracy: 0.9342 - val_loss: 0.2958 - val_accuracy: 0.8756\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2014 - accuracy: 0.9396 - val_loss: 0.2937 - val_accuracy: 0.8789\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1937 - accuracy: 0.9422 - val_loss: 0.2850 - val_accuracy: 0.8811\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1879 - accuracy: 0.9459 - val_loss: 0.2815 - val_accuracy: 0.8845\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1775 - accuracy: 0.9508 - val_loss: 0.2761 - val_accuracy: 0.8890\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1731 - accuracy: 0.9546 - val_loss: 0.2774 - val_accuracy: 0.8901\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.1678 - accuracy: 0.9540 - val_loss: 0.2689 - val_accuracy: 0.8917\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1602 - accuracy: 0.9599 - val_loss: 0.2686 - val_accuracy: 0.8923\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1551 - accuracy: 0.9623 - val_loss: 0.2639 - val_accuracy: 0.8917\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1476 - accuracy: 0.9660 - val_loss: 0.2647 - val_accuracy: 0.8940\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1455 - accuracy: 0.9664 - val_loss: 0.2610 - val_accuracy: 0.8956\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1393 - accuracy: 0.9667 - val_loss: 0.2560 - val_accuracy: 0.8973\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1330 - accuracy: 0.9690 - val_loss: 0.2531 - val_accuracy: 0.9007\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1306 - accuracy: 0.9725 - val_loss: 0.2555 - val_accuracy: 0.8962\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1206 - accuracy: 0.9754 - val_loss: 0.2490 - val_accuracy: 0.9029\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.1217 - accuracy: 0.9775 - val_loss: 0.2471 - val_accuracy: 0.9035\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1122 - accuracy: 0.9813 - val_loss: 0.2474 - val_accuracy: 0.9007\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1148 - accuracy: 0.9771 - val_loss: 0.2476 - val_accuracy: 0.8962\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1060 - accuracy: 0.9793 - val_loss: 0.2436 - val_accuracy: 0.8973\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1005 - accuracy: 0.9821 - val_loss: 0.2401 - val_accuracy: 0.9046\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1028 - accuracy: 0.9821 - val_loss: 0.2387 - val_accuracy: 0.9046\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0958 - accuracy: 0.9845 - val_loss: 0.2390 - val_accuracy: 0.9057\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0917 - accuracy: 0.9852 - val_loss: 0.2365 - val_accuracy: 0.9035\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0912 - accuracy: 0.9848 - val_loss: 0.2326 - val_accuracy: 0.9057\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0830 - accuracy: 0.9884 - val_loss: 0.2369 - val_accuracy: 0.9046\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0831 - accuracy: 0.9867 - val_loss: 0.2371 - val_accuracy: 0.9051\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0812 - accuracy: 0.9869 - val_loss: 0.2293 - val_accuracy: 0.9074\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0792 - accuracy: 0.9884 - val_loss: 0.2275 - val_accuracy: 0.9102\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0731 - accuracy: 0.9902 - val_loss: 0.2285 - val_accuracy: 0.9113\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0749 - accuracy: 0.9898 - val_loss: 0.2291 - val_accuracy: 0.9085\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0683 - accuracy: 0.9902 - val_loss: 0.2310 - val_accuracy: 0.9085\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0656 - accuracy: 0.9909 - val_loss: 0.2225 - val_accuracy: 0.9096\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.3058 - accuracy: 0.8878\n",
      "{'dense_units': 512, 'dropout_rate': 0.5, 'learning_rate': 1e-05, 'optimizer': 'sgd', 'activation': 'sigmoid', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_43\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_131 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_132 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_131[0][0]                  \n",
      "                                                                 input_132[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 7, 7, 512)    4719104     concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 7, 7, 512)    0           conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 7, 7, 512)    2359808     dropout_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 7, 7, 512)    0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_87 (Flatten)            (None, 25088)        0           dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 2)            50178       flatten_87[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 27,153,474\n",
      "Trainable params: 14,208,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 42s 489ms/step - loss: 0.7797 - accuracy: 0.5147 - val_loss: 0.7083 - val_accuracy: 0.5268\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7646 - accuracy: 0.5104 - val_loss: 0.6966 - val_accuracy: 0.5262\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7564 - accuracy: 0.5145 - val_loss: 0.6921 - val_accuracy: 0.5268\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7591 - accuracy: 0.5077 - val_loss: 0.6910 - val_accuracy: 0.5268\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7572 - accuracy: 0.5053 - val_loss: 0.6908 - val_accuracy: 0.5268\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7562 - accuracy: 0.5036 - val_loss: 0.6909 - val_accuracy: 0.5262\n",
      "28/28 [==============================] - 9s 330ms/step - loss: 0.6936 - accuracy: 0.5011\n",
      "{'dense_units': 256, 'dropout_rate': 0.3, 'learning_rate': 0.0001, 'optimizer': 'sgd', 'activation': 'sigmoid', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_44\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_134 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_135 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_134[0][0]                  \n",
      "                                                                 input_135[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 7, 7, 256)    2359552     concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 7, 7, 256)    0           conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 7, 7, 256)    590080      dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 7, 7, 256)    0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_89 (Flatten)            (None, 12544)        0           dropout_89[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 2)            25090       flatten_89[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,999,106\n",
      "Trainable params: 10,054,146\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.7266 - accuracy: 0.4999 - val_loss: 0.6925 - val_accuracy: 0.5257\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7235 - accuracy: 0.4997 - val_loss: 0.6925 - val_accuracy: 0.5234\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7232 - accuracy: 0.4958 - val_loss: 0.6921 - val_accuracy: 0.5279\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7219 - accuracy: 0.5029 - val_loss: 0.6921 - val_accuracy: 0.5296\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7217 - accuracy: 0.5058 - val_loss: 0.6924 - val_accuracy: 0.5257\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7231 - accuracy: 0.5008 - val_loss: 0.6918 - val_accuracy: 0.5285\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7217 - accuracy: 0.5073 - val_loss: 0.6925 - val_accuracy: 0.5257\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7220 - accuracy: 0.5030 - val_loss: 0.6920 - val_accuracy: 0.5285\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7252 - accuracy: 0.4979 - val_loss: 0.6922 - val_accuracy: 0.5268\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.6932 - accuracy: 0.5033\n",
      "{'dense_units': 512, 'dropout_rate': 0.4, 'learning_rate': 1e-06, 'optimizer': 'adam', 'activation': 'sigmoid', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_45\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_137 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_138 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_137[0][0]                  \n",
      "                                                                 input_138[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 7, 7, 512)    4719104     concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 7, 7, 512)    0           conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 7, 7, 512)    2359808     dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 7, 7, 512)    0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_91 (Flatten)            (None, 25088)        0           dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 2)            50178       flatten_91[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 27,153,474\n",
      "Trainable params: 14,208,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 42s 490ms/step - loss: 0.7767 - accuracy: 0.4933 - val_loss: 0.6907 - val_accuracy: 0.5391\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.7328 - accuracy: 0.4997 - val_loss: 0.6867 - val_accuracy: 0.5251\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7289 - accuracy: 0.5173 - val_loss: 0.6821 - val_accuracy: 0.5452\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.7275 - accuracy: 0.5184 - val_loss: 0.6743 - val_accuracy: 0.6239\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.7083 - accuracy: 0.5505 - val_loss: 0.6610 - val_accuracy: 0.6501\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.6916 - accuracy: 0.5875 - val_loss: 0.6386 - val_accuracy: 0.7706\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.6559 - accuracy: 0.6479 - val_loss: 0.6044 - val_accuracy: 0.7729\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.6134 - accuracy: 0.6953 - val_loss: 0.5621 - val_accuracy: 0.7779\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.5648 - accuracy: 0.7403 - val_loss: 0.5240 - val_accuracy: 0.7868\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.5249 - accuracy: 0.7699 - val_loss: 0.4936 - val_accuracy: 0.7902\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4954 - accuracy: 0.7782 - val_loss: 0.4742 - val_accuracy: 0.7935\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4788 - accuracy: 0.7899 - val_loss: 0.4592 - val_accuracy: 0.8002\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4662 - accuracy: 0.7993 - val_loss: 0.4459 - val_accuracy: 0.8036\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4521 - accuracy: 0.7969 - val_loss: 0.4413 - val_accuracy: 0.8036\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4386 - accuracy: 0.8096 - val_loss: 0.4327 - val_accuracy: 0.8047\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4378 - accuracy: 0.8065 - val_loss: 0.4266 - val_accuracy: 0.8086\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4253 - accuracy: 0.8152 - val_loss: 0.4232 - val_accuracy: 0.8119\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4326 - accuracy: 0.8065 - val_loss: 0.4168 - val_accuracy: 0.8108\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4156 - accuracy: 0.8209 - val_loss: 0.4146 - val_accuracy: 0.8142\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4226 - accuracy: 0.8133 - val_loss: 0.4129 - val_accuracy: 0.8114\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4187 - accuracy: 0.8150 - val_loss: 0.4067 - val_accuracy: 0.8186\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4093 - accuracy: 0.8187 - val_loss: 0.4020 - val_accuracy: 0.8142\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.4088 - accuracy: 0.8222 - val_loss: 0.4001 - val_accuracy: 0.8158\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4073 - accuracy: 0.8217 - val_loss: 0.3990 - val_accuracy: 0.8192\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3945 - accuracy: 0.8255 - val_loss: 0.3971 - val_accuracy: 0.8158\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.4148 - accuracy: 0.8172 - val_loss: 0.3961 - val_accuracy: 0.8175\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3860 - accuracy: 0.8326 - val_loss: 0.3913 - val_accuracy: 0.8203\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3922 - accuracy: 0.8305 - val_loss: 0.3928 - val_accuracy: 0.8198\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.3885 - accuracy: 0.8307 - val_loss: 0.3899 - val_accuracy: 0.8209\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3893 - accuracy: 0.8324 - val_loss: 0.3830 - val_accuracy: 0.8248\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3880 - accuracy: 0.8324 - val_loss: 0.3811 - val_accuracy: 0.8259\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3891 - accuracy: 0.8315 - val_loss: 0.3821 - val_accuracy: 0.8242\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3786 - accuracy: 0.8313 - val_loss: 0.3785 - val_accuracy: 0.8276\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3807 - accuracy: 0.8337 - val_loss: 0.3785 - val_accuracy: 0.8265\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.3744 - accuracy: 0.8396 - val_loss: 0.3794 - val_accuracy: 0.8265\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3803 - accuracy: 0.8377 - val_loss: 0.3788 - val_accuracy: 0.8270\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3713 - accuracy: 0.8412 - val_loss: 0.3772 - val_accuracy: 0.8265\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3774 - accuracy: 0.8374 - val_loss: 0.3762 - val_accuracy: 0.8287\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3737 - accuracy: 0.8396 - val_loss: 0.3724 - val_accuracy: 0.8304\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3718 - accuracy: 0.8414 - val_loss: 0.3716 - val_accuracy: 0.8304\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.3693 - accuracy: 0.8401 - val_loss: 0.3723 - val_accuracy: 0.8304\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3579 - accuracy: 0.8507 - val_loss: 0.3735 - val_accuracy: 0.8309\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3684 - accuracy: 0.8414 - val_loss: 0.3695 - val_accuracy: 0.8326\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3607 - accuracy: 0.8490 - val_loss: 0.3686 - val_accuracy: 0.8354\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3613 - accuracy: 0.8481 - val_loss: 0.3681 - val_accuracy: 0.8348\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3616 - accuracy: 0.8466 - val_loss: 0.3672 - val_accuracy: 0.8304\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3612 - accuracy: 0.8453 - val_loss: 0.3661 - val_accuracy: 0.8320\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3594 - accuracy: 0.8458 - val_loss: 0.3672 - val_accuracy: 0.8343\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 41s 490ms/step - loss: 0.3530 - accuracy: 0.8503 - val_loss: 0.3617 - val_accuracy: 0.8371\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.3500 - accuracy: 0.8549 - val_loss: 0.3636 - val_accuracy: 0.8354\n",
      "28/28 [==============================] - 9s 330ms/step - loss: 0.3861 - accuracy: 0.8292\n",
      "{'dense_units': 32, 'dropout_rate': 0.6, 'learning_rate': 1e-06, 'optimizer': 'rmsprop', 'activation': 'tanh', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_46\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_140 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_141 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_140[0][0]                  \n",
      "                                                                 input_141[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 7, 7, 32)     294944      concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 7, 7, 32)     0           conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 7, 7, 32)     9248        dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)            (None, 7, 7, 32)     0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_93 (Flatten)            (None, 1568)         0           dropout_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 2)            3138        flatten_93[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,331,714\n",
      "Trainable params: 7,386,754\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.8436 - accuracy: 0.5066 - val_loss: 0.6847 - val_accuracy: 0.5463\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.8284 - accuracy: 0.5143 - val_loss: 0.6755 - val_accuracy: 0.5809\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.8191 - accuracy: 0.5239 - val_loss: 0.6665 - val_accuracy: 0.6105\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.7994 - accuracy: 0.5465 - val_loss: 0.6576 - val_accuracy: 0.6535\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7934 - accuracy: 0.5308 - val_loss: 0.6474 - val_accuracy: 0.6847\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.7708 - accuracy: 0.5611 - val_loss: 0.6356 - val_accuracy: 0.7037\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.7582 - accuracy: 0.5659 - val_loss: 0.6247 - val_accuracy: 0.7193\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.7375 - accuracy: 0.5971 - val_loss: 0.6122 - val_accuracy: 0.7277\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.7218 - accuracy: 0.6027 - val_loss: 0.5984 - val_accuracy: 0.7372\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6994 - accuracy: 0.6274 - val_loss: 0.5863 - val_accuracy: 0.7450\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6800 - accuracy: 0.6492 - val_loss: 0.5740 - val_accuracy: 0.7450\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6694 - accuracy: 0.6601 - val_loss: 0.5643 - val_accuracy: 0.7483\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6474 - accuracy: 0.6755 - val_loss: 0.5516 - val_accuracy: 0.7567\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6342 - accuracy: 0.6930 - val_loss: 0.5438 - val_accuracy: 0.7550\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6197 - accuracy: 0.7128 - val_loss: 0.5315 - val_accuracy: 0.7567\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6115 - accuracy: 0.7213 - val_loss: 0.5229 - val_accuracy: 0.7640\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5957 - accuracy: 0.7276 - val_loss: 0.5177 - val_accuracy: 0.7712\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5836 - accuracy: 0.7315 - val_loss: 0.5081 - val_accuracy: 0.7785\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5832 - accuracy: 0.7330 - val_loss: 0.5028 - val_accuracy: 0.7779\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5777 - accuracy: 0.7402 - val_loss: 0.4973 - val_accuracy: 0.7868\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5559 - accuracy: 0.7564 - val_loss: 0.4912 - val_accuracy: 0.7852\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5573 - accuracy: 0.7501 - val_loss: 0.4856 - val_accuracy: 0.7868\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5437 - accuracy: 0.7536 - val_loss: 0.4823 - val_accuracy: 0.7874\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5484 - accuracy: 0.7555 - val_loss: 0.4781 - val_accuracy: 0.7879\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5482 - accuracy: 0.7629 - val_loss: 0.4722 - val_accuracy: 0.7902\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5298 - accuracy: 0.7701 - val_loss: 0.4676 - val_accuracy: 0.7919\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5264 - accuracy: 0.7657 - val_loss: 0.4670 - val_accuracy: 0.7924\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5182 - accuracy: 0.7803 - val_loss: 0.4610 - val_accuracy: 0.7958\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5165 - accuracy: 0.7792 - val_loss: 0.4594 - val_accuracy: 0.7946\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5150 - accuracy: 0.7784 - val_loss: 0.4554 - val_accuracy: 0.7952\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5080 - accuracy: 0.7830 - val_loss: 0.4518 - val_accuracy: 0.7991\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5022 - accuracy: 0.7880 - val_loss: 0.4512 - val_accuracy: 0.7969\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5045 - accuracy: 0.7867 - val_loss: 0.4470 - val_accuracy: 0.8013\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4866 - accuracy: 0.7973 - val_loss: 0.4442 - val_accuracy: 0.8008\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5018 - accuracy: 0.7886 - val_loss: 0.4423 - val_accuracy: 0.8002\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4917 - accuracy: 0.7952 - val_loss: 0.4384 - val_accuracy: 0.8036\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4821 - accuracy: 0.7943 - val_loss: 0.4359 - val_accuracy: 0.8064\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4852 - accuracy: 0.7947 - val_loss: 0.4364 - val_accuracy: 0.8058\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4776 - accuracy: 0.8047 - val_loss: 0.4341 - val_accuracy: 0.8064\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4734 - accuracy: 0.7995 - val_loss: 0.4292 - val_accuracy: 0.8092\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4854 - accuracy: 0.7930 - val_loss: 0.4284 - val_accuracy: 0.8097\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4698 - accuracy: 0.8037 - val_loss: 0.4262 - val_accuracy: 0.8108\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4786 - accuracy: 0.7956 - val_loss: 0.4281 - val_accuracy: 0.8086\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4656 - accuracy: 0.8028 - val_loss: 0.4256 - val_accuracy: 0.8064\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4674 - accuracy: 0.8065 - val_loss: 0.4223 - val_accuracy: 0.8142\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4639 - accuracy: 0.8109 - val_loss: 0.4219 - val_accuracy: 0.8136\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4578 - accuracy: 0.8085 - val_loss: 0.4217 - val_accuracy: 0.8114\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4600 - accuracy: 0.8133 - val_loss: 0.4201 - val_accuracy: 0.8097\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4663 - accuracy: 0.8026 - val_loss: 0.4190 - val_accuracy: 0.8147\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4532 - accuracy: 0.8126 - val_loss: 0.4171 - val_accuracy: 0.8136\n",
      "28/28 [==============================] - 9s 327ms/step - loss: 0.4151 - accuracy: 0.8136\n",
      "{'dense_units': 256, 'dropout_rate': 0.5, 'learning_rate': 0.0001, 'optimizer': 'rmsprop', 'activation': 'sigmoid', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_47\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_143 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_144 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_143[0][0]                  \n",
      "                                                                 input_144[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 7, 7, 256)    2359552     concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)            (None, 7, 7, 256)    0           conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 7, 7, 256)    590080      dropout_94[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)            (None, 7, 7, 256)    0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_95 (Flatten)            (None, 12544)        0           dropout_95[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 2)            25090       flatten_95[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,999,106\n",
      "Trainable params: 10,054,146\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 42s 485ms/step - loss: 0.4792 - accuracy: 0.7779 - val_loss: 0.3774 - val_accuracy: 0.8348\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3802 - accuracy: 0.8398 - val_loss: 0.3804 - val_accuracy: 0.8331\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.3341 - accuracy: 0.8560 - val_loss: 0.3200 - val_accuracy: 0.8622\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.2858 - accuracy: 0.8841 - val_loss: 0.3027 - val_accuracy: 0.8638\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.2381 - accuracy: 0.9096 - val_loss: 0.3304 - val_accuracy: 0.8672\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.2046 - accuracy: 0.9216 - val_loss: 0.2926 - val_accuracy: 0.8800\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.1661 - accuracy: 0.9429 - val_loss: 0.3217 - val_accuracy: 0.8845\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.1298 - accuracy: 0.9566 - val_loss: 0.3813 - val_accuracy: 0.8756\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.1183 - accuracy: 0.9632 - val_loss: 0.2982 - val_accuracy: 0.8951\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0906 - accuracy: 0.9699 - val_loss: 0.3185 - val_accuracy: 0.8906\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0852 - accuracy: 0.9734 - val_loss: 0.3120 - val_accuracy: 0.8890\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0762 - accuracy: 0.9734 - val_loss: 0.3481 - val_accuracy: 0.8856\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0607 - accuracy: 0.9797 - val_loss: 0.3080 - val_accuracy: 0.9051\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0606 - accuracy: 0.9824 - val_loss: 0.3097 - val_accuracy: 0.9001\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0503 - accuracy: 0.9837 - val_loss: 0.4230 - val_accuracy: 0.8878\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0384 - accuracy: 0.9887 - val_loss: 0.4120 - val_accuracy: 0.8923\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0527 - accuracy: 0.9837 - val_loss: 0.3289 - val_accuracy: 0.9023\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 483ms/step - loss: 0.0368 - accuracy: 0.9889 - val_loss: 0.4628 - val_accuracy: 0.8767\n",
      "28/28 [==============================] - 9s 329ms/step - loss: 0.5241 - accuracy: 0.8806\n",
      "{'dense_units': 32, 'dropout_rate': 0.2, 'learning_rate': 1e-06, 'optimizer': 'sgd', 'activation': 'sigmoid', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_48\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_146 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_147 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_146[0][0]                  \n",
      "                                                                 input_147[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 7, 7, 32)     294944      concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)            (None, 7, 7, 32)     0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 7, 7, 32)     9248        dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 7, 7, 32)     0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_97 (Flatten)            (None, 1568)         0           dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 2)            3138        flatten_97[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,331,714\n",
      "Trainable params: 7,386,754\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.7452 - accuracy: 0.4877 - val_loss: 0.7370 - val_accuracy: 0.4738\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7507 - accuracy: 0.4814 - val_loss: 0.7366 - val_accuracy: 0.4738\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7487 - accuracy: 0.4809 - val_loss: 0.7358 - val_accuracy: 0.4749\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7468 - accuracy: 0.4883 - val_loss: 0.7350 - val_accuracy: 0.4760\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7472 - accuracy: 0.4833 - val_loss: 0.7369 - val_accuracy: 0.4710\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7465 - accuracy: 0.4831 - val_loss: 0.7344 - val_accuracy: 0.4760\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7474 - accuracy: 0.4838 - val_loss: 0.7352 - val_accuracy: 0.4732\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7462 - accuracy: 0.4831 - val_loss: 0.7342 - val_accuracy: 0.4749\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7458 - accuracy: 0.4873 - val_loss: 0.7348 - val_accuracy: 0.4727\n",
      "28/28 [==============================] - 9s 329ms/step - loss: 0.7235 - accuracy: 0.4989\n",
      "{'dense_units': 64, 'dropout_rate': 0.2, 'learning_rate': 1e-06, 'optimizer': 'sgd', 'activation': 'relu', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_49\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_149 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_150 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_149[0][0]                  \n",
      "                                                                 input_150[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 7, 7, 64)     589888      concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, 7, 7, 64)     0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 7, 7, 64)     36928       dropout_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)            (None, 7, 7, 64)     0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_99 (Flatten)            (None, 3136)         0           dropout_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 2)            6274        flatten_99[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,657,474\n",
      "Trainable params: 7,712,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.7337 - accuracy: 0.4866 - val_loss: 0.7305 - val_accuracy: 0.4743\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7358 - accuracy: 0.4787 - val_loss: 0.7301 - val_accuracy: 0.4743\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7320 - accuracy: 0.4781 - val_loss: 0.7292 - val_accuracy: 0.4743\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.7348 - accuracy: 0.4838 - val_loss: 0.7282 - val_accuracy: 0.4754\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7352 - accuracy: 0.4753 - val_loss: 0.7270 - val_accuracy: 0.4754\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7326 - accuracy: 0.4820 - val_loss: 0.7274 - val_accuracy: 0.4727\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7357 - accuracy: 0.4702 - val_loss: 0.7262 - val_accuracy: 0.4738\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7316 - accuracy: 0.4825 - val_loss: 0.7249 - val_accuracy: 0.4766\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7353 - accuracy: 0.4726 - val_loss: 0.7251 - val_accuracy: 0.4743\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7285 - accuracy: 0.4914 - val_loss: 0.7243 - val_accuracy: 0.4743\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7266 - accuracy: 0.4901 - val_loss: 0.7238 - val_accuracy: 0.4754\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7284 - accuracy: 0.4785 - val_loss: 0.7236 - val_accuracy: 0.4743\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7325 - accuracy: 0.4711 - val_loss: 0.7225 - val_accuracy: 0.4754\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.7137 - accuracy: 0.4972\n",
      "{'dense_units': 64, 'dropout_rate': 0.2, 'learning_rate': 0.0001, 'optimizer': 'sgd', 'activation': 'sigmoid', 'learning_rate_decay': 0.001}\n",
      "Model: \"model_50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_152 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_153 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_152[0][0]                  \n",
      "                                                                 input_153[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 7, 7, 64)     589888      concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, 7, 7, 64)     0           conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 7, 7, 64)     36928       dropout_100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)           (None, 7, 7, 64)     0           conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_101 (Flatten)           (None, 3136)         0           dropout_101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 2)            6274        flatten_101[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 20,657,474\n",
      "Trainable params: 7,712,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.7187 - accuracy: 0.5005 - val_loss: 0.6957 - val_accuracy: 0.5262\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7106 - accuracy: 0.5014 - val_loss: 0.6925 - val_accuracy: 0.5285\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7105 - accuracy: 0.5029 - val_loss: 0.6922 - val_accuracy: 0.5251\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7075 - accuracy: 0.5080 - val_loss: 0.6920 - val_accuracy: 0.5246\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7065 - accuracy: 0.5027 - val_loss: 0.6918 - val_accuracy: 0.5257\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7110 - accuracy: 0.4982 - val_loss: 0.6920 - val_accuracy: 0.5223\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7068 - accuracy: 0.5082 - val_loss: 0.6918 - val_accuracy: 0.5257\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.6934 - accuracy: 0.5050\n",
      "{'dense_units': 512, 'dropout_rate': 0.3, 'learning_rate': 1e-06, 'optimizer': 'rmsprop', 'activation': 'tanh', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_51\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_155 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_156 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_155[0][0]                  \n",
      "                                                                 input_156[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 7, 7, 512)    4719104     concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, 7, 7, 512)    0           conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 7, 7, 512)    2359808     dropout_102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, 7, 7, 512)    0           conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_103 (Flatten)           (None, 25088)        0           dropout_103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 2)            50178       flatten_103[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 27,153,474\n",
      "Trainable params: 14,208,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.6961 - accuracy: 0.5692 - val_loss: 0.6440 - val_accuracy: 0.7271\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.6450 - accuracy: 0.6616 - val_loss: 0.5978 - val_accuracy: 0.7455\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.5938 - accuracy: 0.7230 - val_loss: 0.5537 - val_accuracy: 0.7690\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.5401 - accuracy: 0.7512 - val_loss: 0.5140 - val_accuracy: 0.7701\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.4990 - accuracy: 0.7751 - val_loss: 0.4853 - val_accuracy: 0.7801\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.4709 - accuracy: 0.7928 - val_loss: 0.4664 - val_accuracy: 0.7879\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.4608 - accuracy: 0.7895 - val_loss: 0.4514 - val_accuracy: 0.7974\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.4340 - accuracy: 0.8060 - val_loss: 0.4426 - val_accuracy: 0.8036\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.4292 - accuracy: 0.8108 - val_loss: 0.4345 - val_accuracy: 0.7980\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.4060 - accuracy: 0.8213 - val_loss: 0.4286 - val_accuracy: 0.8064\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.4106 - accuracy: 0.8217 - val_loss: 0.4208 - val_accuracy: 0.8047\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.4007 - accuracy: 0.8233 - val_loss: 0.4163 - val_accuracy: 0.8052\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3891 - accuracy: 0.8300 - val_loss: 0.4097 - val_accuracy: 0.8092\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.4003 - accuracy: 0.8204 - val_loss: 0.4031 - val_accuracy: 0.8142\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3748 - accuracy: 0.8359 - val_loss: 0.4006 - val_accuracy: 0.8170\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3818 - accuracy: 0.8311 - val_loss: 0.3975 - val_accuracy: 0.8147\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3782 - accuracy: 0.8326 - val_loss: 0.3917 - val_accuracy: 0.8265\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3655 - accuracy: 0.8392 - val_loss: 0.3903 - val_accuracy: 0.8231\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3670 - accuracy: 0.8411 - val_loss: 0.3863 - val_accuracy: 0.8242\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3651 - accuracy: 0.8400 - val_loss: 0.3821 - val_accuracy: 0.8259\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3552 - accuracy: 0.8412 - val_loss: 0.3803 - val_accuracy: 0.8270\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3518 - accuracy: 0.8485 - val_loss: 0.3767 - val_accuracy: 0.8304\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.3520 - accuracy: 0.8472 - val_loss: 0.3747 - val_accuracy: 0.8326\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3414 - accuracy: 0.8514 - val_loss: 0.3716 - val_accuracy: 0.8359\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3395 - accuracy: 0.8562 - val_loss: 0.3707 - val_accuracy: 0.8348\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3340 - accuracy: 0.8571 - val_loss: 0.3702 - val_accuracy: 0.8365\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3388 - accuracy: 0.8588 - val_loss: 0.3664 - val_accuracy: 0.8359\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3272 - accuracy: 0.8662 - val_loss: 0.3642 - val_accuracy: 0.8410\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3299 - accuracy: 0.8581 - val_loss: 0.3646 - val_accuracy: 0.8376\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3220 - accuracy: 0.8612 - val_loss: 0.3600 - val_accuracy: 0.8371\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3201 - accuracy: 0.8645 - val_loss: 0.3576 - val_accuracy: 0.8421\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3270 - accuracy: 0.8623 - val_loss: 0.3587 - val_accuracy: 0.8371\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3053 - accuracy: 0.8721 - val_loss: 0.3543 - val_accuracy: 0.8421\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3070 - accuracy: 0.8729 - val_loss: 0.3548 - val_accuracy: 0.8426\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3129 - accuracy: 0.8732 - val_loss: 0.3565 - val_accuracy: 0.8359\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3010 - accuracy: 0.8727 - val_loss: 0.3470 - val_accuracy: 0.8465\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.3037 - accuracy: 0.8740 - val_loss: 0.3495 - val_accuracy: 0.8426\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.2994 - accuracy: 0.8760 - val_loss: 0.3440 - val_accuracy: 0.8454\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.2892 - accuracy: 0.8793 - val_loss: 0.3443 - val_accuracy: 0.8454\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 42s 491ms/step - loss: 0.2965 - accuracy: 0.8808 - val_loss: 0.3447 - val_accuracy: 0.8460\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.2821 - accuracy: 0.8886 - val_loss: 0.3410 - val_accuracy: 0.8449\n",
      "28/28 [==============================] - 9s 330ms/step - loss: 0.3637 - accuracy: 0.8393\n",
      "{'dense_units': 128, 'dropout_rate': 0.6, 'learning_rate': 0.0001, 'optimizer': 'sgd', 'activation': 'sigmoid', 'learning_rate_decay': 0.0001}\n",
      "Model: \"model_52\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_158 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_159 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_158[0][0]                  \n",
      "                                                                 input_159[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 7, 7, 128)    1179776     concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 7, 7, 128)    0           conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 7, 7, 128)    147584      dropout_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)           (None, 7, 7, 128)    0           conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_105 (Flatten)           (None, 6272)         0           dropout_105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 2)            12546       flatten_105[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 21,364,290\n",
      "Trainable params: 8,419,330\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.8034 - accuracy: 0.4986 - val_loss: 0.6918 - val_accuracy: 0.5251\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7917 - accuracy: 0.5055 - val_loss: 0.6920 - val_accuracy: 0.5257\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7926 - accuracy: 0.4984 - val_loss: 0.6915 - val_accuracy: 0.5246\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7975 - accuracy: 0.4982 - val_loss: 0.6913 - val_accuracy: 0.5268\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7929 - accuracy: 0.5043 - val_loss: 0.6910 - val_accuracy: 0.5285\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7934 - accuracy: 0.4986 - val_loss: 0.6912 - val_accuracy: 0.5257\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7918 - accuracy: 0.5014 - val_loss: 0.6913 - val_accuracy: 0.5246\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7915 - accuracy: 0.5038 - val_loss: 0.6912 - val_accuracy: 0.5262\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7935 - accuracy: 0.4999 - val_loss: 0.6911 - val_accuracy: 0.5273\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7923 - accuracy: 0.4986 - val_loss: 0.6911 - val_accuracy: 0.5257\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.6933 - accuracy: 0.5006\n",
      "{'dense_units': 128, 'dropout_rate': 0.4, 'learning_rate': 1e-06, 'optimizer': 'adam', 'activation': 'sigmoid', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_53\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_161 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_162 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_161[0][0]                  \n",
      "                                                                 input_162[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 7, 7, 128)    1179776     concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)           (None, 7, 7, 128)    0           conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 7, 7, 128)    147584      dropout_106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)           (None, 7, 7, 128)    0           conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_107 (Flatten)           (None, 6272)         0           dropout_107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 2)            12546       flatten_107[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 21,364,290\n",
      "Trainable params: 8,419,330\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7812 - accuracy: 0.5202 - val_loss: 0.7239 - val_accuracy: 0.5246\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7558 - accuracy: 0.5188 - val_loss: 0.6992 - val_accuracy: 0.5279\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7381 - accuracy: 0.5171 - val_loss: 0.6895 - val_accuracy: 0.5262\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7308 - accuracy: 0.5201 - val_loss: 0.6846 - val_accuracy: 0.5285\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7246 - accuracy: 0.5223 - val_loss: 0.6810 - val_accuracy: 0.5513\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7179 - accuracy: 0.5334 - val_loss: 0.6764 - val_accuracy: 0.6071\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7075 - accuracy: 0.5555 - val_loss: 0.6693 - val_accuracy: 0.6529\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7086 - accuracy: 0.5559 - val_loss: 0.6597 - val_accuracy: 0.7260\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6911 - accuracy: 0.5807 - val_loss: 0.6473 - val_accuracy: 0.7249\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6706 - accuracy: 0.6213 - val_loss: 0.6302 - val_accuracy: 0.7612\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6450 - accuracy: 0.6642 - val_loss: 0.6124 - val_accuracy: 0.7561\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6349 - accuracy: 0.6777 - val_loss: 0.5928 - val_accuracy: 0.7740\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6118 - accuracy: 0.7121 - val_loss: 0.5751 - val_accuracy: 0.7790\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5941 - accuracy: 0.7208 - val_loss: 0.5610 - val_accuracy: 0.7812\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5810 - accuracy: 0.7381 - val_loss: 0.5476 - val_accuracy: 0.7846\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5617 - accuracy: 0.7492 - val_loss: 0.5357 - val_accuracy: 0.7913\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5532 - accuracy: 0.7642 - val_loss: 0.5247 - val_accuracy: 0.7941\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5436 - accuracy: 0.7590 - val_loss: 0.5164 - val_accuracy: 0.7941\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5305 - accuracy: 0.7740 - val_loss: 0.5055 - val_accuracy: 0.8002\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5247 - accuracy: 0.7779 - val_loss: 0.4982 - val_accuracy: 0.8013\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5172 - accuracy: 0.7793 - val_loss: 0.4891 - val_accuracy: 0.8052\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.5029 - accuracy: 0.7884 - val_loss: 0.4814 - val_accuracy: 0.8019\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4972 - accuracy: 0.7941 - val_loss: 0.4767 - val_accuracy: 0.8058\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4898 - accuracy: 0.7997 - val_loss: 0.4699 - val_accuracy: 0.8058\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4866 - accuracy: 0.7932 - val_loss: 0.4648 - val_accuracy: 0.8058\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4792 - accuracy: 0.8024 - val_loss: 0.4590 - val_accuracy: 0.8080\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4741 - accuracy: 0.8021 - val_loss: 0.4534 - val_accuracy: 0.8097\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4687 - accuracy: 0.8061 - val_loss: 0.4501 - val_accuracy: 0.8097\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4653 - accuracy: 0.8069 - val_loss: 0.4447 - val_accuracy: 0.8125\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4598 - accuracy: 0.8119 - val_loss: 0.4384 - val_accuracy: 0.8175\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4582 - accuracy: 0.8067 - val_loss: 0.4355 - val_accuracy: 0.8175\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4477 - accuracy: 0.8133 - val_loss: 0.4328 - val_accuracy: 0.8158\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4510 - accuracy: 0.8084 - val_loss: 0.4313 - val_accuracy: 0.8153\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4445 - accuracy: 0.8154 - val_loss: 0.4277 - val_accuracy: 0.8158\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4406 - accuracy: 0.8163 - val_loss: 0.4242 - val_accuracy: 0.8186\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4317 - accuracy: 0.8230 - val_loss: 0.4234 - val_accuracy: 0.8203\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4314 - accuracy: 0.8235 - val_loss: 0.4168 - val_accuracy: 0.8220\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4313 - accuracy: 0.8156 - val_loss: 0.4153 - val_accuracy: 0.8225\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4246 - accuracy: 0.8169 - val_loss: 0.4085 - val_accuracy: 0.8276\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4157 - accuracy: 0.8322 - val_loss: 0.4083 - val_accuracy: 0.8220\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4197 - accuracy: 0.8272 - val_loss: 0.4037 - val_accuracy: 0.8248\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4272 - accuracy: 0.8167 - val_loss: 0.4055 - val_accuracy: 0.8259\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4109 - accuracy: 0.8309 - val_loss: 0.3999 - val_accuracy: 0.8287\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4071 - accuracy: 0.8303 - val_loss: 0.3983 - val_accuracy: 0.8270\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4065 - accuracy: 0.8311 - val_loss: 0.3940 - val_accuracy: 0.8309\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4088 - accuracy: 0.8281 - val_loss: 0.3970 - val_accuracy: 0.8287\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4032 - accuracy: 0.8348 - val_loss: 0.3919 - val_accuracy: 0.8337\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4020 - accuracy: 0.8303 - val_loss: 0.3892 - val_accuracy: 0.8343\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.3989 - accuracy: 0.8294 - val_loss: 0.3879 - val_accuracy: 0.8348\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4008 - accuracy: 0.8339 - val_loss: 0.3876 - val_accuracy: 0.8304\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.4014 - accuracy: 0.8231\n",
      "{'dense_units': 128, 'dropout_rate': 0.5, 'learning_rate': 1e-05, 'optimizer': 'sgd', 'activation': 'tanh', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_54\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_164 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_165 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_164[0][0]                  \n",
      "                                                                 input_165[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 7, 7, 128)    1179776     concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_108 (Dropout)           (None, 7, 7, 128)    0           conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 7, 7, 128)    147584      dropout_108[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_109 (Dropout)           (None, 7, 7, 128)    0           conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_109 (Flatten)           (None, 6272)         0           dropout_109[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 2)            12546       flatten_109[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 21,364,290\n",
      "Trainable params: 8,419,330\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7833 - accuracy: 0.5095 - val_loss: 0.7157 - val_accuracy: 0.4905\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7850 - accuracy: 0.5001 - val_loss: 0.7102 - val_accuracy: 0.4955\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7910 - accuracy: 0.4945 - val_loss: 0.7071 - val_accuracy: 0.4989\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7913 - accuracy: 0.4884 - val_loss: 0.7047 - val_accuracy: 0.5033\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7829 - accuracy: 0.4981 - val_loss: 0.7024 - val_accuracy: 0.5067\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7764 - accuracy: 0.5049 - val_loss: 0.7015 - val_accuracy: 0.5067\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7710 - accuracy: 0.5018 - val_loss: 0.6990 - val_accuracy: 0.5173\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7736 - accuracy: 0.5084 - val_loss: 0.6987 - val_accuracy: 0.5128\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7685 - accuracy: 0.5178 - val_loss: 0.6981 - val_accuracy: 0.5134\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7809 - accuracy: 0.5030 - val_loss: 0.6969 - val_accuracy: 0.5212\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7769 - accuracy: 0.5001 - val_loss: 0.6957 - val_accuracy: 0.5268\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7589 - accuracy: 0.5215 - val_loss: 0.6948 - val_accuracy: 0.5268\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7739 - accuracy: 0.5019 - val_loss: 0.6942 - val_accuracy: 0.5335\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7608 - accuracy: 0.5293 - val_loss: 0.6940 - val_accuracy: 0.5318\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7712 - accuracy: 0.5136 - val_loss: 0.6933 - val_accuracy: 0.5374\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7655 - accuracy: 0.5236 - val_loss: 0.6925 - val_accuracy: 0.5391\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7690 - accuracy: 0.5201 - val_loss: 0.6918 - val_accuracy: 0.5424\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7662 - accuracy: 0.5067 - val_loss: 0.6915 - val_accuracy: 0.5435\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7664 - accuracy: 0.5151 - val_loss: 0.6908 - val_accuracy: 0.5441\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7587 - accuracy: 0.5321 - val_loss: 0.6902 - val_accuracy: 0.5502\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7685 - accuracy: 0.5049 - val_loss: 0.6895 - val_accuracy: 0.5469\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7654 - accuracy: 0.5223 - val_loss: 0.6887 - val_accuracy: 0.5513\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7598 - accuracy: 0.5197 - val_loss: 0.6877 - val_accuracy: 0.5564\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7598 - accuracy: 0.5228 - val_loss: 0.6872 - val_accuracy: 0.5586\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7600 - accuracy: 0.5164 - val_loss: 0.6873 - val_accuracy: 0.5552\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7639 - accuracy: 0.5075 - val_loss: 0.6863 - val_accuracy: 0.5614\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7582 - accuracy: 0.5186 - val_loss: 0.6858 - val_accuracy: 0.5597\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7496 - accuracy: 0.5324 - val_loss: 0.6849 - val_accuracy: 0.5670\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7615 - accuracy: 0.5128 - val_loss: 0.6843 - val_accuracy: 0.5681\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7599 - accuracy: 0.5269 - val_loss: 0.6834 - val_accuracy: 0.5731\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7563 - accuracy: 0.5269 - val_loss: 0.6837 - val_accuracy: 0.5709\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7566 - accuracy: 0.5284 - val_loss: 0.6830 - val_accuracy: 0.5720\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7605 - accuracy: 0.5241 - val_loss: 0.6819 - val_accuracy: 0.5770\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7517 - accuracy: 0.5263 - val_loss: 0.6817 - val_accuracy: 0.5770\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7620 - accuracy: 0.5141 - val_loss: 0.6810 - val_accuracy: 0.5765\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7404 - accuracy: 0.5461 - val_loss: 0.6803 - val_accuracy: 0.5781\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7563 - accuracy: 0.5173 - val_loss: 0.6793 - val_accuracy: 0.5865\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7503 - accuracy: 0.5400 - val_loss: 0.6788 - val_accuracy: 0.5893\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7501 - accuracy: 0.5315 - val_loss: 0.6786 - val_accuracy: 0.5910\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7482 - accuracy: 0.5415 - val_loss: 0.6776 - val_accuracy: 0.5932\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7485 - accuracy: 0.5352 - val_loss: 0.6773 - val_accuracy: 0.5971\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7419 - accuracy: 0.5393 - val_loss: 0.6767 - val_accuracy: 0.6004\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7456 - accuracy: 0.5317 - val_loss: 0.6760 - val_accuracy: 0.6021\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7439 - accuracy: 0.5443 - val_loss: 0.6749 - val_accuracy: 0.6055\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7442 - accuracy: 0.5380 - val_loss: 0.6746 - val_accuracy: 0.6055\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7389 - accuracy: 0.5513 - val_loss: 0.6740 - val_accuracy: 0.6083\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7462 - accuracy: 0.5339 - val_loss: 0.6730 - val_accuracy: 0.6133\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.7429 - accuracy: 0.5457 - val_loss: 0.6730 - val_accuracy: 0.6099\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7422 - accuracy: 0.5330 - val_loss: 0.6726 - val_accuracy: 0.6138\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.7470 - accuracy: 0.5371 - val_loss: 0.6713 - val_accuracy: 0.6166\n",
      "28/28 [==============================] - 9s 327ms/step - loss: 0.6749 - accuracy: 0.6032\n",
      "{'dense_units': 512, 'dropout_rate': 0.5, 'learning_rate': 1e-05, 'optimizer': 'sgd', 'activation': 'relu', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_55\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_167 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_168 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_167[0][0]                  \n",
      "                                                                 input_168[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 7, 7, 512)    4719104     concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_110 (Dropout)           (None, 7, 7, 512)    0           conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 7, 7, 512)    2359808     dropout_110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)           (None, 7, 7, 512)    0           conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_111 (Flatten)           (None, 25088)        0           dropout_111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 2)            50178       flatten_111[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 27,153,474\n",
      "Trainable params: 14,208,514\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 42s 490ms/step - loss: 0.7549 - accuracy: 0.5029 - val_loss: 0.6975 - val_accuracy: 0.5240\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7408 - accuracy: 0.5117 - val_loss: 0.6950 - val_accuracy: 0.5223\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 487ms/step - loss: 0.7433 - accuracy: 0.5047 - val_loss: 0.6935 - val_accuracy: 0.5240\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7395 - accuracy: 0.5029 - val_loss: 0.6928 - val_accuracy: 0.5246\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7347 - accuracy: 0.5095 - val_loss: 0.6924 - val_accuracy: 0.5257\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7461 - accuracy: 0.4859 - val_loss: 0.6929 - val_accuracy: 0.5234\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7385 - accuracy: 0.5045 - val_loss: 0.6918 - val_accuracy: 0.5273\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 487ms/step - loss: 0.7405 - accuracy: 0.5036 - val_loss: 0.6916 - val_accuracy: 0.5285\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7377 - accuracy: 0.5082 - val_loss: 0.6910 - val_accuracy: 0.5312\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7406 - accuracy: 0.4997 - val_loss: 0.6909 - val_accuracy: 0.5312\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7368 - accuracy: 0.5036 - val_loss: 0.6904 - val_accuracy: 0.5340\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7400 - accuracy: 0.5060 - val_loss: 0.6904 - val_accuracy: 0.5285\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7356 - accuracy: 0.5141 - val_loss: 0.6899 - val_accuracy: 0.5312\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 487ms/step - loss: 0.7348 - accuracy: 0.5080 - val_loss: 0.6900 - val_accuracy: 0.5285\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7354 - accuracy: 0.5069 - val_loss: 0.6894 - val_accuracy: 0.5318\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7311 - accuracy: 0.5164 - val_loss: 0.6883 - val_accuracy: 0.5379\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 487ms/step - loss: 0.7256 - accuracy: 0.5269 - val_loss: 0.6888 - val_accuracy: 0.5357\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.7336 - accuracy: 0.5118 - val_loss: 0.6879 - val_accuracy: 0.5396\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 489ms/step - loss: 0.7283 - accuracy: 0.5210 - val_loss: 0.6881 - val_accuracy: 0.5357\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7310 - accuracy: 0.5188 - val_loss: 0.6874 - val_accuracy: 0.5402\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 487ms/step - loss: 0.7274 - accuracy: 0.5197 - val_loss: 0.6869 - val_accuracy: 0.5396\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 487ms/step - loss: 0.7298 - accuracy: 0.5199 - val_loss: 0.6871 - val_accuracy: 0.5374\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7266 - accuracy: 0.5178 - val_loss: 0.6863 - val_accuracy: 0.5413\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7378 - accuracy: 0.4992 - val_loss: 0.6860 - val_accuracy: 0.5430\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 487ms/step - loss: 0.7287 - accuracy: 0.5121 - val_loss: 0.6859 - val_accuracy: 0.5430\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7255 - accuracy: 0.5232 - val_loss: 0.6856 - val_accuracy: 0.5419\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7283 - accuracy: 0.5171 - val_loss: 0.6853 - val_accuracy: 0.5413\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 487ms/step - loss: 0.7215 - accuracy: 0.5334 - val_loss: 0.6847 - val_accuracy: 0.5441\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7243 - accuracy: 0.5217 - val_loss: 0.6846 - val_accuracy: 0.5452\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7242 - accuracy: 0.5256 - val_loss: 0.6839 - val_accuracy: 0.5474\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7277 - accuracy: 0.5134 - val_loss: 0.6837 - val_accuracy: 0.5491\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7254 - accuracy: 0.5156 - val_loss: 0.6836 - val_accuracy: 0.5469\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7294 - accuracy: 0.5226 - val_loss: 0.6824 - val_accuracy: 0.5541\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7227 - accuracy: 0.5221 - val_loss: 0.6828 - val_accuracy: 0.5513\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7219 - accuracy: 0.5330 - val_loss: 0.6823 - val_accuracy: 0.5513\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7178 - accuracy: 0.5328 - val_loss: 0.6819 - val_accuracy: 0.5575\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7231 - accuracy: 0.5267 - val_loss: 0.6813 - val_accuracy: 0.5603\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7195 - accuracy: 0.5324 - val_loss: 0.6810 - val_accuracy: 0.5647\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7133 - accuracy: 0.5387 - val_loss: 0.6806 - val_accuracy: 0.5709\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7179 - accuracy: 0.5358 - val_loss: 0.6804 - val_accuracy: 0.5737\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7151 - accuracy: 0.5433 - val_loss: 0.6799 - val_accuracy: 0.5703\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7168 - accuracy: 0.5382 - val_loss: 0.6800 - val_accuracy: 0.5608\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 41s 487ms/step - loss: 0.7214 - accuracy: 0.5337 - val_loss: 0.6798 - val_accuracy: 0.5714\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7139 - accuracy: 0.5396 - val_loss: 0.6790 - val_accuracy: 0.5776\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 41s 487ms/step - loss: 0.7156 - accuracy: 0.5398 - val_loss: 0.6791 - val_accuracy: 0.5759\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7202 - accuracy: 0.5315 - val_loss: 0.6783 - val_accuracy: 0.5815\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7214 - accuracy: 0.5252 - val_loss: 0.6777 - val_accuracy: 0.5815\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7200 - accuracy: 0.5223 - val_loss: 0.6782 - val_accuracy: 0.5809\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7154 - accuracy: 0.5383 - val_loss: 0.6773 - val_accuracy: 0.5854\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.7140 - accuracy: 0.5319 - val_loss: 0.6776 - val_accuracy: 0.5826\n",
      "28/28 [==============================] - 9s 330ms/step - loss: 0.6792 - accuracy: 0.5675\n",
      "{'dense_units': 32, 'dropout_rate': 0.3, 'learning_rate': 1e-05, 'optimizer': 'adam', 'activation': 'relu', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_56\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_170 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_171 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_170[0][0]                  \n",
      "                                                                 input_171[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 7, 7, 32)     294944      concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 7, 7, 32)     0           conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 7, 7, 32)     9248        dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 7, 7, 32)     0           conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_113 (Flatten)           (None, 1568)         0           dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 2)            3138        flatten_113[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 20,331,714\n",
      "Trainable params: 7,386,754\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.6228 - accuracy: 0.6733 - val_loss: 0.5061 - val_accuracy: 0.7857\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4583 - accuracy: 0.8048 - val_loss: 0.4243 - val_accuracy: 0.8103\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.4192 - accuracy: 0.8193 - val_loss: 0.3960 - val_accuracy: 0.8225\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3868 - accuracy: 0.8379 - val_loss: 0.3814 - val_accuracy: 0.8287\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3725 - accuracy: 0.8455 - val_loss: 0.3664 - val_accuracy: 0.8371\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3539 - accuracy: 0.8525 - val_loss: 0.3539 - val_accuracy: 0.8465\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3189 - accuracy: 0.8712 - val_loss: 0.3434 - val_accuracy: 0.8516\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3108 - accuracy: 0.8719 - val_loss: 0.3396 - val_accuracy: 0.8482\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3007 - accuracy: 0.8843 - val_loss: 0.3309 - val_accuracy: 0.8499\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2777 - accuracy: 0.8936 - val_loss: 0.3179 - val_accuracy: 0.8588\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2670 - accuracy: 0.9006 - val_loss: 0.3075 - val_accuracy: 0.8672\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2423 - accuracy: 0.9131 - val_loss: 0.3010 - val_accuracy: 0.8594\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2170 - accuracy: 0.9231 - val_loss: 0.2895 - val_accuracy: 0.8711\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2163 - accuracy: 0.9235 - val_loss: 0.2862 - val_accuracy: 0.8722\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1926 - accuracy: 0.9386 - val_loss: 0.2852 - val_accuracy: 0.8750\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1700 - accuracy: 0.9471 - val_loss: 0.2655 - val_accuracy: 0.8878\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1597 - accuracy: 0.9507 - val_loss: 0.2570 - val_accuracy: 0.8873\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1435 - accuracy: 0.9569 - val_loss: 0.2500 - val_accuracy: 0.8878\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1263 - accuracy: 0.9653 - val_loss: 0.2401 - val_accuracy: 0.8996\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1076 - accuracy: 0.9714 - val_loss: 0.2534 - val_accuracy: 0.8895\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0939 - accuracy: 0.9754 - val_loss: 0.2416 - val_accuracy: 0.8990\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0895 - accuracy: 0.9773 - val_loss: 0.2500 - val_accuracy: 0.8973\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0776 - accuracy: 0.9819 - val_loss: 0.2391 - val_accuracy: 0.9062\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0648 - accuracy: 0.9860 - val_loss: 0.2366 - val_accuracy: 0.9029\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0555 - accuracy: 0.9884 - val_loss: 0.2549 - val_accuracy: 0.9001\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0496 - accuracy: 0.9891 - val_loss: 0.2473 - val_accuracy: 0.9090\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0390 - accuracy: 0.9928 - val_loss: 0.2467 - val_accuracy: 0.9090\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0350 - accuracy: 0.9933 - val_loss: 0.2550 - val_accuracy: 0.9068\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0267 - accuracy: 0.9959 - val_loss: 0.2631 - val_accuracy: 0.9118\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0291 - accuracy: 0.9941 - val_loss: 0.2888 - val_accuracy: 0.9029\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.0226 - accuracy: 0.9957 - val_loss: 0.2812 - val_accuracy: 0.9124\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0192 - accuracy: 0.9972 - val_loss: 0.2819 - val_accuracy: 0.9113\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0173 - accuracy: 0.9970 - val_loss: 0.3055 - val_accuracy: 0.9029\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0169 - accuracy: 0.9978 - val_loss: 0.2925 - val_accuracy: 0.9141\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0156 - accuracy: 0.9978 - val_loss: 0.2865 - val_accuracy: 0.9196\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0108 - accuracy: 0.9994 - val_loss: 0.3113 - val_accuracy: 0.9157\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 40s 476ms/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 0.2767 - val_accuracy: 0.9169\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.3017 - val_accuracy: 0.9124\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0077 - accuracy: 0.9991 - val_loss: 0.3188 - val_accuracy: 0.9107\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 0.3204 - val_accuracy: 0.9096\n",
      "28/28 [==============================] - 9s 327ms/step - loss: 0.4594 - accuracy: 0.8912\n",
      "{'dense_units': 256, 'dropout_rate': 0.5, 'learning_rate': 0.0001, 'optimizer': 'sgd', 'activation': 'tanh', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_57\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_173 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_174 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_173[0][0]                  \n",
      "                                                                 input_174[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 7, 7, 256)    2359552     concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)           (None, 7, 7, 256)    0           conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 7, 7, 256)    590080      dropout_114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)           (None, 7, 7, 256)    0           conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_115 (Flatten)           (None, 12544)        0           dropout_115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 2)            25090       flatten_115[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 22,999,106\n",
      "Trainable params: 10,054,146\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.7781 - accuracy: 0.5053 - val_loss: 0.6897 - val_accuracy: 0.5592\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7649 - accuracy: 0.5145 - val_loss: 0.6850 - val_accuracy: 0.5692\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7541 - accuracy: 0.5260 - val_loss: 0.6753 - val_accuracy: 0.6211\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7487 - accuracy: 0.5265 - val_loss: 0.6686 - val_accuracy: 0.6390\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7387 - accuracy: 0.5428 - val_loss: 0.6609 - val_accuracy: 0.6323\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7298 - accuracy: 0.5598 - val_loss: 0.6536 - val_accuracy: 0.6719\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7226 - accuracy: 0.5755 - val_loss: 0.6468 - val_accuracy: 0.6663\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.7133 - accuracy: 0.5794 - val_loss: 0.6399 - val_accuracy: 0.6987\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.7110 - accuracy: 0.5838 - val_loss: 0.6325 - val_accuracy: 0.7143\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.6936 - accuracy: 0.6115 - val_loss: 0.6253 - val_accuracy: 0.7243\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.6833 - accuracy: 0.6232 - val_loss: 0.6171 - val_accuracy: 0.7316\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.6816 - accuracy: 0.6132 - val_loss: 0.6093 - val_accuracy: 0.7288\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.6601 - accuracy: 0.6498 - val_loss: 0.6012 - val_accuracy: 0.7394\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.6532 - accuracy: 0.6588 - val_loss: 0.5937 - val_accuracy: 0.7494\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.6440 - accuracy: 0.6681 - val_loss: 0.5847 - val_accuracy: 0.7511\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.6430 - accuracy: 0.6702 - val_loss: 0.5776 - val_accuracy: 0.7567\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.6250 - accuracy: 0.6871 - val_loss: 0.5693 - val_accuracy: 0.7589\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.6175 - accuracy: 0.6960 - val_loss: 0.5622 - val_accuracy: 0.7578\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.6052 - accuracy: 0.7074 - val_loss: 0.5518 - val_accuracy: 0.7606\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5996 - accuracy: 0.7111 - val_loss: 0.5451 - val_accuracy: 0.7623\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5869 - accuracy: 0.7171 - val_loss: 0.5371 - val_accuracy: 0.7640\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5769 - accuracy: 0.7302 - val_loss: 0.5312 - val_accuracy: 0.7640\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5637 - accuracy: 0.7459 - val_loss: 0.5218 - val_accuracy: 0.7673\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5576 - accuracy: 0.7335 - val_loss: 0.5140 - val_accuracy: 0.7729\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5475 - accuracy: 0.7494 - val_loss: 0.5105 - val_accuracy: 0.7690\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5360 - accuracy: 0.7511 - val_loss: 0.5055 - val_accuracy: 0.7640\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5319 - accuracy: 0.7599 - val_loss: 0.4989 - val_accuracy: 0.7712\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5298 - accuracy: 0.7548 - val_loss: 0.4946 - val_accuracy: 0.7723\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.5166 - accuracy: 0.7660 - val_loss: 0.4883 - val_accuracy: 0.7746\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 0.5174 - accuracy: 0.7658 - val_loss: 0.4870 - val_accuracy: 0.7729\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.5097 - accuracy: 0.7679 - val_loss: 0.4846 - val_accuracy: 0.7762\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5023 - accuracy: 0.7723 - val_loss: 0.4816 - val_accuracy: 0.7751\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4966 - accuracy: 0.7773 - val_loss: 0.4747 - val_accuracy: 0.7857\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4971 - accuracy: 0.7764 - val_loss: 0.4744 - val_accuracy: 0.7790\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4968 - accuracy: 0.7736 - val_loss: 0.4713 - val_accuracy: 0.7796\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4829 - accuracy: 0.7780 - val_loss: 0.4665 - val_accuracy: 0.7840\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4820 - accuracy: 0.7838 - val_loss: 0.4656 - val_accuracy: 0.7829\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.4788 - accuracy: 0.7810 - val_loss: 0.4632 - val_accuracy: 0.7852\n",
      "28/28 [==============================] - 9s 329ms/step - loss: 0.4490 - accuracy: 0.7924\n",
      "{'dense_units': 128, 'dropout_rate': 0.4, 'learning_rate': 0.0001, 'optimizer': 'adam', 'activation': 'sigmoid', 'learning_rate_decay': 0.001}\n",
      "Model: \"model_58\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_176 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_177 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_176[0][0]                  \n",
      "                                                                 input_177[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 7, 7, 128)    1179776     concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_116 (Dropout)           (None, 7, 7, 128)    0           conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 7, 7, 128)    147584      dropout_116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_117 (Dropout)           (None, 7, 7, 128)    0           conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_117 (Flatten)           (None, 6272)         0           dropout_117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 2)            12546       flatten_117[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 21,364,290\n",
      "Trainable params: 8,419,330\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5249 - accuracy: 0.7446 - val_loss: 0.3815 - val_accuracy: 0.8292\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.3717 - accuracy: 0.8425 - val_loss: 0.3540 - val_accuracy: 0.8482\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.3273 - accuracy: 0.8664 - val_loss: 0.3429 - val_accuracy: 0.8521\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.2973 - accuracy: 0.8808 - val_loss: 0.3116 - val_accuracy: 0.8650\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.2405 - accuracy: 0.9074 - val_loss: 0.3365 - val_accuracy: 0.8544\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1902 - accuracy: 0.9322 - val_loss: 0.2822 - val_accuracy: 0.8873\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1368 - accuracy: 0.9542 - val_loss: 0.2834 - val_accuracy: 0.8917\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1129 - accuracy: 0.9625 - val_loss: 0.2663 - val_accuracy: 0.8951\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.0791 - accuracy: 0.9786 - val_loss: 0.2801 - val_accuracy: 0.8990\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0579 - accuracy: 0.9839 - val_loss: 0.3328 - val_accuracy: 0.8906\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0519 - accuracy: 0.9867 - val_loss: 0.3040 - val_accuracy: 0.8979\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0391 - accuracy: 0.9902 - val_loss: 0.3073 - val_accuracy: 0.9035\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0364 - accuracy: 0.9904 - val_loss: 0.3278 - val_accuracy: 0.8951\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0273 - accuracy: 0.9935 - val_loss: 0.3287 - val_accuracy: 0.8973\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0174 - accuracy: 0.9965 - val_loss: 0.3167 - val_accuracy: 0.9107\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0128 - accuracy: 0.9978 - val_loss: 0.3226 - val_accuracy: 0.9074\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.3153 - val_accuracy: 0.9085\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.3239 - val_accuracy: 0.9035\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0082 - accuracy: 0.9987 - val_loss: 0.3346 - val_accuracy: 0.9068\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.3509 - val_accuracy: 0.9062\n",
      "28/28 [==============================] - 9s 327ms/step - loss: 0.4188 - accuracy: 0.8956\n",
      "{'dense_units': 128, 'dropout_rate': 0.6, 'learning_rate': 1e-06, 'optimizer': 'sgd', 'activation': 'relu', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_59\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_179 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_180 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_179[0][0]                  \n",
      "                                                                 input_180[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 7, 7, 128)    1179776     concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_118 (Dropout)           (None, 7, 7, 128)    0           conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 7, 7, 128)    147584      dropout_118[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_119 (Dropout)           (None, 7, 7, 128)    0           conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_119 (Flatten)           (None, 6272)         0           dropout_119[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 2)            12546       flatten_119[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 21,364,290\n",
      "Trainable params: 8,419,330\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.8504 - accuracy: 0.5025 - val_loss: 0.7162 - val_accuracy: 0.4972\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.8559 - accuracy: 0.4966 - val_loss: 0.7154 - val_accuracy: 0.4944\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.8539 - accuracy: 0.4892 - val_loss: 0.7143 - val_accuracy: 0.4972\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.8495 - accuracy: 0.5053 - val_loss: 0.7135 - val_accuracy: 0.4983\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.8432 - accuracy: 0.5091 - val_loss: 0.7132 - val_accuracy: 0.4967\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.8505 - accuracy: 0.5006 - val_loss: 0.7119 - val_accuracy: 0.4989\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.8425 - accuracy: 0.5049 - val_loss: 0.7114 - val_accuracy: 0.4983\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.8491 - accuracy: 0.5043 - val_loss: 0.7110 - val_accuracy: 0.4978\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.8435 - accuracy: 0.5049 - val_loss: 0.7100 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.8344 - accuracy: 0.4992 - val_loss: 0.7096 - val_accuracy: 0.4983\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.8490 - accuracy: 0.4971 - val_loss: 0.7092 - val_accuracy: 0.4961\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.8436 - accuracy: 0.5036 - val_loss: 0.7084 - val_accuracy: 0.4994\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.8313 - accuracy: 0.5090 - val_loss: 0.7076 - val_accuracy: 0.5022\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.8397 - accuracy: 0.5051 - val_loss: 0.7074 - val_accuracy: 0.4989\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.8338 - accuracy: 0.5077 - val_loss: 0.7067 - val_accuracy: 0.5000\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.8376 - accuracy: 0.4994 - val_loss: 0.7063 - val_accuracy: 0.5017\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.8355 - accuracy: 0.4995 - val_loss: 0.7059 - val_accuracy: 0.5006\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.8353 - accuracy: 0.4942 - val_loss: 0.7052 - val_accuracy: 0.5022\n",
      "28/28 [==============================] - 9s 329ms/step - loss: 0.7065 - accuracy: 0.5006\n",
      "{'dense_units': 32, 'dropout_rate': 0.5, 'learning_rate': 1e-05, 'optimizer': 'adam', 'activation': 'sigmoid', 'learning_rate_decay': 1e-05}\n",
      "Model: \"model_60\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_182 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_183 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_182[0][0]                  \n",
      "                                                                 input_183[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 7, 7, 32)     294944      concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)           (None, 7, 7, 32)     0           conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 7, 7, 32)     9248        dropout_120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)           (None, 7, 7, 32)     0           conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_121 (Flatten)           (None, 1568)         0           dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 2)            3138        flatten_121[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 20,331,714\n",
      "Trainable params: 7,386,754\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.7954 - accuracy: 0.4968 - val_loss: 0.6849 - val_accuracy: 0.4989\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.7086 - accuracy: 0.5611 - val_loss: 0.6232 - val_accuracy: 0.7472\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.6437 - accuracy: 0.6692 - val_loss: 0.5750 - val_accuracy: 0.7785\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5969 - accuracy: 0.7272 - val_loss: 0.5379 - val_accuracy: 0.8002\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5616 - accuracy: 0.7618 - val_loss: 0.5082 - val_accuracy: 0.8164\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.5293 - accuracy: 0.7856 - val_loss: 0.4839 - val_accuracy: 0.8248\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 0.5246 - accuracy: 0.7828 - val_loss: 0.4657 - val_accuracy: 0.8259\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4972 - accuracy: 0.8076 - val_loss: 0.4493 - val_accuracy: 0.8359\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4797 - accuracy: 0.8178 - val_loss: 0.4340 - val_accuracy: 0.8393\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4625 - accuracy: 0.8313 - val_loss: 0.4222 - val_accuracy: 0.8482\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.4469 - accuracy: 0.8342 - val_loss: 0.4072 - val_accuracy: 0.8443\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4341 - accuracy: 0.8381 - val_loss: 0.3959 - val_accuracy: 0.8527\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.4192 - accuracy: 0.8438 - val_loss: 0.3904 - val_accuracy: 0.8510\n",
      "Epoch 14/50\n",
      "18/85 [=====>........................] - ETA: 24s - loss: 0.4232 - accuracy: 0.8438"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_generator,\n\u001b[0;32m     23\u001b[0m       steps_per_epoch\u001b[39m=\u001b[39;49mtrain_steps_per_epoch,\n\u001b[0;32m     24\u001b[0m       epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[0;32m     25\u001b[0m       validation_data\u001b[39m=\u001b[39;49mvalid_generator,\n\u001b[0;32m     26\u001b[0m       validation_steps\u001b[39m=\u001b[39;49mvalid_steps_per_epoch,\n\u001b[0;32m     27\u001b[0m       callbacks\u001b[39m=\u001b[39;49m[early_stopping])\n\u001b[0;32m     29\u001b[0m \u001b[39m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m     30\u001b[0m test_loss, test_accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(test_generator, steps\u001b[39m=\u001b[39mvalid_steps_per_epoch)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\tqdm\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1193\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1187\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1188\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1189\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1190\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1191\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1192\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1193\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1194\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1195\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\tqdm\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\tqdm\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\tqdm\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3040\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\tqdm\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1964\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\tqdm\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\tqdm\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize best hyperparameters and best validation accuracy\n",
    "best_hyperparameters = None\n",
    "best_test_loss = 100\n",
    "\n",
    "# Define the number of random combinations to try\n",
    "num_random_combinations = 70\n",
    "\n",
    "# Perform random search\n",
    "for _ in range(num_random_combinations):\n",
    "    # Generate random combination of hyperparameters\n",
    "    combination = {\n",
    "        param: random.choice(values)\n",
    "        for param, values in hyperparameters.items()\n",
    "    }\n",
    "    print(combination)\n",
    "    # Create and train the model with the current hyperparameters\n",
    "    model = comparison_siamese_model((224,224,3), **combination)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_generator,\n",
    "          steps_per_epoch=train_steps_per_epoch,\n",
    "          epochs=50,\n",
    "          validation_data=valid_generator,\n",
    "          validation_steps=valid_steps_per_epoch,\n",
    "          callbacks=[early_stopping])\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, steps=valid_steps_per_epoch)\n",
    "    \n",
    "    # Check if the current model has the best test accuracy so far\n",
    "    if best_test_loss > test_loss:\n",
    "        best_hyperparameters = combination\n",
    "        best_test_loss = test_loss\n",
    "        # Save the weights of the best model\n",
    "        model.save_weights('best_model_weights.h5')\n",
    "        plot_accuracy(history)\n",
    "        plot_loss(history)\n",
    "\n",
    "        # Print the best hyperparameters and best test accuracy\n",
    "        print('Best Hyperparameters:', best_hyperparameters)\n",
    "        print('Best Test Loss:', best_test_loss)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_62\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_188 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_189 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_188[0][0]                  \n",
      "                                                                 input_189[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 7, 7, 32)     294944      concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_124 (Dropout)           (None, 7, 7, 32)     0           conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 7, 7, 32)     9248        dropout_124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_125 (Dropout)           (None, 7, 7, 32)     0           conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_125 (Flatten)           (None, 1568)         0           dropout_125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 2)            3138        flatten_125[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 20,331,714\n",
      "Trainable params: 7,386,754\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_62\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_188 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_189 (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg19 (Functional)              (None, 7, 7, 512)    20024384    input_188[0][0]                  \n",
      "                                                                 input_189[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 7, 7, 1024)   0           vgg19[0][0]                      \n",
      "                                                                 vgg19[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 7, 7, 32)     294944      concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_124 (Dropout)           (None, 7, 7, 32)     0           conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 7, 7, 32)     9248        dropout_124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_125 (Dropout)           (None, 7, 7, 32)     0           conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_125 (Flatten)           (None, 1568)         0           dropout_125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 2)            3138        flatten_125[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 20,331,714\n",
      "Trainable params: 7,386,754\n",
      "Non-trainable params: 12,944,960\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "85/85 [==============================] - 41s 473ms/step - loss: 0.6136 - accuracy: 0.6807 - val_loss: 0.4919 - val_accuracy: 0.7913\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.4488 - accuracy: 0.8041 - val_loss: 0.4274 - val_accuracy: 0.8064\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.4144 - accuracy: 0.8213 - val_loss: 0.3979 - val_accuracy: 0.8253\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.3780 - accuracy: 0.8409 - val_loss: 0.3844 - val_accuracy: 0.8253\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3637 - accuracy: 0.8499 - val_loss: 0.3737 - val_accuracy: 0.8331\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.3457 - accuracy: 0.8557 - val_loss: 0.3634 - val_accuracy: 0.8382\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.3316 - accuracy: 0.8688 - val_loss: 0.3585 - val_accuracy: 0.8359\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.3107 - accuracy: 0.8758 - val_loss: 0.3506 - val_accuracy: 0.8398\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.3027 - accuracy: 0.8804 - val_loss: 0.3431 - val_accuracy: 0.8415\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.3025 - accuracy: 0.8815 - val_loss: 0.3401 - val_accuracy: 0.8482\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.2759 - accuracy: 0.8987 - val_loss: 0.3309 - val_accuracy: 0.8516\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2771 - accuracy: 0.8989 - val_loss: 0.3263 - val_accuracy: 0.8560\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.2622 - accuracy: 0.9076 - val_loss: 0.3211 - val_accuracy: 0.8544\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.2479 - accuracy: 0.9133 - val_loss: 0.3148 - val_accuracy: 0.8599\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.2456 - accuracy: 0.9106 - val_loss: 0.3113 - val_accuracy: 0.8599\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.2300 - accuracy: 0.9215 - val_loss: 0.3081 - val_accuracy: 0.8627\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.2309 - accuracy: 0.9211 - val_loss: 0.3035 - val_accuracy: 0.8644\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.2145 - accuracy: 0.9329 - val_loss: 0.3010 - val_accuracy: 0.8650\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.2124 - accuracy: 0.9327 - val_loss: 0.2923 - val_accuracy: 0.8733\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.2031 - accuracy: 0.9381 - val_loss: 0.2942 - val_accuracy: 0.8728\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1940 - accuracy: 0.9414 - val_loss: 0.2830 - val_accuracy: 0.8739\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.1957 - accuracy: 0.9422 - val_loss: 0.2826 - val_accuracy: 0.8789\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.1828 - accuracy: 0.9484 - val_loss: 0.2785 - val_accuracy: 0.8778\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1786 - accuracy: 0.9494 - val_loss: 0.2797 - val_accuracy: 0.8778\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.1747 - accuracy: 0.9519 - val_loss: 0.2737 - val_accuracy: 0.8806\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1637 - accuracy: 0.9590 - val_loss: 0.2708 - val_accuracy: 0.8828\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.1596 - accuracy: 0.9580 - val_loss: 0.2694 - val_accuracy: 0.8856\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.1535 - accuracy: 0.9623 - val_loss: 0.2665 - val_accuracy: 0.8890\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1486 - accuracy: 0.9632 - val_loss: 0.2665 - val_accuracy: 0.8834\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1436 - accuracy: 0.9667 - val_loss: 0.2589 - val_accuracy: 0.8945\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1411 - accuracy: 0.9682 - val_loss: 0.2590 - val_accuracy: 0.8901\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1338 - accuracy: 0.9721 - val_loss: 0.2542 - val_accuracy: 0.8901\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1319 - accuracy: 0.9708 - val_loss: 0.2573 - val_accuracy: 0.8890\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1255 - accuracy: 0.9732 - val_loss: 0.2520 - val_accuracy: 0.8917\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1216 - accuracy: 0.9760 - val_loss: 0.2517 - val_accuracy: 0.8956\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.1177 - accuracy: 0.9763 - val_loss: 0.2461 - val_accuracy: 0.8951\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 40s 479ms/step - loss: 0.1115 - accuracy: 0.9776 - val_loss: 0.2491 - val_accuracy: 0.8962\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1092 - accuracy: 0.9787 - val_loss: 0.2453 - val_accuracy: 0.9012\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1081 - accuracy: 0.9795 - val_loss: 0.2453 - val_accuracy: 0.8962\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.1038 - accuracy: 0.9811 - val_loss: 0.2393 - val_accuracy: 0.9001\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0981 - accuracy: 0.9834 - val_loss: 0.2382 - val_accuracy: 0.9018\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0952 - accuracy: 0.9839 - val_loss: 0.2422 - val_accuracy: 0.8962\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0907 - accuracy: 0.9847 - val_loss: 0.2375 - val_accuracy: 0.9007\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.0890 - accuracy: 0.9858 - val_loss: 0.2334 - val_accuracy: 0.9018\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 40s 477ms/step - loss: 0.0878 - accuracy: 0.9854 - val_loss: 0.2382 - val_accuracy: 0.8996\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 40s 478ms/step - loss: 0.0844 - accuracy: 0.9878 - val_loss: 0.2315 - val_accuracy: 0.9051\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0812 - accuracy: 0.9882 - val_loss: 0.2309 - val_accuracy: 0.9074\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0769 - accuracy: 0.9897 - val_loss: 0.2327 - val_accuracy: 0.9051\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0767 - accuracy: 0.9900 - val_loss: 0.2297 - val_accuracy: 0.9035\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 41s 478ms/step - loss: 0.0736 - accuracy: 0.9891 - val_loss: 0.2290 - val_accuracy: 0.9102\n",
      "28/28 [==============================] - 9s 328ms/step - loss: 0.2939 - accuracy: 0.8795\n"
     ]
    }
   ],
   "source": [
    "def comparison_siamese_model(input_shape):\n",
    "    \"\"\"Create a siamese model for image comparison using VGG19 as base model.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): Shape of the input images.\n",
    "    Returns:\n",
    "        keras.models.Model: The compiled siamese model.\n",
    "    \"\"\"\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    for layer in base_model.layers[:-4]:\n",
    "        layer.trainable=False\n",
    "\n",
    "    # Create inputs for pairs of images\n",
    "    input_1 = Input(shape=input_shape)\n",
    "    input_2 = Input(shape=input_shape)\n",
    "\n",
    "    # Get embeddings of the images using the shared VGG19 model\n",
    "    output_1 = base_model(input_1)\n",
    "    output_2 = base_model(input_2)\n",
    "\n",
    "    concat = concatenate([output_1, output_2])\n",
    "\n",
    "    # Classification layer to predict similarity\n",
    "    flatten = Flatten()(concat)\n",
    "    x = Conv2D(32, (3, 3), activation=\"tanh\", padding='same')(concat)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Conv2D(32, (3, 3), activation=\"tanh\", padding='same')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Flatten()(x)\n",
    "    output = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "    # Create the complete siamese model\n",
    "    siamese_model = Model(inputs=[input_1, input_2], outputs=output)\n",
    "\n",
    "    # Compile the model with the provided hyperparameters\n",
    "    siamese_model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=1e-05, decay=0.001), metrics=['accuracy'])\n",
    "\n",
    "    # Print model summary\n",
    "    siamese_model.summary()\n",
    "\n",
    "    return siamese_model\n",
    "\n",
    "siamese_model = comparison_siamese_model((224,224,3))\n",
    "\n",
    "siamese_model.summary()\n",
    "\n",
    "history = siamese_model.fit(train_generator,\n",
    "          steps_per_epoch=train_steps_per_epoch,\n",
    "          epochs=50,\n",
    "          validation_data=valid_generator,\n",
    "          validation_steps=valid_steps_per_epoch,\n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "siamese_model.save(\"handpicked_siamese_modle.h5\")\n",
    "\n",
    "test_loss, test_acc = siamese_model.evaluate(test_generator, steps=valid_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABo9ElEQVR4nO3deXhMZ/8G8Huy7wuyEokl9khISEPtIZaqUJWqElq0RUvx/vAqgrbR6uKtXVu8pZZSW2uNtWqLInZKSwRJrFnJYub8/njemWQkRhIzc5LJ/bmuc83MmTNnvjNN5c5znkUhSZIEIiIiIhNhJncBRERERPrEcENEREQmheGGiIiITArDDREREZkUhhsiIiIyKQw3REREZFIYboiIiMikMNwQERGRSWG4ISIiIpPCcEOkB4MHD4afn1+ZXhsTEwOFQqHfgsqZ69evQ6FQYPny5UZ/b4VCgZiYGM3j5cuXQ6FQ4Pr16899rZ+fHwYPHqzXel7kZ4WISobhhkyaQqEo0bZ//365S630PvzwQygUCly9evWZx0yePBkKhQJnzpwxYmWld/v2bcTExCAhIUHuUjTUAfPLL7+UuxQig7OQuwAiQ1qxYoXW4x9//BFxcXFF9jds2PCF3ue7776DSqUq02s//vhjTJw48YXe3xQMGDAAc+fOxapVqzB16tRij1m9ejUCAgLQtGnTMr/PwIED8cYbb8Da2rrM53ie27dvY/r06fDz80NQUJDWcy/ys0JEJcNwQybtrbfe0np89OhRxMXFFdn/tEePHsHOzq7E72NpaVmm+gDAwsICFhb8XzE0NBR169bF6tWriw03R44cwbVr1zBr1qwXeh9zc3OYm5u/0DlexIv8rBBRyfCyFFV67du3R5MmTXDixAm0bdsWdnZ2+Pe//w0A2Lx5M3r06AFvb29YW1ujTp06mDlzJpRKpdY5nu5HUfgSwJIlS1CnTh1YW1ujRYsWOH78uNZri+tzo1AoMGrUKGzatAlNmjSBtbU1GjdujB07dhSpf//+/QgJCYGNjQ3q1KmDxYsXl7gfz8GDB/H666+jZs2asLa2ho+PDz766CM8fvy4yOdzcHDArVu3EBkZCQcHB7i5uWH8+PFFvou0tDQMHjwYzs7OcHFxQXR0NNLS0p5bCyBaby5duoSTJ08WeW7VqlVQKBTo378/8vLyMHXqVAQHB8PZ2Rn29vZo06YN9u3b99z3KK7PjSRJ+OSTT1CjRg3Y2dmhQ4cOOH/+fJHXPnjwAOPHj0dAQAAcHBzg5OSEbt264fTp05pj9u/fjxYtWgAAhgwZorn0qe5vVFyfm+zsbIwbNw4+Pj6wtrZG/fr18eWXX0KSJK3jSvNzUVZ37tzBO++8Aw8PD9jY2CAwMBD//e9/ixy3Zs0aBAcHw9HREU5OTggICMB//vMfzfP5+fmYPn06/P39YWNjg6pVq+Lll19GXFyc1nkuXbqEvn37okqVKrCxsUFISAi2bNmidUxJz0Wkxj8XiQDcv38f3bp1wxtvvIG33noLHh4eAMQvQgcHB4wdOxYODg7Yu3cvpk6dioyMDMyePfu55121ahUyMzPx7rvvQqFQ4IsvvkCfPn3wzz//PPcv+D/++AMbNmzAiBEj4OjoiG+//RavvfYabty4gapVqwIATp06ha5du8LLywvTp0+HUqnEjBkz4ObmVqLPvW7dOjx69Ajvv/8+qlativj4eMydOxc3b97EunXrtI5VKpWIiIhAaGgovvzyS+zevRtfffUV6tSpg/fffx+ACAm9evXCH3/8gffeew8NGzbExo0bER0dXaJ6BgwYgOnTp2PVqlVo3ry51nv//PPPaNOmDWrWrIl79+7h+++/R//+/TFs2DBkZmbihx9+QEREBOLj44tcCnqeqVOn4pNPPkH37t3RvXt3nDx5El26dEFeXp7Wcf/88w82bdqE119/HbVq1UJqaioWL16Mdu3a4cKFC/D29kbDhg0xY8YMTJ06FcOHD0ebNm0AAK1atSr2vSVJwquvvop9+/bhnXfeQVBQEHbu3Il//etfuHXrFr755hut40vyc1FWjx8/Rvv27XH16lWMGjUKtWrVwrp16zB48GCkpaVh9OjRAIC4uDj0798fnTp1wueffw4AuHjxIg4dOqQ5JiYmBrGxsRg6dChatmyJjIwM/Pnnnzh58iQ6d+4MADh//jxat26N6tWrY+LEibC3t8fPP/+MyMhI/PLLL+jdu3eJz0WkRSKqREaOHCk9/WPfrl07CYC0aNGiIsc/evSoyL53331XsrOzk3JycjT7oqOjJV9fX83ja9euSQCkqlWrSg8ePNDs37x5swRA+vXXXzX7pk2bVqQmAJKVlZV09epVzb7Tp09LAKS5c+dq9vXs2VOys7OTbt26pdl35coVycLCosg5i1Pc54uNjZUUCoWUmJio9fkASDNmzNA6tlmzZlJwcLDm8aZNmyQA0hdffKHZ9+TJE6lNmzYSAGnZsmXPralFixZSjRo1JKVSqdm3Y8cOCYC0ePFizTlzc3O1Xvfw4UPJw8NDevvtt7X2A5CmTZumebxs2TIJgHTt2jVJkiTpzp07kpWVldSjRw9JpVJpjvv3v/8tAZCio6M1+3JycrTqkiTx39ra2lrruzl+/PgzP+/TPyvq7+yTTz7ROq5v376SQqHQ+hko6c9FcdQ/k7Nnz37mMXPmzJEASCtXrtTsy8vLk8LCwiQHBwcpIyNDkiRJGj16tOTk5CQ9efLkmecKDAyUevToobOmTp06SQEBAVr/L6lUKqlVq1aSv79/qc5FVBgvSxEBsLa2xpAhQ4rst7W11dzPzMzEvXv30KZNGzx69AiXLl167nmjoqLg6uqqeaz+K/6ff/557mvDw8NRp04dzeOmTZvCyclJ81qlUondu3cjMjIS3t7emuPq1q2Lbt26Pff8gPbny87Oxr1799CqVStIkoRTp04VOf69997TetymTRutz7Jt2zZYWFhoWnIA0cflgw8+KFE9gOgndfPmTfz++++afatWrYKVlRVef/11zTmtrKwAACqVCg8ePMCTJ08QEhJS7CUtXXbv3o28vDx88MEHWpfyxowZU+RYa2trmJmJfzaVSiXu378PBwcH1K9fv9Tvq7Zt2zaYm5vjww8/1No/btw4SJKE7du3a+1/3s/Fi9i2bRs8PT3Rv39/zT5LS0t8+OGHyMrKwoEDBwAALi4uyM7O1nlZyMXFBefPn8eVK1eKff7BgwfYu3cv+vXrp/l/6969e7h//z4iIiJw5coV3Lp1q0TnInoaww0RgOrVq2t+WRZ2/vx59O7dG87OznBycoKbm5umM3J6evpzz1uzZk2tx+qg8/Dhw1K/Vv169Wvv3LmDx48fo27dukWOK25fcW7cuIHBgwejSpUqmn407dq1A1D089nY2BS53FW4HgBITEyEl5cXHBwctI6rX79+ieoBgDfeeAPm5uZYtWoVACAnJwcbN25Et27dtILif//7XzRt2lTTB8PNzQ1bt24t0X+XwhITEwEA/v7+Wvvd3Ny03g8QQeqbb76Bv78/rK2tUa1aNbi5ueHMmTOlft/C7+/t7Q1HR0et/eoRfOr61J73c/EiEhMT4e/vrwlwz6plxIgRqFevHrp164YaNWrg7bffLtLvZ8aMGUhLS0O9evUQEBCAf/3rX1pD+K9evQpJkjBlyhS4ublpbdOmTQMgfsZLci6ipzHcEEG7BUMtLS0N7dq1w+nTpzFjxgz8+uuviIuL0/QxKMlw3meNypGe6iiq79eWhFKpROfOnbF161ZMmDABmzZtQlxcnKbj69Ofz1gjjNzd3dG5c2f88ssvyM/Px6+//orMzEwMGDBAc8zKlSsxePBg1KlTBz/88AN27NiBuLg4dOzY0aDDrD/77DOMHTsWbdu2xcqVK7Fz507ExcWhcePGRhvebeifi5Jwd3dHQkICtmzZoukv1K1bN62+VW3btsXff/+NpUuXokmTJvj+++/RvHlzfP/99wAKfr7Gjx+PuLi4Yjd1SH/euYiexg7FRM+wf/9+3L9/Hxs2bEDbtm01+69duyZjVQXc3d1hY2NT7KR3uibCUzt79iz++usv/Pe//8WgQYM0+19kBIqvry/27NmDrKwsrdaby5cvl+o8AwYMwI4dO7B9+3asWrUKTk5O6Nmzp+b59evXo3bt2tiwYYPWpST1X/ylrRkArly5gtq1a2v23717t0hryPr169GhQwf88MMPWvvT0tJQrVo1zePSzDjt6+uL3bt3IzMzU6v1Rn3ZU12fMfj6+uLMmTNQqVRarTfF1WJlZYWePXuiZ8+eUKlUGDFiBBYvXowpU6ZoQkmVKlUwZMgQDBkyBFlZWWjbti1iYmIwdOhQzXdtaWmJ8PDw59am61xET2PLDdEzqP9CLvwXcV5eHhYsWCBXSVrMzc0RHh6OTZs24fbt25r9V69eLdJP41mvB7Q/nyRJWsN5S6t79+548uQJFi5cqNmnVCoxd+7cUp0nMjISdnZ2WLBgAbZv344+ffrAxsZGZ+3Hjh3DkSNHSl1zeHg4LC0tMXfuXK3zzZkzp8ix5ubmRVpI1q1bp+kbomZvbw8AJRoC3717dyiVSsybN09r/zfffAOFQlHi/lP60L17d6SkpGDt2rWafU+ePMHcuXPh4OCguWR5//59rdeZmZlpJlbMzc0t9hgHBwfUrVtX87y7uzvat2+PxYsXIzk5uUgtd+/e1dx/3rmInsaWG6JnaNWqFVxdXREdHa1ZGmDFihVGbf5/npiYGOzatQutW7fG+++/r/kl2aRJk+dO/d+gQQPUqVMH48ePx61bt+Dk5IRffvnlhfpu9OzZE61bt8bEiRNx/fp1NGrUCBs2bCh1fxQHBwdERkZq+t0UviQFAK+88go2bNiA3r17o0ePHrh27RoWLVqERo0aISsrq1TvpZ6vJzY2Fq+88gq6d++OU6dOYfv27VqtMer3nTFjBoYMGYJWrVrh7Nmz+Omnn7RafACgTp06cHFxwaJFi+Do6Ah7e3uEhoaiVq1aRd6/Z8+e6NChAyZPnozr168jMDAQu3btwubNmzFmzBitzsP6sGfPHuTk5BTZHxkZieHDh2Px4sUYPHgwTpw4AT8/P6xfvx6HDh3CnDlzNC1LQ4cOxYMHD9CxY0fUqFEDiYmJmDt3LoKCgjT9cxo1aoT27dsjODgYVapUwZ9//on169dj1KhRmvecP38+Xn75ZQQEBGDYsGGoXbs2UlNTceTIEdy8eVMzf1BJzkWkRZYxWkQyedZQ8MaNGxd7/KFDh6SXXnpJsrW1lby9vaX/+7//k3bu3CkBkPbt26c57llDwYsbdounhiY/ayj4yJEji7zW19dXa2iyJEnSnj17pGbNmklWVlZSnTp1pO+//14aN26cZGNj84xvocCFCxek8PBwycHBQapWrZo0bNgwzdDiwsOYo6OjJXt7+yKvL672+/fvSwMHDpScnJwkZ2dnaeDAgdKpU6dKPBRcbevWrRIAycvLq8jwa5VKJX322WeSr6+vZG1tLTVr1kz67bffivx3kKTnDwWXJElSKpXS9OnTJS8vL8nW1lZq3769dO7cuSLfd05OjjRu3DjNca1bt5aOHDkitWvXTmrXrp3W+27evFlq1KiRZli++rMXV2NmZqb00UcfSd7e3pKlpaXk7+8vzZ49W2touvqzlPTn4mnqn8lnbStWrJAkSZJSU1OlIUOGSNWqVZOsrKykgICAIv/d1q9fL3Xp0kVyd3eXrKyspJo1a0rvvvuulJycrDnmk08+kVq2bCm5uLhItra2UoMGDaRPP/1UysvL0zrX33//LQ0aNEjy9PSULC0tperVq0uvvPKKtH79+lKfi0hNIUnl6M9QItKLyMhIDp0lokqLfW6IKrinl0q4cuUKtm3bhvbt28tTEBGRzNhyQ1TBeXl5YfDgwahduzYSExOxcOFC5Obm4tSpU0XmbiEiqgzYoZioguvatStWr16NlJQUWFtbIywsDJ999hmDDRFVWmy5ISIiIpPCPjdERERkUhhuiIiIyKRUuj43KpUKt2/fhqOjY6mmSCciIiL5SJKEzMxMeHt7F1nc9WmVLtzcvn0bPj4+cpdBREREZZCUlIQaNWroPKbShRv19OFJSUlwcnKSuRoiIiIqiYyMDPj4+GgtMPsslS7cqC9FOTk5MdwQERFVMCXpUsIOxURERGRSGG6IiIjIpDDcEBERkUmpdH1uiIjoxSmVSuTn58tdBpkYKyur5w7zLgmGGyIiKjFJkpCSkoK0tDS5SyETZGZmhlq1asHKyuqFzsNwQ0REJaYONu7u7rCzs+NkqKQ36kl2k5OTUbNmzRf62WK4ISKiElEqlZpgU7VqVbnLIRPk5uaG27dv48mTJ7C0tCzzedihmIiISkTdx8bOzk7mSshUqS9HKZXKFzoPww0REZUKL0WRoejrZ4vhhoiIiEwKww0REVEp+fn5Yc6cOXKXQc/AcENERCZLoVDo3GJiYsp03uPHj2P48OEvVFv79u0xZsyYFzoHFY+jpfREqQTu3AEePQLq1JG7GiIiAoDk5GTN/bVr12Lq1Km4fPmyZp+Dg4PmviRJUCqVsLB4/q9GNzc3/RZKesWWGz3Ztw/w9gZefVXuSoiISM3T01OzOTs7Q6FQaB5funQJjo6O2L59O4KDg2FtbY0//vgDf//9N3r16gUPDw84ODigRYsW2L17t9Z5n74spVAo8P3336N3796ws7ODv78/tmzZ8kK1//LLL2jcuDGsra3h5+eHr776Suv5BQsWwN/fHzY2NvDw8EDfvn01z61fvx4BAQGwtbVF1apVER4ejuzs7BeqpyJhy42eeHiI29RUeesgIjIWSRKt1XKwswP0NWhr4sSJ+PLLL1G7dm24uroiKSkJ3bt3x6effgpra2v8+OOP6NmzJy5fvoyaNWs+8zzTp0/HF198gdmzZ2Pu3LkYMGAAEhMTUaVKlVLXdOLECfTr1w8xMTGIiorC4cOHMWLECFStWhWDBw/Gn3/+iQ8//BArVqxAq1at8ODBAxw8eBCAaK3q378/vvjiC/Tu3RuZmZk4ePAgJEkq83dU0TDc6Ik63Ny/D+TnAy8w9xARUYXw6BFQ6KqOUWVlAfb2+jnXjBkz0LlzZ83jKlWqIDAwUPN45syZ2LhxI7Zs2YJRo0Y98zyDBw9G//79AQCfffYZvv32W8THx6Nr166lrunrr79Gp06dMGXKFABAvXr1cOHCBcyePRuDBw/GjRs3YG9vj1deeQWOjo7w9fVFs2bNAIhw8+TJE/Tp0we+vr4AgICAgFLXUJHxspSeVK0KqNf6untX3lqIiKjkQkJCtB5nZWVh/PjxaNiwIVxcXODg4ICLFy/ixo0bOs/TtGlTzX17e3s4OTnhzp07Zarp4sWLaN26tda+1q1b48qVK1AqlejcuTN8fX1Ru3ZtDBw4ED/99BMe/a8ZLTAwEJ06dUJAQABef/11fPfdd3j48GGZ6qioGG70xNwcUPcv46UpIqoM7OxEC4ocmz4nSbZ/qglo/Pjx2LhxIz777DMcPHgQCQkJCAgIQF5ens7zPL1cgEKhgEql0l+hhTg6OuLkyZNYvXo1vLy8MHXqVAQGBiItLQ3m5uaIi4vD9u3b0ahRI8ydOxf169fHtWvXDFJLeSR7uJk/fz78/PxgY2OD0NBQxMfH6zw+LS0NI0eOhJeXF6ytrVGvXj1s27bNSNXqxn43RFSZKBTi0pAcmyEnST506BAGDx6M3r17IyAgAJ6enrh+/brh3rAYDRs2xKFDh4rUVa9ePZibmwMALCwsEB4eji+++AJnzpzB9evXsXfvXgAiWLVu3RrTp0/HqVOnYGVlhY0bNxr1M8hJ1j43a9euxdixY7Fo0SKEhoZizpw5iIiIwOXLl+Hu7l7k+Ly8PHTu3Bnu7u5Yv349qlevjsTERLi4uBi/+GIw3BARVXz+/v7YsGEDevbsCYVCgSlTphisBebu3btISEjQ2ufl5YVx48ahRYsWmDlzJqKionDkyBHMmzcPCxYsAAD89ttv+Oeff9C2bVu4urpi27ZtUKlUqF+/Po4dO4Y9e/agS5cucHd3x7Fjx3D37l00bNjQIJ+hPJI13Hz99dcYNmwYhgwZAgBYtGgRtm7diqVLl2LixIlFjl+6dCkePHiAw4cPa5r//Pz8jFmyTgw3REQV39dff423334brVq1QrVq1TBhwgRkZGQY5L1WrVqFVatWae2bOXMmPv74Y/z888+YOnUqZs6cCS8vL8yYMQODBw8GALi4uGDDhg2IiYlBTk4O/P39sXr1ajRu3BgXL17E77//jjlz5iAjIwO+vr746quv0K1bN4N8hvJIIck0NiwvLw92dnZYv349IiMjNfujo6ORlpaGzZs3F3lN9+7dUaVKFdjZ2WHz5s1wc3PDm2++iQkTJmia6Z6Wm5uL3NxczeOMjAz4+PggPT0dTk5Oev1M48cDX30FjB0rbomITElOTg6uXbuGWrVqwcbGRu5yyATp+hnLyMiAs7NziX5/y9bn5t69e1AqlfBQN3f8j4eHB1JSUop9zT///IP169dDqVRi27ZtmDJlCr766it88sknz3yf2NhYODs7azYfHx+9fo7C2HJDREQkP9k7FJeGSqWCu7s7lixZguDgYERFRWHy5MlYtGjRM18zadIkpKena7akpCSD1cdwQ0REJD/Z+txUq1YN5ubmSH0qCaSmpsLT07PY13h5ecHS0lLrElTDhg2RkpKCvLw8WFlZFXmNtbU1rK2t9Vv8MzDcEBERyU+2lhsrKysEBwdjz549mn0qlQp79uxBWFhYsa9p3bo1rl69qtVr/a+//oKXl1exwcbYGG6IiIjkJ+tlqbFjx+K7777Df//7X1y8eBHvv/8+srOzNaOnBg0ahEmTJmmOf//99/HgwQOMHj0af/31F7Zu3YrPPvsMI0eOlOsjaFGHm3v3xCrhREREZHyyDgWPiorC3bt3MXXqVKSkpCAoKAg7duzQdDK+ceMGzMwK8pePjw927tyJjz76CE2bNkX16tUxevRoTJgwQa6PoMXNTUwspVKJgPNUX2kiIiIyAtmGgsulNEPJysLNTQSb06eBQsuMEBFVeBwKToZW4YeCmyr2uyEiIpIXw42eMdwQERHJi+FGzxhuiIhMT/v27TFmzBjNYz8/P8yZM0fnaxQKBTZt2vTC762v81QmDDd6xnBDRFR+9OzZE127di32uYMHD0KhUODMmTOlPu/x48cxfPjwFy1PS0xMDIKCgorsT05ONvi6UMuXLy83i1DrA8ONnjHcEBGVH++88w7i4uJw8+bNIs8tW7YMISEhaFqG0R9ubm6ws7PTR4nP5enpabTJaE0Fw42eqcPNnTvy1kFERMArr7wCNzc3LF++XGt/VlYW1q1bh3feeQf3799H//79Ub16ddjZ2SEgIACrV6/Wed6nL0tduXIFbdu2hY2NDRo1aoS4uLgir5kwYQLq1asHOzs71K5dG1OmTEF+fj4A0XIyffp0nD59GgqFAgqFQlPz05elzp49i44dO8LW1hZVq1bF8OHDkZWVpXl+8ODBiIyMxJdffgkvLy9UrVoVI0eO1LxXWdy4cQO9evWCg4MDnJyc0K9fP60VBk6fPo0OHTrA0dERTk5OCA4Oxp9//gkASExMRM+ePeHq6gp7e3s0btwY27ZtK3MtJSHrPDemyN1d3LLlhohMniQBjx7J8952dmJiseewsLDAoEGDsHz5ckyePBmK/71m3bp1UCqV6N+/P7KyshAcHIwJEybAyckJW7duxcCBA1GnTh20bNnyue+hUqnQp08feHh44NixY0hPT9fqn6Pm6OiI5cuXw9vbG2fPnsWwYcPg6OiI//u//0NUVBTOnTuHHTt2YPfu3QAAZ2fnIufIzs5GREQEwsLCcPz4cdy5cwdDhw7FqFGjtALcvn374OXlhX379uHq1auIiopCUFAQhg0b9tzPU9znUwebAwcO4MmTJxg5ciSioqKwf/9+AMCAAQPQrFkzLFy4EObm5khISIClpSUAYOTIkcjLy8Pvv/8Oe3t7XLhwAQ4ODqWuo1SkSiY9PV0CIKWnpxvk/MePSxIgSd7eBjk9EZFsHj9+LF24cEF6/Pix2JGVJf7Bk2PLyipx3RcvXpQASPv27dPsa9OmjfTWW2898zU9evSQxo0bp3ncrl07afTo0ZrHvr6+0jfffCNJkiTt3LlTsrCwkG7duqV5fvv27RIAaePGjc98j9mzZ0vBwcGax9OmTZMCAwOLHFf4PEuWLJFcXV2lrEKff+vWrZKZmZmUkpIiSZIkRUdHS76+vtKTJ080x7z++utSVFTUM2tZtmyZ5OzsXOxzu3btkszNzaUbN25o9p0/f14CIMXHx0uSJEmOjo7S8uXLi319QECAFBMT88z3LqzIz1ghpfn9zctSelb4slShJbCIiEgmDRo0QKtWrbB06VIAwNWrV3Hw4EG88847AAClUomZM2ciICAAVapUgYODA3bu3IkbN26U6PwXL16Ej48PvL29NfuKWyNx7dq1aN26NTw9PeHg4ICPP/64xO9R+L0CAwNhb2+v2de6dWuoVCpcvnxZs69x48Zai0x7eXnhThn7S6g/n4+Pj2Zfo0aN4OLigosXLwIQyykNHToU4eHhmDVrFv7++2/NsR9++CE++eQTtG7dGtOmTStTB+7SYrjRM/VlqSdPgIcP5a2FiMig7OyArCx5tlJ25n3nnXfwyy+/IDMzE8uWLUOdOnXQrl07AMDs2bPxn//8BxMmTMC+ffuQkJCAiIgI5OXl6e2rOnLkCAYMGIDu3bvjt99+w6lTpzB58mS9vkdh6ktCagqFQmvRaX2LiYnB+fPn0aNHD+zduxeNGjXCxo0bAQBDhw7FP//8g4EDB+Ls2bMICQnB3LlzDVYLwHCjd9bWgHo0HfvdEJFJUygAe3t5thL0tymsX79+MDMzw6pVq/Djjz/i7bff1vS/OXToEHr16oW33noLgYGBqF27Nv76668Sn7thw4ZISkpCcnKyZt/Ro0e1jjl8+DB8fX0xefJkhISEwN/fH4mJiVrHWFlZQfmcVZcbNmyI06dPIzs7W7Pv0KFDMDMzQ/369Utcc2moP19SUpJm34ULF5CWloZGjRpp9tWrVw8fffQRdu3ahT59+mDZsmWa53x8fPDee+9hw4YNGDduHL777juD1KrGcGMAHA5ORFS+ODg4ICoqCpMmTUJycjIGDx6sec7f3x9xcXE4fPgwLl68iHfffVdrJNDzhIeHo169eoiOjsbp06dx8OBBTJ48WesYf39/3LhxA2vWrMHff/+Nb7/9VtOyoebn54dr164hISEB9+7dQ25ubpH3GjBgAGxsbBAdHY1z585h3759+OCDDzBw4EDNotNlpVQqkZCQoLVdvHgR4eHhCAgIwIABA3Dy5EnEx8dj0KBBaNeuHUJCQvD48WOMGjUK+/fvR2JiIg4dOoTjx4+jYcOGAIAxY8Zg586duHbtGk6ePIl9+/ZpnjMUhhsDYLghIip/3nnnHTx8+BARERFa/WM+/vhjNG/eHBEREWjfvj08PT0RGRlZ4vOamZlh48aNePz4MVq2bImhQ4fi008/1Trm1VdfxUcffYRRo0YhKCgIhw8fxpQpU7SOee2119C1a1d06NABbm5uxQ5Ht7Ozw86dO/HgwQO0aNECffv2RadOnTBv3rzSfRnFyMrKQrNmzbS2nj17QqFQYPPmzXB1dUXbtm0RHh6O2rVrY+3atQAAc3Nz3L9/H4MGDUK9evXQr18/dOvWDdOnTwcgQtPIkSPRsGFDdO3aFfXq1cOCBQteuF5duCq4AfTrB6xbB8yZA4webZC3ICIyOq4KTobGVcHLMbbcEBERyYfhxgAYboiIiOTDcGMADDdERETyYbgxAIYbIiIi+TDcGADDDRGZsko2DoWMSF8/Www3BlA43PDfACIyFepZbx/JtVgmmTz1jM2Fl44oC64KbgDqcJOXB6SnF8xYTERUkZmbm8PFxUWzRpGdnZ1mll+iF6VSqXD37l3Y2dnBwuLF4gnDjQHY2gKOjkBmpmi9YbghIlPh6ekJAGVehJFIFzMzM9SsWfOFQzPDjYF4eBSEGwMt90FEZHQKhQJeXl5wd3dHfn6+3OWQibGysoKZ2Yv3mGG4MRAPD+DqVXYqJiLTZG5u/sL9IogMhR2KDYQjpoiIiOTBcGMgDDdERETyYLgxEIYbIiIieTDcGAjDDRERkTwYbgyE4YaIiEgeDDcGwnBDREQkD4YbA+ESDERERPJguDEQdbh5/BjIypK3FiIiosqE4cZAHBwAOztxn7OUExERGQ/DjQGx3w0REZHxMdwYEMMNERGR8THcGBDDDRERkfEx3BgQww0REZHxMdwYEMMNERGR8THcGBDDDRERkfEx3BgQww0REZHxMdwYEMMNERGR8THcGBDDDRERkfEx3BiQOtxkZoplGIiIiMjwGG4MyMkJsLYW99l6Q0REZBwMNwakUPDSFBERkbEx3BgYww0REZFxMdwYGMMNERGRcTHcGJi7u7hluCEiIjIOhhsDY8sNERGRcTHcGBjDDRERkXEx3BgYww0REZFxlYtwM3/+fPj5+cHGxgahoaGIj49/5rHLly+HQqHQ2mxsbIxYbekw3BARERmX7OFm7dq1GDt2LKZNm4aTJ08iMDAQERERuHPnzjNf4+TkhOTkZM2WmJhoxIpLh+GGiIjIuGQPN19//TWGDRuGIUOGoFGjRli0aBHs7OywdOnSZ75GoVDA09NTs3moE0Q5pC4tLQ3IzZW1FCIiokpB1nCTl5eHEydOIDw8XLPPzMwM4eHhOHLkyDNfl5WVBV9fX/j4+KBXr144f/68McotE1dXwMJC3NfRGEVERER6Imu4uXfvHpRKZZGWFw8PD6SkpBT7mvr162Pp0qXYvHkzVq5cCZVKhVatWuHmzZvFHp+bm4uMjAytzZjMzDjXDRERkTHJflmqtMLCwjBo0CAEBQWhXbt22LBhA9zc3LB48eJij4+NjYWzs7Nm8/HxMXLF7HdDRERkTLKGm2rVqsHc3BypT/3WT01NhaenZ4nOYWlpiWbNmuHq1avFPj9p0iSkp6drtqSkpBeuu7QYboiIiIxH1nBjZWWF4OBg7NmzR7NPpVJhz549CAsLK9E5lEolzp49Cy8vr2Kft7a2hpOTk9ZmbAw3RERExmMhdwFjx45FdHQ0QkJC0LJlS8yZMwfZ2dkYMmQIAGDQoEGoXr06YmNjAQAzZszASy+9hLp16yItLQ2zZ89GYmIihg4dKufHAO7eBXbsAJRKYPBgracYboiIiIxH9nATFRWFu3fvYurUqUhJSUFQUBB27Nih6WR848YNmJkVNDA9fPgQw4YNQ0pKClxdXREcHIzDhw+jUaNGcn0E4cQJYNAgoE6dZ4YbjpYiIiIyPIUkSZLcRRhTRkYGnJ2dkZ6ert9LVOnpYty3JAEpKQWJBsBPPwFvvQV07AgUugJHREREJVSa398VbrRUueXsDDRpIu4fOqT1FC9LERERGQ/DjT61aiVuDx/W2s1wQ0REZDwMN/rUurW4fUbLzf37wJMnRq6JiIiokmG40Sd1uDlxAnj8WLO7alUxU7EkiUFVREREZDgMN/pUq5ZopsnPFwHnf8zNATc3cZ+XpoiIiAyL4UafFIrnXppiuCEiIjIshht9Y7ghIiKSFcONvqnDzeHDopPN/zDcEBERGQfDjb41awbY2IihUX/9pdnNcENERGQcDDf6ZmUFtGgh7he6NMVwQ0REZBwMN4ZQ+NLU/zDcEBERGQfDjSGoZypmyw0REZHRMdwYgjrcXLok+t6A4YaIiMhYGG4MoWpVoEEDcf/IEQAF4ebuXUCplKkuIiKiSoDhxlCeujTl5ibm+FOpNI05REREZAAMN4by1GR+FhaiQQfgpSkiIiJDYrgxFHW4OX4cyMsDwH43RERExsBwYyj16ommmpwc4NQpAAw3RERExsBwYygKRZF+Nww3REREhsdwY0hP9bthuCEiIjI8hhtDemoRTYYbIiIiw2O4MaTgYMDSEkhJAa5dY7ghIiIyAoYbQ7K1FQEHAA4dYrghIiIyAoYbQyt0aYrhhoiIyPAYbgyt0Igpdbi5c0fMVExERET6x3BjaOqWm3Pn4G6VBgsL4MkT4Nw5ecsiIiIyVQw3hubhAdSpA0gSrE4dQ2Sk2D1/vqxVERERmSyGG2MoNN/Nhx+KuytWAA8eyFcSERGRqWK4MYZC/W5efhkICgIePwa+/17WqoiIiEwSw40xqFtujh2DQvkEo0eLh/Pni/43REREpD8MN8bQqBHg7AxkZwNnzuCNN4Bq1YAbN4AtW+QujoiIyLQw3BiDmRkQFibuHzoEGxvg3XfFw2+/la8sIiIiU8RwYyxPLaL5/vuAuTlw4ACQkCBfWURERKaG4cZYCi+iCaB6daBvX7Fr7lyZaiIiIjJBDDfG0rKlaKpJShIboBkW/tNPwL17MtZGRERkQhhujMXeXowBBzSXpsLCgJAQIDcX+O47+UojIiIyJQw3xvTUpSmFoqD1ZsECID9fprqIiIhMCMONMT3VqRgA+vUD3N2BmzeBjRtlqouIiMiEMNwYk3qm4tOngZQUAIC1NfDee2I3h4UTERG9OIYbY6pRQ3S0USqBL77Q7H7vPcDSUjTonDghY31EREQmgOHG2KZNE7cLF2pab7y8xOUpgMPCiYiIXhTDjbF16QK89BKQk6PVeqPuWLx6NZCaKlNtREREJoDhxtgUCmD6dHF/4UIgORmAmAYnNBTIywOWLJGxPiIiogqO4UYOnTuLvjfPaL1ZuFCEHCIiIio9hhs5KBRATIy4v2iRpvWmb1/R/yY5GfjlF/nKIyIiqsgYbuTSubMYGp6TA3z+OQDAykosqAlwWDgREVFZMdzI5enWm9u3AQDDh4uQc/QocPy4fOURERFVVAw3cgoPF603ubma1hsPj4Jh4YsWyVgbERFRBcVwI6fCI6cWL9a03qgvTa1eDaSlyVMaERFRRcVwI7dOncSaU7m5wKxZAMRAqoAA4PFjYMUKmesjIiKqYBhu5Fa49WbJEuDWLSgUBetNLVoESJJ85REREVU0DDflQceOwMsva7XevPUWYG8PXLgA/PGHzPURERFVIOUi3MyfPx9+fn6wsbFBaGgo4uPjS/S6NWvWQKFQIDIy0rAFGlrhkVP/a71xcgLefFPsYsdiIiKikpM93KxduxZjx47FtGnTcPLkSQQGBiIiIgJ37tzR+brr169j/PjxaNOmjZEqNbCOHYE2bcTUxP9rvXn3XfHU+vXA3bsy1kZERFSByB5uvv76awwbNgxDhgxBo0aNsGjRItjZ2WHp0qXPfI1SqcSAAQMwffp01K5d24jVGtDTrTc3byI4GGjRQuSd5cvlLI6IiKjikDXc5OXl4cSJEwgPD9fsMzMzQ3h4OI4cOfLM182YMQPu7u545513nvseubm5yMjI0NrKrQ4dgLZttVpv1B2LFy8GVCoZayMiIqogZA039+7dg1KphIeHh9Z+Dw8PpKSkFPuaP/74Az/88AO+++67Er1HbGwsnJ2dNZuPj88L120whVtvvvsOOHUKUVGAszPw99/Anj2yVkdERFQhyH5ZqjQyMzMxcOBAfPfdd6hWrVqJXjNp0iSkp6drtqSkJANX+YLatxczF+flAe3bw/74fgwaJJ5ix2IiIqLns5DzzatVqwZzc3OkpqZq7U9NTYWnp2eR4//++29cv34dPXv21OxT/e9ajYWFBS5fvow6depovcba2hrW1tYGqN5AFApg3TqgVy/g99+Brl0x/vPVmIve2LxZTGLs7S13kUREROWXrC03VlZWCA4Oxp5C11tUKhX27NmDsLCwIsc3aNAAZ8+eRUJCgmZ79dVX0aFDByQkJJTvS06l4eIC7NgBREYCubmoObYvZvl/D6US+OEHuYsjIiIq32RtuQGAsWPHIjo6GiEhIWjZsiXmzJmD7OxsDBkyBAAwaNAgVK9eHbGxsbCxsUGTJk20Xu/i4gIARfZXeLa2ogXnvfeAH37AhCvDkI47WLJ4EiZNUsBC9v9yRERE5ZPsvyKjoqJw9+5dTJ06FSkpKQgKCsKOHTs0nYxv3LgBM7MK1TVIfywsRMdid3cgNhafYTLcb93Btt++xquRlfQ7ISIieg6FJFWulYsyMjLg7OyM9PR0ODk5yV1Oyc2ZA3z0EQBgn9eb6HB9GWBlJW9NRERERlKa39/887+iGDMGKV+uRD4s0CF5FR51fhXIzpa7KiIionKH4aYC8Rw3ANOa/Yps2MHu951Ap07Ac5apICIiqmwYbiqYkI+7ohP24IGiCnDsGNC0KRAXJ3dZRERE5QbDTQXTsydww+sltJb+QHqNRkBqKtClCzBhApCfL3d5REREsmO4qWAsLYGhQ4FLaIg3ah8vWDr8iy+Al18W6zQQERFVYgw3FdDQoYCZGbDjdztcGrMIWL9eTPwXHw80awasWiV3iURERLJhuKmAatYEevQQ9/v0AZJbvQacPi1abjIzgQEDgCFDgKwseQslIiKSAcNNBfXNN0CNGsDFi0DbtkCSoiawbx8wbZpo1lm+HGjeHDh5Uu5SiYiIjIrhpoKqU0esq+nnB1y9KgLOtSQLICYG2LtXJJ8rV4CXXgK+/BL43wKjREREpo7hpgKrVUsEnLp1gevXRcC5cgVAu3ZAQoJYeDM/H/jXv8ScODduyFswERGRETDcVHA+PiLgNGwI3LwpAs6FCwCqVgU2bAAWLwbs7YH9+4GAAGDlSqByrbhBRESVDMONCfDyEtmlaVMgJUU03Jw+DUChAIYPF604L70EZGQAAwcCUVHAgwcyV01ERGQYDDcmwt1ddLUJDgbu3QM6dAD+/PN/T9atCxw8CMycKVYaX7cOaNIE2LlT1pqJiIgMgeHGhFStCuzeDYSFAQ8fim42R47870kLC+Djj8WO+vWB5GSga1fggw+AR49krZuIiEifGG5MjIuLaJBp21ZchercWTTaaISEiOHho0aJx/PmiSHju3YBT57IUTIREZFeMdyYIEdHYPt2IDwcyM4Wg6b++afQAXZ2wNy5wI4dosPO5ctARATg7S2Wc9i1i+tUERFRhVWmcJOUlISbN29qHsfHx2PMmDFYsmSJ3gqjF2NnB2zZArRoIfoOv/qqmLxYS0QEcPYs8P77QJUqwN27wJIlYr+HB/D228C2bUBuriyfgYiIqCzKFG7efPNN7Nu3DwCQkpKCzp07Iz4+HpMnT8aMGTP0WiCVna0tsHGjaJw5f14MlCoyl1/VqsCCBWKYVVycaLlxcxOddpYtE+s8eHiIF+/cyWHkRERU7pUp3Jw7dw4tW7YEAPz8889o0qQJDh8+jJ9++gnLly/XZ330gqpXFwHH2hrYvFmszlAsS0txHWvRItHZeN8+YORIwNMTSE8X8+N07So68xw6ZNTPQEREVBplCjf5+fmwtrYGAOzevRuvvvoqAKBBgwZITk7WX3WkF6Gh4moTAHzyCbB27XNeYG4OtG8vOhvfugX88YfogGxjI+6//LK4znXunKFLJyIiKrUyhZvGjRtj0aJFOHjwIOLi4tC1a1cAwO3bt1G1alW9Fkj6MWgQMH68uD9kSCnW0zQzA1q3Fh2Qr1wBhg4V+379VcwaOGQIl3UgIqJypUzh5vPPP8fixYvRvn179O/fH4GBgQCALVu2aC5XUfkza5a4svT4sRhBlZpayhPUqAF8953owNOnj+h/s3w5UK8eMG6cmD2QiIhIZgpJKlsPUaVSiYyMDLi6umr2Xb9+HXZ2dnB3d9dbgfqWkZEBZ2dnpKenw8nJSe5yjC4tTVym+usv0SCzZ4/oj1Mm8fHAxImifw4AODmJRTpHjxbj0YmIiPSkNL+/y9Ry8/jxY+Tm5mqCTWJiIubMmYPLly+X62BDYpK/LVsAZ2fRL3jkyBcYANWypUhHO3YAQUFi1sApU8Ry5V98ISbZISIiMrIyhZtevXrhxx9/BACkpaUhNDQUX331FSIjI7Fw4UK9Fkj6V78+sGaN6Drzww+i33CZKRRiXpwTJ4BVqwB/f+D+fWDCBKB2beDrr7m8AxERGVWZws3JkyfRpk0bAMD69evh4eGBxMRE/Pjjj/j222/1WiAZRteuonEFAD76SKxJ9ULMzID+/YELF0Q/nNq1gTt3RF+cOnWAb78FcnJetGwiIqLnKlO4efToERz/16di165d6NOnD8zMzPDSSy8hMTFRrwWS4YwdK+bmUyqB3r2B/fv1cFILCyA6Grh0Cfj+e8DXV0wQOHq0WJ18wQLOeExERAZVpnBTt25dbNq0CUlJSdi5cye6dOkCALhz506l7KRbUSkUYv6b8HAgKwvo1k2stqAXlpbAO++InsuLFomRVrduiU4+deuK5xYuBP78E8jL09ObEhERlXG01Pr16/Hmm29CqVSiY8eOiIuLAwDExsbi999/x/bt2/VeqL5U9tFSxcnJAfr1E1PXWFoCq1cDr72m5zfJzRUtOZ99Bty+rf2clRUQGChWLG/RQmwNG4rJBImIiFC6399lHgqekpKC5ORkBAYGwsxMNADFx8fDyckJDRo0KMspjYLhpnj5+eIS1dq1ovvMsmVi4j+9e/xYrGEVHw8cPy5abh48KHqcvb1o3Zk5UwwxJyKiSs0o4UZNvTp4jRo1XuQ0RsNw82xKJTB8OLB0qXi8YIFYMNygJAm4dk0EHXXYOXFCXCcDxKqf//kP0LevuI5GRESVksHnuVGpVJgxYwacnZ3h6+sLX19fuLi4YObMmVAVWXaaKgpzczEB8YcfiscjRgCzZxv4TRUKMbIqKgr48kvRqzktDdi+XfTNSU4W18x69AD++cfAxRARkSkoU7iZPHky5s2bh1mzZuHUqVM4deoUPvvsM8ydOxdTpkzRd41kRGZmwJw5wL//LR7/3/+JlcRfrH2vlMzNxVj1s2eBqVNFn5zt24HGjYHYWHZAJiIincp0Wcrb2xuLFi3SrAautnnzZowYMQK3bt3SW4H6xstSJRcbWxByPvoI+Oorma4MXb4smpH27hWPGzYUI7DatpWhGCIikoPBL0s9ePCg2E7DDRo0wIPiOodShTRpkph7DwC++UbkC6O24KjVry9mGVyxAnBzAy5eBNq1A95+W8yhQ0REVEiZwk1gYCDmFTNn/7x589C0adMXLorKjw8+EEs0mJmJxhJ1Z2OjUyiAt94SrTjvviv2LVsGVK8ugs6cOcD16zIVR0RE5UmZLksdOHAAPXr0QM2aNREWFgYAOHLkCJKSkrBt2zbN0gzlES9Llc0XX4jlouztgVOnxBJSsjpyREyxfPSo9v6gICAyUky5HBDAEVZERCbC4Jel2rVrh7/++gu9e/dGWloa0tLS0KdPH5w/fx4rVqwoU9FUvo0bB7RvLxb6fustMS+OrMLCRMC5fl202rRrJ5qXEhKAmBgxKWDduqLwQ4cAjuIjIqo0Xniem8JOnz6N5s2bQ6lU6uuUeseWm7K7cQNo2hRITwemTAFmzJC7oqfcuyemWd60Cdi1S3uhzpo1xcKeb77JFh0iogrI4C03VDnVrCn63QDAp58Chw/LW08R1aoBQ4YAmzcDd+8C69cDAwYADg4imX3+uWjRCQgQH4Dz5hARmSSGGyqVN94Ql6VUKnGbkSF3Rc/g4CAWyFq5ErhzB1i3TvTDsbICzp8HPv4YqFNHXN769luOuiIiMiEMN1Rq8+YBvr5i1QT1bMblmq2tWL5hwwYgNVUM+QoPF310jh4FRo8GfHzELMkHD8o03p2IiPSlVH1u+vTpo/P5tLQ0HDhwgH1uKoE//hB9eFUq4Oefgddfl7uiMkhJEcWvWgUcO1awPzAQGDVK9M+xs5OvPiIi0jDYwplDhgwp0XHLli0r6SmNjuFGfz7+WHRdcXUFzpwBKsjaqcU7c0Y0Sa1cKVYuB8QHGzpUrB5aq5a89RERVXJGXRW8omG40Z/8fKBVK7GQd8eOQFycuNJToT18KC5bzZ8vrrsBYmRVz57AyJFAhw6ApaW8NRIRVUIMNzow3OjXX38BzZoBjx6JFcTHj5e7Ij1RKsVinXPnimHlara2wEsvAW3aiC0sTMxsSEREBsVwowPDjf4tWSJWRLC0BOLjxSTBJuXyZWDBAuCnn4D797Wfs7AAmjcvCDsvvwxUrSpPnUREJozhRgeGG/2TJDHKevNmsWD39u1iNJXJUamAS5fEiCr1duNG0ePq1QNatizYgoIAa2ujl0tEZEoYbnRguDGMu3fF7MUpKWIqmVGjgH//uxI0Yty4oR12LlwoeoylpQg4hQNPvXom0EGJiMh4GG50YLgxnPPnxSri+/aJx05OYrHN0aMrUbeU+/eB48fF9bn4eDHE/N69osd5eRUs8Nm+PTspExE9B8ONDgw3hiVJov/thAnA6dNin5eXWMvy7bdFF5VKRZLE4p6Fw87JkwXDzQHAxUWMxurdG4iI4Nw6RETFqHBrS82fPx9+fn6wsbFBaGgo4uPjn3nshg0bEBISAhcXF9jb2yMoKIgrkZcjCoX4/XzypJgyxs8PSE4WHY4bNwZ++aWSTQCsUIg5cqKigK++ErMfPnwIbNsGDBsGuLsDaWnAihVAnz5ifazevYEffxTLRhARUanJ3nKzdu1aDBo0CIsWLUJoaCjmzJmDdevW4fLly3B3dy9y/P79+/Hw4UM0aNAAVlZW+O233zBu3Dhs3boVERERz30/ttwYV24usHgxMHNmwdWZZs0Af3/RiqPeLC21H9vaAtHRQN268tZvcEolcOSIWBpi40bRylOYmxvQqJFIho0aFdx3c+PK5kRUqVSoy1KhoaFo0aIF5s2bBwBQqVTw8fHBBx98gIkTJ5boHM2bN0ePHj0wc+bM5x7LcCOPjAzRcPHVV0B2dsle07SpaAEyNzdsbeWGJIlreRs3iu3s2WcfW7WqCDohIcC4cUD16sark4hIBhUm3OTl5cHOzg7r169HZGSkZn90dDTS0tKwefNmna+XJAl79+7Fq6++ik2bNqFz585FjsnNzUVubq7mcUZGBnx8fBhuZJKSAmzdKrqc5OcDT54UbIUfL1kCpKeLyYJLuOqH6cnOFkPPL1wQ2/nz4vaff7Sv7dnbi7UwPvqIQ86JyGSVJtzI2r3z3r17UCqV8PDw0Nrv4eGBS5cuPfN16enpqF69OnJzc2Fubo4FCxYUG2wAIDY2FtOnT9dr3VR2np7AO+88/zh3d+Bf/xK/s/v1q0SjrQqztweCg8VW2OPHYmLBc+eAhQuBw4eBSZOA778H5swBevTgJSsiqtTKRYfi0nJ0dERCQgKOHz+OTz/9FGPHjsX+/fuLPXbSpElIT0/XbElJScYtlsrkgw9EZ+Tbt8WlLCrE1lbMm/PWW6KD8ooVYkja33+LUVc9eoh1MYiIKilZw021atVgbm6O1NRUrf2pqanw9PR85uvMzMxQt25dBAUFYdy4cejbty9iY2OLPdba2hpOTk5aG5V/1tbArFni/hdfiBFXVAyFQoScy5fF+HtLSzFFdJMmwP/9n+js9CwqlfhijxwBtmwBHjwwXt1ERAYka7ixsrJCcHAw9uzZo9mnUqmwZ88ehIWFlfg8KpVKq18NmYZ+/YDQUNH1ZNo0uasp5xwdRRo8dw7o3l10YJo9G6hfXwxX++kn4NNPxfDzLl3EDMm2toC3t1javVcvMQrrwAG5PwkR0QuTfbTU2rVrER0djcWLF6Nly5aYM2cOfv75Z1y6dAkeHh4YNGgQqlevrmmZiY2NRUhICOrUqYPc3Fxs27YNEydOxMKFCzF06NDnvh9HS1Usf/wh1qM0MxMDiZo0kbuiCmLrVmDMGODqVd3HmZkBNWqIIem3bonHn3wiWoG4PAQRlSMVpkMxAERFReHu3buYOnUqUlJSEBQUhB07dmg6Gd+4cQNmhf6Rzc7OxogRI3Dz5k3Y2tqiQYMGWLlyJaKiouT6CGRAL78s5rbbsEF0MN6+Xe6KKogePYDwcNHBePVqwNVVdGLy9RW36vs1aohLWdnZwIgRYvLAf/9brJO1YkUlWByMiEyR7C03xsaWm4rn6lWx2viTJ8DOneKqChmAJAHLlgEjRwI5OYCPD7B2LVCKS8RERIZS4ZZfINKlbl3x+xYQrTdKpbz1mCyFQiwAduyYmEI6KQlo2xb45ptKtmYGEVV0DDdUIUyZAjg7A2fOiCsnZEBNmwJ//inWw3ryBBg7VlwbTEuTuzIiohLhZSmqML78UrTceHuLaVwq5cR+xiRJYpLAjz4C8vLEAqD//jfg4CDG6j9r8/AQK50TEelRhVl+QQ4MNxVXbi7QoIFYW3L6dGDqVLkrqiROnABefx24dq1kx5uZAS1aiOXhIyKAli3FaqhERC+A4UYHhpuKbe1a4I03RKvNlStiYl4ygrQ0MdnQ5cuiFSc3t/gtJ0csClaYszPQqVNB2PH1Lf49cnOBu3cLtsePgXbt2ApERAAYbnRiuKnYJEkM3jl2TMxHt2SJ3BVREUlJQFycGNoWFwc8fKj9fL16omUnPV07zGRmFj2Xra1Is+++K1qAuGYWUaXFcKMDw03FV3hiv+PHRRePu3eBO3fEpr6vvg0IEI0OVlZyV14JKZWic/LOncCuXcDRo7qHu1lYAG5uYnv8WDTPqQUGipAzYADA/3eJKh2GGx0YbkzDa6+Jif1Kqlcv4OefGXBkl5YG7N0reoRXrVoQZNzdxa2zc0HrjCSJFc8XLxb/8dRLrNjbA2++KYLO0yumE5HJYrjRgeHGNFy9Kn6vZWQA5uZFf0eqby0sgJgY8XsxMlL8jrS0lLt6KrUHD8QcAIsXA5cuFewPDgZeeUXcBgeLoXREZJIYbnRguDEdWVkitLi66l4Gadcu4NVXxbG9e4tOyQw4FZQkiaUhFi0CfvlFdG4uzNOzIOgUDjzsq0NU4THc6MBwUznt3CkuTeXmivno1qxhwKnw7t0TTXHHjonh6hcvAipV0eM8PMTq6J6eYnideiv8uEoVLhRKVM4x3OjAcFN57dghAk5enuizs3o1A45Jyc4WS8efOFGwXbhQfOB5mqWlGKIeFAQ0a1aweXoavGwiKhmGGx0Ybiq37dtF35u8PDEv3U8/MeCYtEePxJod168DKSlAcrLYCt+/f//Zr/f0BJo3Lwg7DRqITl5qxf3zaWMjVl3npTAivWK40YHhhrZtE31v1AFn1SpOoFup5eUBqaligsJTpwq2y5fLvmBoWBjwySdAx476rZWoEmO40YHhhgBg61YRcPLzgX79RAsOAw5pycoSrT6FA8/TS1AUbp1R38/IED9YgAg3n3wiwg4RvRCGGx0Ybkjtt99E5+L8fDEJ7ooVDDikB8nJwGefiWHr6pDTvTswc6a4xEVEZVKa398cHkCV1iuviNHElpZi9FT//kVHFhOVmpcXMHeumF156FDRR2fbNjEsvW9f4Px5uSskMnlsuaFK79dfxe+cvDygZ08xutjGRu6qyGRcuSKWsV+1SvThUShEkg4LEyO5nt6UyoL79eoBPXoADg5yfwoi2fGylA4MN1ScnTvFKKqcHKBLF2DjRsDOTu6qyKScPy8WOfvll9K9zsYG6NpVJPBXXhFLVJTU/ftAfLy4jYgQ03YTVVAMNzow3NCz7NsnWm6ys4H27UWLDv9gJr07eRJYsEB0PDYzK9jMzbUfq1TA77+LtUbUrKxE+n79dTHttotLwXO5uUBCgpjUUL39/XfB8xYWIiS99ZZ4ra2tsT4xkV4w3OjAcEO6HDoEdOsGZGYCrVqJrhKl+UOZSK8kCTh7Fli/Hli3TntdLUtLIDwcqF1btM4kJBR0YC6sfn0RZBISCvY5OoqWoIEDgXbtODszVQgMNzow3NDzxMeLFvy0NCAkRFyyqlJF7qqIIC5trV8vtnPnij7v5gaEhgItW4rbFi3E4muACEYrV4otMbHgNTVqAAMGiCGDXl6ihcfCQoQn9X2GHyoHGG50YLihkkhIEH8U378PBAYCcXHsrkDlzKVLwIYNYsX0kBARZkoyM7JKBRw+LOY++PlnkeKfx8xMhBwrK6B1a2DIELGWCXvekxEx3OjAcEMldf480KmTmLy2USNg927xhy2RycjNFTNarlwpmigfPSr5a11dRYvP22+LpSlKKjtb/PWQlycCGXvuUwkx3OjAcEOl8ddfYpLZW7cAf39g5EixvFCDBoCPD1vryQSpVKLvzpMnYit8/+FD0fdn2TLg5s2C1wQFidacAQOAqlUL9ufliVmejx8v2AovZmplBbz0kvifrGNHEXasrIz6caniYLjRgeGGSuuff8S/u4W7KQDiD8769QvCToMGooWncWOumUgmTqkE9uwBli4V8yaoZ7+0shKXq6pVE0HmzJniZ8b09hb/k9y6pb3f1hZ4+eWCsNO8OacNJw2GGx0YbqgskpOBhQvFpaqLF8W8bE+eFH/sa68Bq1dztXGqJB48ED/wS5eKYe5Pq1JFdGwOCRG3LVqIcCNJYqj63r0F29272q81N3/+KuxWVmL+n/feEyO/+JeFyWK40YHhhvQhP1+soXjpktguXhS3J06I5wYMAH78kZetqJJJSBBBR6UqCDO1apUscEiSuGSlDjr795ess3NhDRqIkDNoUMEoMTIZDDc6MNyQIf32m1ht/MkT8W/sggX8Q5KoTJRK0WT6tKf/h7p9G/jhB9EpOjtb7LO1FUPb33tPBKwX+Z/w/n1xCS4uTowqePxYLInRu7cYUskRY0bDcKMDww0Z2tq1YukgSQL+9S/g888ZcIgMLiNDrN+1cKHo66PWvLkIOa1aib5AVarovmacmwscOQLs2iUCzYkTxV8OA8QU5t27i6DTvTvA3ykGxXCjA8MNGcP33wPDhon7n3wCTJ4sbz1ElYYkAUePipDz888irDzNxUUEHfVWtaoIPZcuAQcOFB0S36QJ0Lmz2KytRSfqjRu1O0RbWYmWnD59xPIWLzIxliQBp06JFqMmTcSyGfwLieFGF4YbMpZvvgHGjhX3//Mf4MMP5a2HqNK5fx9YvlxcskpKEp2fS/Irz8NDBJUuXcStt3fRY1Qq4M8/RcjZsEHMG6GmUIg+RxERYnvppeeP+pIkMcJMPQP1tWsFzzVuDIwfL5qEra1L9NFNEcONDgw3ZEzTpwMxMeL+0qViKhAikolSKebquXev+M3TUwSagIDStZRIkhhVoA46T48ac3ISM4Kqw46fn9ivUolWJnWgSUoqeI2trRj9deiQWOwOELOIjh4NvPuu9qKplQTDjQ4MN2RMkiT+4Pr6azFyas0asaAzEZmw27dFn52dO0W/nfv3tZ+vXx8IDhYjwm7fLtjv4CCGtfftKy5F2dsD6enAkiXAnDkFxzo4iOveY8YANWvqp+bcXNEhuxwvpMdwowPDDRmbJAHDh4t+OJaWwKZNou/h814D8DI7UYWnVIqWnJ07xXbkiNin5uQk+uj07StajWxtiz9PXp4YZv/llwWLppqbi1FhkZEi8Njbi9lFC9/a24tLWXl5wI0bwPXr2ltiori9fVv8w+PtLYJX4a2crDvDcKMDww3JQakE3npLtNzY2ACTJol/ax4+FNuDBwX31VtQELB5M1C9utzVE5HepKeLeXxOnRLLTYSHl64fjSSJkDR7tjhPSZiZFSx5URZeXgVBp1kz0Vna0VF7M8KyGQw3OjDckFzy88Xsxb/+WvLXNGkCHDxYKS+vE9HznDgBzJ0LXL0qLik9eqR9+/TSF3Z2or9PcZuvr3j+9GlxXvV28WLJgpGVlXbYad5cdObWI4YbHRhuSE45OWJo+LVrYgLVKlXErXpTP87PF/OEJScDbduKP9Q4VxgRlcqTJwVBx8JCDHsv7bVu9Sru6rBz7pyYOTozU2w5OcW/7uWXxV9mesRwowPDDVUUp0+LYJORIVp81q7VXmaHiEh2+flAVlZB2FFvdnZA69Z6fSuGGx0Ybqgi2bdPDJrIywNGjhQt0OxkTESVUWl+f3NZP6JyrEMHYMUKEWjmzwdmzZK7IiKi8o/hhqic69dPTHEBAP/+t9776BERmRyGG6IK4MMPgQkTxP2hQ4Ft2+Sth4ioPGO4IaogYmOBQYPEnDmvvw7Ex8tdERFR+cRwQ1RBKBRiluOICDG6s0cP7bX6iIhIeM4ypURUnlhaivX1OnQQCxJ36CCWcvD3B+rWFbd16ohRmERElRXDDVEF4+AAbN0qppC4elW05jzN27sg8DRsCERHi/m7iIgqA85zQ1RBpaeLpRyuXgWuXCm4ffiw6LFVqwJffSX67HCeHCKqiDiJnw4MN2TqHjzQDjy//AKcPSue69ABWLQIqFdP3hqJiEqL4UYHhhuqbPLzgW++AWJigMePxfp2kyeLoeWlWYyYiEhOnKGYiDQsLYH/+z+x3l1EhFjKYdo0IChI7+vaERGVC+Ui3MyfPx9+fn6wsbFBaGgo4nVM4PHdd9+hTZs2cHV1haurK8LDw3UeT0RC7drA9u3A6tWAuztw6ZJYmHPoUHEpi4jIVMgebtauXYuxY8di2rRpOHnyJAIDAxEREYE7d+4Ue/z+/fvRv39/7Nu3D0eOHIGPjw+6dOmCW7duGblyoopHoQDeeEMEm2HDxL4ffgAaNABWrgQq10VqIjJVsve5CQ0NRYsWLTBv3jwAgEqlgo+PDz744ANMnDjxua9XKpVwdXXFvHnzMGjQoOcezz43RAX++AN4913gwgXxuGNHYMECoH59eesiInpahelzk5eXhxMnTiA8PFyzz8zMDOHh4Thy5EiJzvHo0SPk5+ejSpUqxT6fm5uLjIwMrY2IhJdfBk6dAj79FLCxAfbuBZo2FX1ycnLkro6IqGxkDTf37t2DUqmEh4eH1n4PDw+kpKSU6BwTJkyAt7e3VkAqLDY2Fs7OzprNx8fnhesmMiVWVmK18fPnga5dRYfjGTOAgABg1y65qyMiKj3Z+9y8iFmzZmHNmjXYuHEjbGxsij1m0qRJSE9P12xJSUlGrpKoYqhdW6w2vm6dmOH46lUxuqp/fyA5uWTnyM9nvx0ikp+syy9Uq1YN5ubmSE1N1dqfmpoKT09Pna/98ssvMWvWLOzevRtNmzZ95nHW1taw5mQeRCWiUAB9+wJdugBTpwJz5wJr1ojQ89lnwGuvATdvAklJwI0bRW+TkwFfXxGQQkLk/jREVFmViw7FLVu2xNy5cwGIDsU1a9bEqFGjntmh+IsvvsCnn36KnTt34qWXXirV+7FDMVHJnTwpOhz/+WfpXmdnJ0JRz56GqYuIKp/S/P6WfeHMsWPHIjo6GiEhIWjZsiXmzJmD7OxsDBkyBAAwaNAgVK9eHbGxsQCAzz//HFOnTsWqVavg5+en6Zvj4OAABwcH2T4HkSlq3hw4ehRYvFjMapyeDnh6Aj4+QM2aRW+rVQPee0/01YmMFC0/I0bI/SmIqLKRPdxERUXh7t27mDp1KlJSUhAUFIQdO3ZoOhnfuHEDZmYFXYMWLlyIvLw89O3bV+s806ZNQ0xMjDFLJ6oUzM1FQBk+HFCpRAdkXX77TQScpUuBkSOB69eBWbMAswrdw4+IKhLZL0sZGy9LERmeJInh5VOmiMf9+gH//a8Ybk5EVBYVZp4bIjJNCgXw8cfAjz+Kta1+/hno3Bm4f1/uyoioMmC4ISKDGTgQ2LEDcHYWsyG3agX884/cVRGRqWO4ISKD6tgROHRIdDj+6y/gpZeAY8fkroqITBnDDREZXOPGYtRVs2bA3btAmzZiLp2vvxbrWlWunn9EZGjsUExERpOVBbz5JvDrr9r7fXzEbMhduwKdOgEuLrKUR0TlWGl+fzPcEJFRSRJw+bLoi7NjB3DggPYinebmQFiYCDtdugDBwWIfEVVuDDc6MNwQlS+PHwO//14Qdi5d0n7exQXo0AEIDxebv78YjUVElQvDjQ4MN0TlW2IisHOnCDr79gFpadrP16xZEHQ6dQLc3WUpk4iMjOFGB4YboopDqQROnAB27xbboUNAXp72MQMHAvPnA46O8tRIRMbBcKMDww1RxfXokZgvJy5OhJ2EBLHf3x9Yu1aMxiIi08QZionIJNnZiU7Gs2cDp06JoOPjA1y5IubPmT+fw8qJiOGGiCqw1q1FyOnZU1yuGjUK6Nu3aD8dIqpcGG6IqEKrWhXYvBn45huxjtWGDUBQkJg0kIgqJ4YbIqrwFApgzBjg8GGgdm0x4qpNG+DLLwGVSu7qiMjYGG6IyGSEhAAnTwL9+gFPngD/+hfwyitAaqrclRGRMTHcEJFJcXYG1qwBFi0CbGyA7duB6tVF/5wZM8TlKqVS7iqJyJA4FJyITNaZM8Dbb4u5cgpzdRWTAHbpIpZ58PGRpz4iKjnOc6MDww1R5ZOYCOzaJWY+3r0bSE/Xfr5hQ3H5avhwoG5deWokIt0YbnRguCGq3J48AY4fF0Fn1y7g2DHtTsddugAjRgA9egAWFvLVSUTaGG50YLghosIePhStOcuXi/456n8Ra9QA3n0XGDoU8PSUtUQiAmcoJiIqMVdX4PXXga1bgb//BiZMAKpVA27eBKZMEf1xoqKAAwc4+zFRRcGWGyKip+TkAOvXAwsXirlz1Bo2BPr3F0PN69eXrz6iyoiXpXRguCGi0khIECFn5UqxcKda06Yi5Lz+OlCvnmzlEVUaDDc6MNwQUVmkp4ulHdatE6uSP3lS8FxgYEHQ8feXr0YiU8ZwowPDDRG9qAcPgE2bRNDZvVs76AQFiaATFSWWgiAi/WC40YHhhoj06f597aBTePbjkBARdPr1A3x9ZSuRyCQw3OjAcENEhnLvngg6a9cCe/dqz58TGipac15/XQwzJ6LSYbjRgeGGiIzhzh3RR2ft2qLDyFu3Btq2BRo3Bpo0ESOvbGzkq5WoImC40YHhhoiMLSVFDC3/+Wfgjz+KzpdjZiaWfWjcuCDwNG4MNGjAWZKJ1BhudGC4ISI53boF/PorcPo0cO4ccP68mCW5ODVqiEkFhw5lyw4Rw40ODDdEVJ5IkmjZOX9ebOrAc+4ckJkpjvH0BP7v/8RyEHZ28tZLJBeGGx0YboioIsjJAZYtA2bNAm7cEPvc3IBx48TCno6O8tZHZGxcW4qIqIKzsQHefx+4cgX47jsxZ87du8DEiYCfH/DJJ2JiQSIqii03REQVwJMnwKpVwKefAn/9JfY5OwODBomOx7Vqic3Pj/1zyDTxspQODDdEVJEplWLU1SefABcuFH+Ml1dB2KlVSyz4GRnJ/jpUsTHc6MBwQ0SmQKUCtmwRc+hcu1awqTshP83VFRg2DBg5EqhZ07i1EukDw40ODDdEZKokSax79c8/2oEnLk7sAwBzc6B3b2D0aDGZoEIhb81EJcVwowPDDRFVNkolsHUr8J//iGUh1Jo3FyEnKgqwtpavPqKS4GgpIiLSMDcHXn0V2LMHOHOmYFLAkyeB6GixqGdMDHD2bNHZk4kqIrbcEBFVQvfuiSHm8+eLWZPV3N2Bjh2B8HCgUycx+oqoPOBlKR0YboiICuTniwU+ly0DDh4EHj3Sfr52bRFywsOBDh3ERIJEcmC40YHhhoioeLm5wNGj4vLVnj3AsWOiv05hQUEi6ISHAy+/DNjby1IqVUIMNzow3BARlUxGBvD77wVh5+xZ7eetrICwsIKwExLCVczJcBhudGC4ISIqm9RUMdpq924xvDwpSft5Jydx6apXL+CNNwBbW3nqJNPEcKMDww0R0YuTJODqVRF0du8G9u0DHj4seL5KFeDtt8X6WLVry1cnmQ6GGx0YboiI9E+pBE6dAnbsAH74Abh+XexXKIBu3YBRo4CICMCME5BQGXGeGyIiMipzc9Hn5uOPRYvOli0izEgSsG0b0L07UK8e8NVXYhZlIkNiyw0RERnMlSvAwoXA0qVAerrYZ2sLvPIKEBAA1K8vNn9/LuxJuvGylA4MN0RExpedDaxaJSYNPH26+GNq1iwIO/XrA3Xrinl1qlUDqlYVw865FlblxXCjA8MNEZF8JAk4fFgMMb98uWAr3Bn5WaysCoKO+tbDA2jTRlwCc3ExePkkI4YbHRhuiIjKF0kC7t/XDjuXL4sVze/fF0tF5ObqPoe5uZhUsEcPccmrQQO28piaChVu5s+fj9mzZyMlJQWBgYGYO3cuWrZsWeyx58+fx9SpU3HixAkkJibim2++wZgxY0r1fgw3REQViySJZSHUQafw7bVrYoTWhQvar6lVS4ScHj2Adu3EQqFUsVWY0VJr167F2LFjMW3aNJw8eRKBgYGIiIjAnTt3ij3+0aNHqF27NmbNmgVPT08jV0tERHJQKER/m5o1gebNgc6dgf79xfDyr74Czp8H/vkHmDtXXJ6yshKhZ+5coGtXcfnqzTfFxIMqldyfhoxB1pab0NBQtGjRAvPmzQMAqFQq+Pj44IMPPsDEiRN1vtbPzw9jxoxhyw0REWnJyhLLRWzdKrbbtwueq1kTGDxYbLVqyVUhlUWFaLnJy8vDiRMnEB4eXlCMmRnCw8Nx5MgRucoiIqIKzsFBLAGxZAlw86ZYAHTECNHh+MYNYMYMMWtyx47AihVFV0Knik+2cHPv3j0olUp4eHho7ffw8EBKSore3ic3NxcZGRlaGxERVQ4KBdCypRiCfvu2GI7eubPYv28fMGgQ4OkJDB8O7NwJ3L0rd8WkDyY/Q3FsbCycnZ01m4+Pj9wlERGRDGxtRV+dXbvE8hAzZohLU5mZwHffif457u6Aj49o+Zk+Hfj1V+DWLdGpmSoO2cJNtWrVYG5ujtTUVK39qampeu0sPGnSJKSnp2u2pKeXsSUiokqnZk1gyhSxVMS+faIPTr164rmbN8XyETExwKuvAjVqiNadbt1E4DlxgmGnvJMt3FhZWSE4OBh79uzR7FOpVNizZw/CwsL09j7W1tZwcnLS2oiIiACxkGf79sCyZWJunfR0McHgnDniklWTJuKYO3fEkPOYGLGGlo+PWPF8+3YgJ0fmD0FFWMj55mPHjkV0dDRCQkLQsmVLzJkzB9nZ2RgyZAgAYNCgQahevTpiY2MBiE7IF/43mUFeXh5u3bqFhIQEODg4oG7durJ9DiIiMg1OTmLG4zZtCvY9egScPQucPClGYe3YIS5VLVokNnt7MQS9Z08xr46bm3z1kyD7JH7z5s3TTOIXFBSEb7/9FqGhoQCA9u3bw8/PD8uXLwcAXL9+HbWKGbvXrl077N+/v0Tvx6HgRET0InJygP37xaWrLVtE0FFTKIAWLcRCoL6+RTdbW9nKrvAq1AzFxsZwQ0RE+iJJwKlTBUHn1Cndx7u5FQSdwouCFnfr6MglJApjuNGB4YaIiAwlKQk4dAhITCy6ZWWV7lyWlqLPz8svF2ze3oapuyJguNGB4YaIiIxNksTK5+qgk5RUdJ2swrePHxd/nlq1tMNOgwaiw3NlwHCjA8MNERGVd48eAampwPHjwB9/iO306aJrY7m6AmFhQGio2Fq2FPtMEcONDgw3RERUEWVkAEePFoSdo0eLb+GpV68g7ISGAk2bisVEKzqGGx0YboiIyBTk54sOzEePivWzjh0D/v676HHW1qJFp1s3oHt3EXYqYkdlhhsdGG6IiMhU3bsHxMcXhJ34eNHXpzBvbxFyuncHwsPFqKyKgOFGB4YbIiKqLCQJuHIF2LsX2LZNTEJYeBV0S0sxYWH37mKmZgcHwNwcsLAouC1838oKsLGR57Mw3OjAcENERJVVTo5YXmLbNrFduVL6c9SuLSYqbNlS3DZvLmZpNjSGGx0YboiIiIQrV8T6WNu2if47+fnAkyeAUllwq1TqPoeZGdC4cUHYadlSzM9jaanfWhludGC4ISIiKjlJKgg5mZkiBB0/LvrzxMcDyclFX+PvD/z1l37rKM3vb1kXziQiIqLyTaEo6HtjbQ107iw2tVu3CsLO8eNiCwiQr16A4YaIiIheQPXqYouMFI9VKtHCI6dKMmkzERERGYOZGeDsLHMN8r49ERERkX4x3BAREZFJYbghIiIik8JwQ0RERCaF4YaIiIhMCsMNERERmRSGGyIiIjIpDDdERERkUhhuiIiIyKQw3BAREZFJYbghIiIik8JwQ0RERCaF4YaIiIhMioXcBRibJEkAgIyMDJkrISIiopJS/95W/x7XpdKFm8zMTACAj4+PzJUQERFRaWVmZsLZ2VnnMQqpJBHIhKhUKty+fRuOjo5QKBQlfl1GRgZ8fHyQlJQEJycnA1ZIAL9vY+P3bVz8vo2L37dxGer7liQJmZmZ8Pb2hpmZ7l41la7lxszMDDVq1Cjz652cnPg/hxHx+zYuft/Gxe/buPh9G5chvu/ntdiosUMxERERmRSGGyIiIjIpDDclZG1tjWnTpsHa2lruUioFft/Gxe/buPh9Gxe/b+MqD993petQTERERKaNLTdERERkUhhuiIiIyKQw3BAREZFJYbghIiIik8JwUwLz58+Hn58fbGxsEBoaivj4eLlLMgm///47evbsCW9vbygUCmzatEnreUmSMHXqVHh5ecHW1hbh4eG4cuWKPMWagNjYWLRo0QKOjo5wd3dHZGQkLl++rHVMTk4ORo4ciapVq8LBwQGvvfYaUlNTZaq4Ylu4cCGaNm2qmcgsLCwM27dv1zzP79qwZs2aBYVCgTFjxmj28TvXn5iYGCgUCq2tQYMGmufl/q4Zbp5j7dq1GDt2LKZNm4aTJ08iMDAQERERuHPnjtylVXjZ2dkIDAzE/Pnzi33+iy++wLfffotFixbh2LFjsLe3R0REBHJycoxcqWk4cOAARo4ciaNHjyIuLg75+fno0qULsrOzNcd89NFH+PXXX7Fu3TocOHAAt2/fRp8+fWSsuuKqUaMGZs2ahRMnTuDPP/9Ex44d0atXL5w/fx4Av2tDOn78OBYvXoymTZtq7ed3rl+NGzdGcnKyZvvjjz80z8n+XUukU8uWLaWRI0dqHiuVSsnb21uKjY2VsSrTA0DauHGj5rFKpZI8PT2l2bNna/alpaVJ1tbW0urVq2Wo0PTcuXNHAiAdOHBAkiTx/VpaWkrr1q3THHPx4kUJgHTkyBG5yjQprq6u0vfff8/v2oAyMzMlf39/KS4uTmrXrp00evRoSZL4861v06ZNkwIDA4t9rjx812y50SEvLw8nTpxAeHi4Zp+ZmRnCw8Nx5MgRGSszfdeuXUNKSorWd+/s7IzQ0FB+93qSnp4OAKhSpQoA4MSJE8jPz9f6zhs0aICaNWvyO39BSqUSa9asQXZ2NsLCwvhdG9DIkSPRo0cPre8W4M+3IVy5cgXe3t6oXbs2BgwYgBs3bgAoH991pVs4szTu3bsHpVIJDw8Prf0eHh64dOmSTFVVDikpKQBQ7Hevfo7KTqVSYcyYMWjdujWaNGkCQHznVlZWcHFx0TqW33nZnT17FmFhYcjJyYGDgwM2btyIRo0aISEhgd+1AaxZswYnT57E8ePHizzHn2/9Cg0NxfLly1G/fn0kJydj+vTpaNOmDc6dO1cuvmuGG6JKaOTIkTh37pzWNXLSv/r16yMhIQHp6elYv349oqOjceDAAbnLMklJSUkYPXo04uLiYGNjI3c5Jq9bt26a+02bNkVoaCh8fX3x888/w9bWVsbKBF6W0qFatWowNzcv0sM7NTUVnp6eMlVVOai/X373+jdq1Cj89ttv2LdvH2rUqKHZ7+npiby8PKSlpWkdz++87KysrFC3bl0EBwcjNjYWgYGB+M9//sPv2gBOnDiBO3fuoHnz5rCwsICFhQUOHDiAb7/9FhYWFvDw8OB3bkAuLi6oV68erl69Wi5+vhludLCyskJwcDD27Nmj2adSqbBnzx6EhYXJWJnpq1WrFjw9PbW++4yMDBw7dozffRlJkoRRo0Zh48aN2Lt3L2rVqqX1fHBwMCwtLbW+88uXL+PGjRv8zvVEpVIhNzeX37UBdOrUCWfPnkVCQoJmCwkJwYABAzT3+Z0bTlZWFv7++294eXmVj59vo3RbrsDWrFkjWVtbS8uXL5cuXLggDR8+XHJxcZFSUlLkLq3Cy8zMlE6dOiWdOnVKAiB9/fXX0qlTp6TExERJkiRp1qxZkouLi7R582bpzJkzUq9evaRatWpJjx8/lrnyiun999+XnJ2dpf3790vJycma7dGjR5pj3nvvPalmzZrS3r17pT///FMKCwuTwsLCZKy64po4caJ04MAB6dq1a9KZM2ekiRMnSgqFQtq1a5ckSfyujaHwaClJ4neuT+PGjZP2798vXbt2TTp06JAUHh4uVatWTbpz544kSfJ/1ww3JTB37lypZs2akpWVldSyZUvp6NGjcpdkEvbt2ycBKLJFR0dLkiSGg0+ZMkXy8PCQrK2tpU6dOkmXL1+Wt+gKrLjvGoC0bNkyzTGPHz+WRowYIbm6ukp2dnZS7969peTkZPmKrsDefvttydfXV7KyspLc3NykTp06aYKNJPG7Noanww2/c/2JioqSvLy8JCsrK6l69epSVFSUdPXqVc3zcn/XCkmSJOO0EREREREZHvvcEBERkUlhuCEiIiKTwnBDREREJoXhhoiIiEwKww0RERGZFIYbIiIiMikMN0RERGRSGG6IqFJSKBTYtGmT3GUQkQEw3BCR0Q0ePBgKhaLI1rVrV7lLIyITYCF3AURUOXXt2hXLli3T2mdtbS1TNURkSthyQ0SysLa2hqenp9bm6uoKQFwyWrhwIbp16wZbW1vUrl0b69ev13r92bNn0bFjR9ja2qJq1aoYPnw4srKytI5ZunQpGjduDGtra3h5eWHUqFFaz9+7dw+9e/eGnZ0d/P39sWXLFs1zDx8+xIABA+Dm5gZbW1v4+/sXCWNEVD4x3BBRuTRlyhS89tprOH36NAYMGIA33ngDFy9eBABkZ2cjIiICrq6uOH78ONatW4fdu3drhZeFCxdi5MiRGD58OM6ePYstW7agbt26Wu8xffp09OvXD2fOnEH37t0xYMAAPHjwQPP+Fy5cwPbt23Hx4kUsXLgQ1apVM94XQERlZ7QlOomI/ic6OloyNzeX7O3ttbZPP/1UkiSxgvl7772n9ZrQ0FDp/ffflyRJkpYsWSK5urpKWVlZmue3bt0qmZmZSSkpKZIkSZK3t7c0efLkZ9YAQPr44481j7OysiQA0vbt2yVJkqSePXtKQ4YM0c8HJiKjYp8bIpJFhw4dsHDhQq19VapU0dwPCwvTei4sLAwJCQkAgIsXLyIwMBD29vaa51u3bg2VSoXLly9DoVDg9u3b6NSpk84amjZtqrlvb28PJycn3LlzBwDw/vvv47XXXsPJkyfRpUsXREZGolWrVmX6rERkXAw3RCQLe3v7IpeJ9MXW1rZEx1laWmo9VigUUKlUAIBu3bohMTER27ZtQ1xcHDp16oSRI0fiyy+/1Hu9RKRf7HNDROXS0aNHizxu2LAhAKBhw4Y4ffo0srOzNc8fOnQIZmZmqF+/PhwdHeHn54c9e/a8UA1ubm6Ijo7GypUrMWfOHCxZsuSFzkdExsGWGyKSRW5uLlJSUrT2WVhYaDrtrlu3DiEhIXj55Zfx008/IT4+Hj/88AMAYMCAAZg2bRqio6MRExODu3fv4oMPPsDAgQPh4eEBAIiJicF7770Hd3d3dOvWDZmZmTh06BA++OCDEtU3depUBAcHo3HjxsjNzcVvv/2mCVdEVL4x3BCRLHbs2AEvLy+tffXr18elS5cAiJFMa9aswYgRI+Dl5YXVq1ejUaNGAAA7Ozvs3LkTo0ePRosWLWBnZ4fXXnsNX3/9teZc0dHRyMnJwTfffIPx48ejWrVq6Nu3b4nrs7KywqRJk3D9+nXY2tqiTZs2WLNmjR4+OREZmkKSJEnuIoiIClMoFNi4cSMiIyPlLoWIKiD2uSEiIiKTwnBDREREJoV9boio3OHVciJ6EWy5ISIiIpPCcENEREQmheGGiIiITArDDREREZkUhhsiIiIyKQw3REREZFIYboiIiMikMNwQERGRSWG4ISIiIpPy//qm9AOcydblAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy(history)\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
